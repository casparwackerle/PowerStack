# FILE: playbooks/roles/tycho_testing/tasks/main.yml
- name: Resolve plan file path
  set_fact:
    plan_path: "{{ tycho_test_plan_root }}/{{ tycho_test_plan_id }}.yaml"

- name: Load plan YAML file (raw)
  set_fact:
    plan_yaml: "{{ lookup('file', plan_path) }}"

- name: Parse plan YAML
  set_fact:
    plan_obj: "{{ plan_yaml | from_yaml }}"

- name: Fail fast on apiVersion/kind mismatch
  fail:
    msg: "Invalid plan header: expected apiVersion tycho.testing/v1 and kind TestPlan"
  when: plan_obj.apiVersion != 'tycho.testing/v1' or plan_obj.kind != 'TestPlan'

- name: Fail fast if metadata.plan_id mismatches selected plan id
  fail:
    msg: "Plan ID mismatch: file selected={{ tycho_test_plan_id }}, metadata.plan_id={{ plan_obj.metadata.plan_id | default('MISSING') }}"
  when: (plan_obj.metadata.plan_id | default('')) != tycho_test_plan_id

- name: Extract namespace from plan
  set_fact:
    plan_ns: "{{ plan_obj.spec.target.namespace | default('') }}"

- name: Fail fast if namespace missing
  fail:
    msg: "spec.target.namespace is required"
  when: plan_ns | length == 0

# ---------------------------
# Slice 2: Additional plan validation (fail fast)
# ---------------------------

- name: Extract target node name from plan
  set_fact:
    plan_target_node: "{{ plan_obj.spec.target.node_name | default('') }}"

- name: Fail fast if target node name missing
  fail:
    msg: "spec.target.node_name is required"
  when: plan_target_node | length == 0

- name: Extract repetitions count from plan (type-safe)
  set_fact:
    plan_rep_count_raw: "{{ plan_obj.spec.repetitions.count | default('') }}"
    plan_rep_count: "{{ (plan_obj.spec.repetitions.count | default(0)) | int }}"

- name: Fail fast if repetitions.count invalid
  fail:
    msg: "spec.repetitions.count must be an integer >= 1 (got: '{{ plan_rep_count_raw | default('MISSING') }}')"
  when: (plan_rep_count | int) < 1

- name: Extract phases list
  set_fact:
    plan_phases: "{{ plan_obj.spec.phases | default([]) }}"

- name: Fail fast if phases missing or empty
  fail:
    msg: "spec.phases must be a non-empty list"
  when: plan_phases | length == 0

- name: Fail fast on unknown workload templates (Slice 2 minimum set)
  fail:
    msg: "Unknown workload template '{{ (item.workload.template | default('MISSING')) }}' in phase '{{ item.name }}' (allowed: noop-sleep, sleep, ramp, stressng-cpu, stressng-cpu-burst, stressng-cpu-jitter, gpu-burn-steady, gpu-burn-burst)"
  loop: "{{ plan_phases }}"
  when: (item.type == 'workload') and ((item.workload.template | default('')) not in ['sleep','noop-sleep','stressng-cpu','ramp','stressng-cpu-burst','stressng-cpu-jitter','gpu-burn-steady','gpu-burn-burst'])

- name: Fail fast if any phase name missing
  fail:
    msg: "Every phase must have a non-empty 'name'"
  loop: "{{ plan_phases }}"
  when: (item.name | default('') | length) == 0

- name: Fail fast if sleep phase missing duration_sec
  fail:
    msg: "Phase '{{ item.name }}' type=sleep requires duration_sec"
  loop: "{{ plan_phases }}"
  when: (item.type == 'sleep') and ((item.duration_sec | default(0) | int) <= 0)

- name: Fail fast if ramp phase missing duration_sec or ramp_profile
  fail:
    msg: "Phase '{{ item.name }}' type=ramp requires duration_sec and ramp_profile"
  loop: "{{ plan_phases }}"
  when: (item.type == 'ramp') and (((item.duration_sec | default(0) | int) <= 0) or ((item.ramp_profile | default('') | length) == 0))

- name: Fail fast if workload phase missing workload.template
  fail:
    msg: "Phase '{{ item.name }}' type=workload requires workload.template"
  loop: "{{ plan_phases }}"
  when: (item.type == 'workload') and (((item.workload | default({})).template | default('') | length) == 0)



# - name: Fail fast on unknown workload templates (Slice 2 minimum set)
#   fail:
#     msg: "Unknown workload template '{{ (item.workload.template | default('MISSING')) }}' in phase '{{ item.name }}' (allowed: noop-sleep, stressng-cpu, stressng-cpu-burst, stressng-cpu-jitter, gpu-burn-steady', gpu-burn-burst)"
#   loop: "{{ plan_phases }}"
#   when: (item.type == 'workload') and ((item.workload.template | default('')) not in ['noop-sleep','stressng-cpu','stressng-cpu-burst','stressng-cpu-jitter','gpu-burn-steady','gpu-burn-burst'])

# Validate stressng-cpu params (minimum set)
- name: Fail fast if stressng-cpu missing required params
  fail:
    msg: "Phase '{{ item.name }}' stressng-cpu requires params: duration_sec (>0), workers (>0), method (non-empty), cpu_request_mcpu (>0)"
  loop: "{{ plan_phases }}"
  when: >
    (item.type == 'workload') and
    ((item.workload.template | default('')) == 'stressng-cpu') and
    (
      ((item.workload.params.duration_sec | default(0) | int) <= 0) or
      ((item.workload.params.workers | default(0) | int) <= 0) or
      ((item.workload.params.method | default('') | length) == 0) or
      ((item.workload.params.cpu_request_mcpu | default(0) | int) <= 0)
    )

# Validate stressng-cpu-burst params (minimum set)
- name: Fail fast if stressng-cpu-burst missing required params
  fail:
    msg: >-
      Phase '{{ item.name }}' stressng-cpu-burst requires params:
      total_duration_sec (>0), on_sec (>0), off_sec (>0), seed (>=0),
      on_workers (>=0), on_method (non-empty),
      off_mode (sleep|stress),
      off_workers (>=0 when off_mode=stress), off_method (non-empty when off_mode=stress),
      cpu_request_mcpu (>0), cpu_limit_mcpu (>=0, 0 means unset)
  loop: "{{ plan_phases }}"
  when: >
    (item.type == 'workload') and
    ((item.workload.template | default('')) == 'stressng-cpu-burst') and
    (
      ((item.workload.params.total_duration_sec | default(0) | int) <= 0) or
      ((item.workload.params.on_sec | default(0) | int) <= 0) or
      ((item.workload.params.off_sec | default(0) | int) <= 0) or
      ((item.workload.params.seed | default(-1) | int) < 0) or
      ((item.workload.params.on_workers | default(-1) | int) < 0) or
      ((item.workload.params.on_method | default('') | length) == 0) or
      ((item.workload.params.off_mode | default('') | length) == 0) or
      ((item.workload.params.off_mode | default('')) not in ['sleep','stress']) or
      (
        ((item.workload.params.off_mode | default('')) == 'stress') and
        (
          ((item.workload.params.off_workers | default(-1) | int) < 0) or
          ((item.workload.params.off_method | default('') | length) == 0)
        )
      ) or
      ((item.workload.params.cpu_request_mcpu | default(0) | int) <= 0) or
      ((item.workload.params.cpu_limit_mcpu | default(0) | int) < 0)
    )

- name: Fail fast if stressng-cpu-jitter missing required params
  fail:
    msg: >-
      Phase '{{ item.name }}' stressng-cpu-jitter requires params:
      total_duration_sec (>0), on_sec (>0),
      gap_min_sec (>=0), gap_max_sec (>=gap_min_sec),
      seed (>=0), workers (>=0), method (non-empty),
      cpu_request_mcpu (>0), cpu_limit_mcpu (>=0, 0 means unset)
  loop: "{{ plan_phases }}"
  when: >
    (item.type == 'workload') and
    ((item.workload.template | default('')) == 'stressng-cpu-jitter') and
    (
      ((item.workload.params.total_duration_sec | default(0) | int) <= 0) or
      ((item.workload.params.on_sec | default(0) | int) <= 0) or
      ((item.workload.params.gap_min_sec | default(-1) | int) < 0) or
      ((item.workload.params.gap_max_sec | default(-1) | int) < (item.workload.params.gap_min_sec | default(0) | int)) or
      ((item.workload.params.seed | default(-1) | int) < 0) or
      ((item.workload.params.workers | default(-1) | int) < 0) or
      ((item.workload.params.method | default('') | length) == 0) or
      ((item.workload.params.cpu_request_mcpu | default(0) | int) <= 0) or
      ((item.workload.params.cpu_limit_mcpu | default(0) | int) < 0)
    )
- name: Fail fast if gpu-burn-steady has invalid gpu_burn params
  fail:
    msg: >-
      Phase '{{ item.name }}' gpu-burn-steady: invalid gpu_burn params.
      gpu_burn_mem_mb and gpu_burn_mem_pct are mutually exclusive.
      gpu_burn_mem_pct must be 1..100.
      gpu_burn_gpu_index must be >= 0 if set.
  loop: "{{ plan_phases }}"
  when: >
    (item.type == 'workload') and
    ((item.workload.template | default('')) == 'gpu-burn-steady') and
    (
      (
        (item.workload.params.gpu_burn_mem_mb is defined) and
        (item.workload.params.gpu_burn_mem_pct is defined)
      ) or
      (
        (item.workload.params.gpu_burn_mem_pct is defined) and
        (
          (item.workload.params.gpu_burn_mem_pct | int) < 1 or
          (item.workload.params.gpu_burn_mem_pct | int) > 100
        )
      ) or
      (
        (item.workload.params.gpu_burn_gpu_index is defined) and
        ((item.workload.params.gpu_burn_gpu_index | int) < 0)
      )
    )

- name: Fail fast if gpu-burn-burst has invalid gpu_burn params
  fail:
    msg: >-
      Phase '{{ item.name }}' gpu-burn-burst: invalid gpu_burn params.
      gpu_burn_mem_mb and gpu_burn_mem_pct are mutually exclusive.
      gpu_burn_mem_pct must be 1..100.
      gpu_burn_gpu_index must be >= 0 if set.
  loop: "{{ plan_phases }}"
  when: >
    (item.type == 'workload') and
    ((item.workload.template | default('')) == 'gpu-burn-burst') and
    (
      (
        (item.workload.params.gpu_burn_mem_mb is defined) and
        (item.workload.params.gpu_burn_mem_pct is defined)
      ) or
      (
        (item.workload.params.gpu_burn_mem_pct is defined) and
        (
          (item.workload.params.gpu_burn_mem_pct | int) < 1 or
          (item.workload.params.gpu_burn_mem_pct | int) > 100
        )
      ) or
      (
        (item.workload.params.gpu_burn_gpu_index is defined) and
        ((item.workload.params.gpu_burn_gpu_index | int) < 0)
      )
    )


# ---------------------------
# Slice 2: Build runner assets (stored in ConfigMap via workload_yaml_map)
# ---------------------------

- name: Build runner meta env (flat, shell-safe)
  set_fact:
    runner_meta_env: |
      PLAN_ID="{{ tycho_test_plan_id }}"
      NAMESPACE="{{ plan_ns }}"
      TARGET_NODE="{{ plan_target_node }}"
      REPETITIONS="{{ plan_rep_count }}"

      # ConfigMap that contains plan.yaml + runner assets (same object).
      PLAN_CONFIGMAP="{{ tycho_test_plan_configmap_name }}"

      # Where the PVC is mounted in the runner container (Job template mounts /out).
      OUT_MOUNT="/out"

      # stress-ng workload image (simple, prebuilt)
      STRESSNG_IMAGE="polinux/stress-ng:latest"

      # GPU burn workload image (override per plan via params.image if needed)
      GPU_BURN_IMAGE="oguzpastirmaci/gpu-burn:latest"

      # Default runtime class for GPU workloads (can be overridden per phase via params.runtime_class)
      GPU_RUNTIME_CLASS_DEFAULT="nvidia"

      # Default timeout slack in seconds
      TIMEOUT_SLACK_SEC="60"


- name: Build phases PSV (pipe-separated, preserves empty safely)
  set_fact:
    runner_phases_psv: |
      {% for p in plan_phases -%}
      {# Columns: name|type|planned_duration_sec|template|params_json|role #}
      {{ p.name | trim }}|{{ p.type | trim }}|{{
        (p.duration_sec | default(0) | int)
        if (p.type in ['sleep','ramp'])
        else (
          (p.workload.params.total_duration_sec | default(0) | int)
          if ((p.workload.template | default('')) in ['stressng-cpu-burst','stressng-cpu-jitter','gpu-burn-burst'])
          else (p.workload.params.duration_sec | default(0) | int)
        )
      }}|{{
        (p.workload.template | default(''))
        if (p.type == 'workload')
        else ('noop-sleep' if (p.type == 'sleep') else ('ramp-' ~ (p.ramp_profile | default(''))))
      }}|{{
        (p.workload.params | default({}) | to_json)
        if (p.type == 'workload')
        else (
          ({ 'duration_sec': (p.duration_sec | default(0) | int) } | to_json)
          if (p.type == 'sleep')
          else ({
            'ramp_profile': (p.ramp_profile | default('')),
            'duration_sec': (p.duration_sec | default(0) | int),
            'max_workers': (p.params.max_workers | default(0) | int),
            'step_count': (p.params.step_count | default(0) | int),
            'method': (p.params.method | default('')),
            'cpu_request_mcpu': (p.params.cpu_request_mcpu | default(0) | int)
          } | to_json)
        )
      }}|{{
        'ramp' if (p.type == 'ramp') else 'workload' if (p.type == 'workload') else 'sleep'
      }}
      {% endfor -%}


- name: Build runner script (runner.sh)
  set_fact:
    runner_sh: |
      #!/bin/sh
      set -eu

      log() {
        # runner event log (also goes to stdout for kubectl logs job/...)
        # usage: log "message"
        ts="$(date -u +%Y-%m-%dT%H:%M:%SZ)"
        echo "[tycho-testing][${ts}] $*"
        if [ -n "${EVENTS_LOG:-}" ]; then
          echo "[tycho-testing][${ts}] $*" >> "${EVENTS_LOG}"
        fi
      }

      die() {
        log "FATAL: $*"
        exit 1
      }

      sanitize_k8s_name() {
        # best-effort DNS-1123-ish slug for pod names (keep short)
        # input: arbitrary string
        echo "$1" \
          | tr '[:upper:]' '[:lower:]' \
          | sed -e 's/[^a-z0-9-]/-/g' -e 's/--*/-/g' -e 's/^-//g' -e 's/-$//g' \
          | cut -c1-45
      }

      utc_now() {
        date -u +%Y-%m-%dT%H:%M:%SZ
      }

      safe_ts() {
        # for filenames AND Kubernetes resource names:
        # - lowercase
        # - replace ':' with '-'
        # - replace any remaining invalid chars with '-'
        # - collapse repeats and trim edges
        echo "$1" \
          | tr '[:upper:]' '[:lower:]' \
          | tr ':' '-' \
          | sed -e 's/[^a-z0-9.-]/-/g' -e 's/--*/-/g' -e 's/^-//g' -e 's/-$//g'
      }

      write_atomic_json() {
        # args: target_path, json_file
        # writes json_file content atomically to target_path using a tmp + sync + mv
        target="$1"
        src="$2"
        tmp="${target}.tmp"
        cat "${src}" > "${tmp}"
        # best-effort durability. (posix fsync is not available in pure sh)
        sync
        mv -f "${tmp}" "${target}"
        sync
      }

      # -------------
      # Load runner inputs
      # -------------

      if [ ! -f /plan/runner_meta.env ]; then
        die "missing /plan/runner_meta.env"
      fi
      if [ ! -f /plan/runner_phases.psv ]; then
        die "missing /plan/runner_phases.psv"
      fi

      # shellcheck disable=SC1091
      . /plan/runner_meta.env

      if [ -z "${PLAN_ID:-}" ] || [ -z "${NAMESPACE:-}" ] || [ -z "${TARGET_NODE:-}" ] || [ -z "${REPETITIONS:-}" ] || [ -z "${PLAN_CONFIGMAP:-}" ]; then
        die "runner_meta.env missing required keys (PLAN_ID, NAMESPACE, TARGET_NODE, REPETITIONS, PLAN_CONFIGMAP)"
      fi

      OUT_BASE="${OUT_MOUNT}/${PLAN_ID}"

      log "job started"
      log "namespace: ${NAMESPACE}"
      log "plan id: ${PLAN_ID}"
      log "target node: ${TARGET_NODE}"
      log "repetitions: ${REPETITIONS}"
      log "out base: ${OUT_BASE}"
      log ""

      log "verify in-cluster auth: read ConfigMap plan"
      kubectl -n "${NAMESPACE}" get configmap "${PLAN_CONFIGMAP}" -o name >/dev/null 2>&1 || die "cannot read plan ConfigMap (${PLAN_CONFIGMAP})"
      log "ok"
      log ""

      # -------------
      # Execution
      # -------------

      rep=0
      while [ "${rep}" -lt "${REPETITIONS}" ]; do
        RUN_START="$(utc_now)"
        SAFE_TS="$(safe_ts "${RUN_START}")"

        OUT_DIR="${OUT_BASE}/rep-${rep}"
        mkdir -p "${OUT_DIR}"

        EVENTS_LOG="${OUT_DIR}/events.log"
        : > "${EVENTS_LOG}"

        log "rep=${rep} start run_start_utc=${RUN_START}"
        log "writing outputs under ${OUT_DIR}"

        # phase list JSON accumulator (we build an array body with commas)
        PHASES_BODY_FILE="${OUT_DIR}/phases_body.json.tmp"
        : > "${PHASES_BODY_FILE}"
        first_phase=1

        # iterate phases.psv (pipe-separated)
        # columns: name|type|planned_duration_sec|template|params_json|role
        while IFS="|" read -r PHASE_NAME PHASE_TYPE PLANNED_DUR TEMPLATE PARAMS_JSON ROLE; do
          # skip empty lines
          if [ -z "${PHASE_NAME}" ]; then
            continue
          fi

          # Normalize fields (defensive: trims accidental whitespace / CRLF)
          PHASE_NAME="$(printf '%s' "${PHASE_NAME}" | tr -d '\r' | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')"
          PHASE_TYPE="$(printf '%s' "${PHASE_TYPE}" | tr -d '\r' | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')"
          TEMPLATE="$(printf '%s' "${TEMPLATE}" | tr -d '\r' | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')"

          PHASE_START="$(utc_now)"
          log "phase '${PHASE_NAME}' type=${PHASE_TYPE} start_utc=${PHASE_START}"

          phase_status="ok"
          phase_exit_reason=""

          # per-phase k8s metadata (filled only for pod phases)
          k8s_kind=""
          k8s_name=""
          k8s_uid=""
          k8s_node="${TARGET_NODE}"

          if [ "${PHASE_TYPE}" = "sleep" ]; then
            # sleep: pure wait
            dur="${PLANNED_DUR}"
            log "sleep ${dur}s"
            sleep "${dur}"

          elif [ "${PHASE_TYPE}" = "ramp" ]; then
            # ramp: cpu ramp up to max_workers over total duration (step_count steps).
            # PARAMS_JSON fields:
            # - ramp_profile (must be "cpu")
            # - duration_sec (total duration)
            # - max_workers (target workers at final step)
            # - step_count (number of steps, default 10)
            # - method (stress-ng cpu method, default "matrixprod")
            # - cpu_request_mcpu (cap for cpu request; per step uses min(workers*1000, cap). If cap=0, uses workers*1000)

            profile="$(echo "${PARAMS_JSON}" | sed -n 's/.*"ramp_profile"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
            total="${PLANNED_DUR}"

            maxw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"max_workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            steps="$(echo "${PARAMS_JSON}" | sed -n 's/.*"step_count"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
            cap_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

            if [ -z "${method}" ]; then method="matrixprod"; fi
            if [ -z "${steps}" ] || [ "${steps}" -le 0 ]; then steps=10; fi
            if [ -z "${maxw}" ] || [ "${maxw}" -le 0 ]; then maxw=4; fi
            if [ -z "${cap_req}" ]; then cap_req=0; fi

            if [ "${profile}" != "cpu" ]; then
              phase_status="failed"
              phase_exit_reason="unknown ramp_profile"
            else
              log "ramp cpu total=${total}s max_workers=${maxw} steps=${steps} method=${method} cap_cpu_request_mcpu=${cap_req}"

              # integer step duration, last step absorbs remainder
              base_step=$(( total / steps ))
              rem=$(( total - (base_step * steps) ))
              if [ "${base_step}" -le 0 ]; then
                base_step=1
                rem=0
                steps="${total}"
              fi

              i=1
              while [ "${i}" -le "${steps}" ]; do
                step_dur="${base_step}"
                if [ "${i}" -eq "${steps}" ]; then
                  step_dur=$(( base_step + rem ))
                fi

                # linear ramp: workers = ceil(maxw * i / steps)
                workers=$(( (maxw * i + steps - 1) / steps ))
                if [ "${workers}" -lt 1 ]; then workers=1; fi

                # per-step cpu request (mcpu): workers*1000, optionally capped
                req=$(( workers * 1000 ))
                if [ "${cap_req}" -gt 0 ] && [ "${req}" -gt "${cap_req}" ]; then
                  req="${cap_req}"
                fi

                step_slug="$(sanitize_k8s_name "${PHASE_NAME}-s${i}")"
                pod_name="tycho-${PLAN_ID}-r${rep}-${step_slug}-${SAFE_TS}"

                log "ramp step ${i}/${steps} duration=${step_dur}s workers=${workers} cpu_request=${req}m pod=${pod_name}"

                cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "ramp"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                stress-ng --cpu ${workers} --cpu-method ${method} --timeout ${step_dur}s --metrics-brief
            resources:
              requests:
                cpu: "${req}m"
      EOF

                deadline=$(( $(date +%s) + step_dur + TIMEOUT_SLACK_SEC ))
                while :; do
                  now="$(date +%s)"
                  if [ "${now}" -gt "${deadline}" ]; then
                    phase_status="failed"
                    phase_exit_reason="timeout in ramp step"
                    break
                  fi

                  st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                  if [ "${st}" = "Succeeded" ]; then
                    break
                  fi
                  if [ "${st}" = "Failed" ]; then
                    phase_status="failed"
                    phase_exit_reason="pod failed in ramp step"
                    break
                  fi
                  sleep 1
                done

                step_log="${OUT_DIR}/phase_${PHASE_NAME}_step_${i}.log"
                agg_log="${OUT_DIR}/phase_${PHASE_NAME}.log"

                # Always create log files so debugging is deterministic
                : > "${step_log}"
                : > "${agg_log}" 2>/dev/null || true

                # Capture logs (best-effort). If logs fail, store a helpful marker.
                if ! kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${step_log}" 2>&1; then
                  echo "[tycho-testing] kubectl logs failed for pod=${pod_name}" >> "${step_log}"
                fi

                # Append into aggregated ramp log
                {
                  echo "===== ramp step ${i}/${steps} pod=${pod_name} ====="
                  cat "${step_log}"
                  echo
                } >> "${agg_log}" 2>/dev/null || true

                # On failure: also capture describe
                if [ "${phase_status}" != "ok" ]; then
                  kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_step_${i}_describe.txt" 2>&1 || true
                fi

                kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true

                if [ "${phase_status}" != "ok" ]; then
                  break
                fi

                i=$(( i + 1 ))
              done
            fi

          elif [ "${PHASE_TYPE}" = "workload" ]; then
            # workload: one Pod, wait for terminal, collect logs, cleanup
            if [ "${TEMPLATE}" = "noop-sleep" ]; then
              dur="${PLANNED_DUR}"
              phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
              pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

              k8s_kind="Pod"
              k8s_name="${pod_name}"

              log "workload noop-sleep duration=${dur}s pod=${pod_name}"

              cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: sleep
            image: "busybox:1.36"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                sleep ${dur}
      EOF

              k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
              deadline=$(( $(date +%s) + dur + TIMEOUT_SLACK_SEC ))
              while :; do
                now="$(date +%s)"
                if [ "${now}" -gt "${deadline}" ]; then
                  phase_status="failed"
                  phase_exit_reason="timeout"
                  break
                fi

                st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                if [ "${st}" = "Succeeded" ]; then
                  break
                fi
                if [ "${st}" = "Failed" ]; then
                  phase_status="failed"
                  phase_exit_reason="pod failed"
                  break
                fi
                sleep 1
              done

              kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
              if [ "${phase_status}" != "ok" ]; then
                kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
              fi
              kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true

            elif [ "${TEMPLATE}" = "stressng-cpu" ]; then
              # parse required params from PARAMS_JSON (simple sed extraction, valid for our generated JSON)
              workers="$(echo "${PARAMS_JSON}" | sed -n 's/.*"workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
              dur="$(echo "${PARAMS_JSON}" | sed -n 's/.*"duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

              if [ -z "${workers}" ] || [ -z "${method}" ] || [ -z "${dur}" ] || [ -z "${cpu_req}" ]; then
                phase_status="failed"
                phase_exit_reason="missing stressng-cpu params"
              else
                phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
                pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

                k8s_kind="Pod"
                k8s_name="${pod_name}"

                log "workload stressng-cpu workers=${workers} method=${method} duration=${dur}s cpu_request=${cpu_req}m pod=${pod_name}"

                cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                stress-ng --cpu ${workers} --cpu-method ${method} --timeout ${dur}s --metrics-brief
            resources:
              requests:
                cpu: "${cpu_req}m"
      EOF
                k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
                deadline=$(( $(date +%s) + dur + TIMEOUT_SLACK_SEC ))
                while :; do
                  now="$(date +%s)"
                  if [ "${now}" -gt "${deadline}" ]; then
                    phase_status="failed"
                    phase_exit_reason="timeout"
                    break
                  fi

                  st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                  if [ "${st}" = "Succeeded" ]; then
                    break
                  fi
                  if [ "${st}" = "Failed" ]; then
                    phase_status="failed"
                    phase_exit_reason="pod failed"
                    break
                  fi
                  sleep 1
                done

                kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
                if [ "${phase_status}" != "ok" ]; then
                  kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
                fi
                kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
              fi
            elif [ "${TEMPLATE}" = "stressng-cpu-burst" ]; then
              # params:
              # total_duration_sec, on_sec, off_sec, seed
              # on_workers, on_method
              # off_mode (sleep|stress), off_workers, off_method
              # cpu_request_mcpu, cpu_limit_mcpu (0 => unset)
              total="$(echo "${PARAMS_JSON}" | sed -n 's/.*"total_duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              on_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              off_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              seed="$(echo "${PARAMS_JSON}" | sed -n 's/.*"seed"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

              on_workers="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              on_method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

              off_mode="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_mode"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
              off_workers="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              off_method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

              cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              cpu_lim="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_limit_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

              # defaults / coercions
              if [ -z "${seed}" ]; then seed=0; fi
              if [ -z "${off_mode}" ]; then off_mode="sleep"; fi
              if [ -z "${off_workers}" ]; then off_workers=0; fi
              if [ -z "${cpu_lim}" ]; then cpu_lim=0; fi

              if [ -z "${total}" ] || [ -z "${on_sec}" ] || [ -z "${off_sec}" ] || [ -z "${on_workers}" ] || [ -z "${on_method}" ] || [ -z "${cpu_req}" ]; then
                phase_status="failed"
                phase_exit_reason="missing stressng-cpu-burst params"
              else
                phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
                pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

                k8s_kind="Pod"
                k8s_name="${pod_name}"

                log "workload stressng-cpu-burst total=${total}s on=${on_sec}s off=${off_sec}s seed=${seed} on_workers=${on_workers} on_method=${on_method} off_mode=${off_mode} off_workers=${off_workers} off_method=${off_method} cpu_request=${cpu_req}m cpu_limit=${cpu_lim}m pod=${pod_name}"

                # render pod manifest (limits are optional; cpu_lim=0 => omit)
                if [ "${cpu_lim}" -gt 0 ]; then
                  cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                # seed is currently only logged for determinism; kept for future jitter extensions
                SEED="${seed}"
                TOTAL="${total}"
                ON_SEC="${on_sec}"
                OFF_SEC="${off_sec}"
                ON_WORKERS="${on_workers}"
                ON_METHOD="${on_method}"
                OFF_MODE="${off_mode}"
                OFF_WORKERS="${off_workers}"
                OFF_METHOD="${off_method}"

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then
                    break
                  fi

                  # ON segment
                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    if [ "\$ON_WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$ON_WORKERS" --cpu-method "\$ON_METHOD" --timeout "\${run_on}s" --metrics-brief
                    else
                      sleep "\$run_on"
                    fi
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then
                    break
                  fi

                  # OFF segment
                  run_off="\$OFF_SEC"
                  if [ "\$run_off" -gt "\$rem" ]; then run_off="\$rem"; fi
                  if [ "\$run_off" -gt 0 ]; then
                    if [ "\$OFF_MODE" = "stress" ] && [ "\$OFF_WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$OFF_WORKERS" --cpu-method "\$OFF_METHOD" --timeout "\${run_off}s" --metrics-brief
                    else
                      sleep "\$run_off"
                    fi
                  fi
                done

            resources:
              requests:
                cpu: "${cpu_req}m"
              limits:
                cpu: "${cpu_lim}m"
      EOF
                else
                  cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                SEED="${seed}"
                TOTAL="${total}"
                ON_SEC="${on_sec}"
                OFF_SEC="${off_sec}"
                ON_WORKERS="${on_workers}"
                ON_METHOD="${on_method}"
                OFF_MODE="${off_mode}"
                OFF_WORKERS="${off_workers}"
                OFF_METHOD="${off_method}"

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then
                    break
                  fi

                  # ON segment
                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    if [ "\$ON_WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$ON_WORKERS" --cpu-method "\$ON_METHOD" --timeout "\${run_on}s" --metrics-brief
                    else
                      sleep "\$run_on"
                    fi
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then
                    break
                  fi

                  # OFF segment
                  run_off="\$OFF_SEC"
                  if [ "\$run_off" -gt "\$rem" ]; then run_off="\$rem"; fi
                  if [ "\$run_off" -gt 0 ]; then
                    if [ "\$OFF_MODE" = "stress" ] && [ "\$OFF_WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$OFF_WORKERS" --cpu-method "\$OFF_METHOD" --timeout "\${run_off}s" --metrics-brief
                    else
                      sleep "\$run_off"
                    fi
                  fi
                done
            resources:
              requests:
                cpu: "${cpu_req}m"
      EOF
                fi

                k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
                deadline=$(( $(date +%s) + ${total} + ${TIMEOUT_SLACK_SEC} ))
                while :; do
                  now="$(date +%s)"
                  if [ "${now}" -gt "${deadline}" ]; then
                    phase_status="failed"
                    phase_exit_reason="timeout"
                    break
                  fi

                  st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                  if [ "${st}" = "Succeeded" ]; then
                    break
                  fi
                  if [ "${st}" = "Failed" ]; then
                    phase_status="failed"
                    phase_exit_reason="pod failed"
                    break
                  fi
                  sleep 1
                done

                kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
                if [ "${phase_status}" != "ok" ]; then
                  kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
                fi
                kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
              fi
            elif [ "${TEMPLATE}" = "stressng-cpu-jitter" ]; then
              total="$(echo "${PARAMS_JSON}" | sed -n 's/.*"total_duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              on_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              gmin="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gap_min_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              gmax="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gap_max_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              seed="$(echo "${PARAMS_JSON}" | sed -n 's/.*"seed"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

              workers="$(echo "${PARAMS_JSON}" | sed -n 's/.*"workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

              cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              cpu_lim="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_limit_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

              if [ -z "${seed}" ]; then seed=0; fi
              if [ -z "${gmin}" ]; then gmin=0; fi
              if [ -z "${gmax}" ]; then gmax="${gmin}"; fi
              if [ -z "${cpu_lim}" ]; then cpu_lim=0; fi

              if [ -z "${total}" ] || [ -z "${on_sec}" ] || [ -z "${workers}" ] || [ -z "${method}" ] || [ -z "${cpu_req}" ]; then
                phase_status="failed"
                phase_exit_reason="missing stressng-cpu-jitter params"
              else
                phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
                pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

                k8s_kind="Pod"
                k8s_name="${pod_name}"

                log "workload stressng-cpu-jitter total=${total}s on=${on_sec}s gap=[${gmin},${gmax}] seed=${seed} workers=${workers} method=${method} cpu_request=${cpu_req}m cpu_limit=${cpu_lim}m pod=${pod_name}"

                # limits optional (cpu_lim=0 => omit)
                if [ "${cpu_lim}" -gt 0 ]; then
                  cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                TOTAL="${total}"
                ON_SEC="${on_sec}"
                GAP_MIN="${gmin}"
                GAP_MAX="${gmax}"
                STATE="${seed}"
                WORKERS="${workers}"
                METHOD="${method}"

                # LCG PRNG for /bin/sh (deterministic)
                # state = (1103515245*state + 12345) mod 2^31
                next_u31() {
                  STATE=\$(( (1103515245 * STATE + 12345) % 2147483648 ))
                  echo "\$STATE"
                }

                rand_gap() {
                  if [ "\$GAP_MAX" -le "\$GAP_MIN" ]; then
                    echo "\$GAP_MIN"
                    return
                  fi
                  span=\$(( GAP_MAX - GAP_MIN + 1 ))
                  r="\$(next_u31)"
                  echo \$(( GAP_MIN + (r % span) ))
                }

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    if [ "\$WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$WORKERS" --cpu-method "\$METHOD" --timeout "\${run_on}s" --metrics-brief
                    else
                      sleep "\$run_on"
                    fi
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  gap="\$(rand_gap)"
                  if [ "\$gap" -gt "\$rem" ]; then gap="\$rem"; fi
                  if [ "\$gap" -gt 0 ]; then
                    sleep "\$gap"
                  fi
                done
            resources:
              requests:
                cpu: "${cpu_req}m"
              limits:
                cpu: "${cpu_lim}m"
      EOF
                else
                  cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                TOTAL="${total}"
                ON_SEC="${on_sec}"
                GAP_MIN="${gmin}"
                GAP_MAX="${gmax}"
                STATE="${seed}"
                WORKERS="${workers}"
                METHOD="${method}"

                next_u31() {
                  STATE=\$(( (1103515245 * STATE + 12345) % 2147483648 ))
                  echo "\$STATE"
                }

                rand_gap() {
                  if [ "\$GAP_MAX" -le "\$GAP_MIN" ]; then
                    echo "\$GAP_MIN"
                    return
                  fi
                  span=\$(( GAP_MAX - GAP_MIN + 1 ))
                  r="\$(next_u31)"
                  echo \$(( GAP_MIN + (r % span) ))
                }

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    if [ "\$WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$WORKERS" --cpu-method "\$METHOD" --timeout "\${run_on}s" --metrics-brief
                    else
                      sleep "\$run_on"
                    fi
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  gap="\$(rand_gap)"
                  if [ "\$gap" -gt "\$rem" ]; then gap="\$rem"; fi
                  if [ "\$gap" -gt 0 ]; then
                    sleep "\$gap"
                  fi
                done
            resources:
              requests:
                cpu: "${cpu_req}m"
      EOF
                fi

                k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
                deadline=$(( $(date +%s) + ${total} + ${TIMEOUT_SLACK_SEC} ))
                while :; do
                  now="$(date +%s)"
                  if [ "${now}" -gt "${deadline}" ]; then
                    phase_status="failed"
                    phase_exit_reason="timeout"
                    break
                  fi
                  st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                  if [ "${st}" = "Succeeded" ]; then break; fi
                  if [ "${st}" = "Failed" ]; then phase_status="failed"; phase_exit_reason="pod failed"; break; fi
                  sleep 1
                done

                kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
                if [ "${phase_status}" != "ok" ]; then
                  kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
                fi
                kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
              fi




              
            elif [ "${TEMPLATE}" = "gpu-burn-steady" ]; then
              dur="$(echo "${PARAMS_JSON}" | sed -n 's/.*"duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              gcount="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_request_count"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              img="$(echo "${PARAMS_JSON}" | sed -n 's/.*"image"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
              cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              cpu_lim="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_limit_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              runtime_class="$(echo "${PARAMS_JSON}" | sed -n 's/.*"runtime_class"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

              mem_mb="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_mem_mb"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              mem_pct="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_mem_pct"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              use_doubles_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_use_doubles"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"
              use_tc_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_use_tensor_cores"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"
              gpu_index="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_gpu_index"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              list_gpus_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_list_gpus"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"

              if [ -z "${gcount}" ]; then gcount=1; fi
              if [ -z "${cpu_req}" ]; then cpu_req=0; fi
              if [ -z "${cpu_lim}" ]; then cpu_lim=0; fi
              if [ -z "${img}" ]; then img="${GPU_BURN_IMAGE}"; fi
              if [ -z "${runtime_class}" ]; then runtime_class="${GPU_RUNTIME_CLASS_DEFAULT}"; fi

              use_doubles="false"
              use_tc="false"
              list_gpus="false"
              if [ "${use_doubles_raw}" = "true" ] || [ "${use_doubles_raw}" = "1" ]; then use_doubles="true"; fi
              if [ "${use_tc_raw}" = "true" ] || [ "${use_tc_raw}" = "1" ]; then use_tc="true"; fi
              if [ "${list_gpus_raw}" = "true" ] || [ "${list_gpus_raw}" = "1" ]; then list_gpus="true"; fi

              if [ -z "${dur}" ] || [ -z "${img}" ] || [ "${gcount}" -lt 1 ]; then
                phase_status="failed"
                phase_exit_reason="missing gpu-burn-steady params"
              else
                phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
                pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

                k8s_kind="Pod"
                k8s_name="${pod_name}"

                log "workload gpu-burn-steady dur=${dur}s gpus=${gcount} image=${img} runtimeClass=${runtime_class} mem_mb=${mem_mb:-} mem_pct=${mem_pct:-} doubles=${use_doubles} tc=${use_tc} gpu_index=${gpu_index:-} list_gpus=${list_gpus} cpu_request=${cpu_req}m cpu_limit=${cpu_lim}m pod=${pod_name}"

                cpu_req_yaml=""
                cpu_lim_yaml=""
                if [ "${cpu_req}" -gt 0 ]; then cpu_req_yaml="cpu: \"${cpu_req}m\""; fi
                if [ "${cpu_lim}" -gt 0 ]; then cpu_lim_yaml="cpu: \"${cpu_lim}m\""; fi

                cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        runtimeClassName: "${runtime_class}"
        containers:
          - name: gpuburn
            image: "${img}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu

                DUR="${dur}"
                USE_DOUBLES="${use_doubles}"
                USE_TC="${use_tc}"
                LIST_GPUS="${list_gpus}"
                GPU_INDEX="${gpu_index:-}"
                MEM_MB="${mem_mb:-}"
                MEM_PCT="${mem_pct:-}"

                # Resolve gpu-burn binary.
                GPU_BURN_BIN=""
                if command -v gpu_burn >/dev/null 2>&1; then
                  GPU_BURN_BIN="gpu_burn"
                elif command -v gpu-burn >/dev/null 2>&1; then
                  GPU_BURN_BIN="gpu-burn"
                elif [ -x "/app/gpu_burn" ]; then
                  GPU_BURN_BIN="/app/gpu_burn"
                else
                  echo "gpu-burn binary not found (expected gpu_burn, gpu-burn, or /app/gpu_burn)"
                  exit 2
                fi

                # Build argv safely without eval.
                # FLAGS_STR is for logging only.
                FLAGS_STR=""
                set --

                if [ -n "\${MEM_MB:-}" ] && [ "\${MEM_MB:-0}" -gt 0 ] 2>/dev/null; then
                  set -- "\$@" -m "\${MEM_MB}"
                  FLAGS_STR="\${FLAGS_STR} -m \${MEM_MB}"
                elif [ -n "\${MEM_PCT:-}" ] && [ "\${MEM_PCT:-0}" -gt 0 ] 2>/dev/null; then
                  set -- "\$@" -m "\${MEM_PCT}%"
                  FLAGS_STR="\${FLAGS_STR} -m \${MEM_PCT}%"
                fi

                if [ "\${USE_DOUBLES}" = "true" ]; then
                  set -- "\$@" -d
                  FLAGS_STR="\${FLAGS_STR} -d"
                fi

                if [ "\${USE_TC}" = "true" ]; then
                  set -- "\$@" -tc
                  FLAGS_STR="\${FLAGS_STR} -tc"
                fi

                if [ -n "\${GPU_INDEX:-}" ]; then
                  set -- "\$@" -i "\${GPU_INDEX}"
                  FLAGS_STR="\${FLAGS_STR} -i \${GPU_INDEX}"
                fi

                if [ "\${LIST_GPUS}" = "true" ]; then
                  echo "[gpu-burn] \${GPU_BURN_BIN} -l"
                  "\${GPU_BURN_BIN}" -l || true
                  echo
                fi

                nvidia-smi -L || true

                echo "[gpu-burn] running: \${GPU_BURN_BIN}\${FLAGS_STR} \${DUR}"
                "\${GPU_BURN_BIN}" "\$@" "\${DUR}"


            resources:
              requests:
                nvidia.com/gpu: "${gcount}"
                ${cpu_req_yaml}
              limits:
                nvidia.com/gpu: "${gcount}"
                ${cpu_lim_yaml}
      EOF

                k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
                deadline=$(( $(date +%s) + dur + TIMEOUT_SLACK_SEC ))
                while :; do
                  now="$(date +%s)"
                  if [ "${now}" -gt "${deadline}" ]; then
                    phase_status="failed"
                    phase_exit_reason="timeout"
                    break
                  fi

                  st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                  if [ "${st}" = "Succeeded" ]; then
                    break
                  fi
                  if [ "${st}" = "Failed" ]; then
                    phase_status="failed"
                    phase_exit_reason="pod failed"
                    break
                  fi
                  sleep 1
                done

                kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
                if [ "${phase_status}" != "ok" ]; then
                  kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
                fi
                kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
              fi




            elif [ "${TEMPLATE}" = "gpu-burn-burst" ]; then
              total="$(echo "${PARAMS_JSON}" | sed -n 's/.*"total_duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              on_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              off_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              gcount="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_request_count"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              img="$(echo "${PARAMS_JSON}" | sed -n 's/.*"image"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
              cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              cpu_lim="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_limit_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              runtime_class="$(echo "${PARAMS_JSON}" | sed -n 's/.*"runtime_class"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

              mem_mb="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_mem_mb"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              mem_pct="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_mem_pct"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              use_doubles_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_use_doubles"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"
              use_tc_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_use_tensor_cores"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"
              gpu_index="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_gpu_index"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              list_gpus_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_list_gpus"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"

              if [ -z "${gcount}" ]; then gcount=1; fi
              if [ -z "${off_sec}" ]; then off_sec=0; fi
              if [ -z "${cpu_req}" ]; then cpu_req=0; fi
              if [ -z "${cpu_lim}" ]; then cpu_lim=0; fi
              if [ -z "${img}" ]; then img="${GPU_BURN_IMAGE}"; fi
              if [ -z "${runtime_class}" ]; then runtime_class="${GPU_RUNTIME_CLASS_DEFAULT}"; fi

              use_doubles="false"
              use_tc="false"
              list_gpus="false"
              if [ "${use_doubles_raw}" = "true" ] || [ "${use_doubles_raw}" = "1" ]; then use_doubles="true"; fi
              if [ "${use_tc_raw}" = "true" ] || [ "${use_tc_raw}" = "1" ]; then use_tc="true"; fi
              if [ "${list_gpus_raw}" = "true" ] || [ "${list_gpus_raw}" = "1" ]; then list_gpus="true"; fi

              if [ -z "${total}" ] || [ -z "${on_sec}" ] || [ -z "${img}" ] || [ "${gcount}" -lt 1 ]; then
                phase_status="failed"
                phase_exit_reason="missing gpu-burn-burst params"
              else
                phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
                pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

                k8s_kind="Pod"
                k8s_name="${pod_name}"

                log "workload gpu-burn-burst total=${total}s on=${on_sec}s off=${off_sec}s gpus=${gcount} image=${img} runtimeClass=${runtime_class} mem_mb=${mem_mb:-} mem_pct=${mem_pct:-} doubles=${use_doubles} tc=${use_tc} gpu_index=${gpu_index:-} list_gpus=${list_gpus} cpu_request=${cpu_req}m cpu_limit=${cpu_lim}m pod=${pod_name}"

                cpu_req_yaml=""
                cpu_lim_yaml=""
                if [ "${cpu_req}" -gt 0 ]; then cpu_req_yaml="cpu: \"${cpu_req}m\""; fi
                if [ "${cpu_lim}" -gt 0 ]; then cpu_lim_yaml="cpu: \"${cpu_lim}m\""; fi

                cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        runtimeClassName: "${runtime_class}"
        containers:
          - name: gpuburn
            image: "${img}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu

                TOTAL="${total}"
                ON_SEC="${on_sec}"
                OFF_SEC="${off_sec}"

                USE_DOUBLES="${use_doubles}"
                USE_TC="${use_tc}"
                LIST_GPUS="${list_gpus}"
                GPU_INDEX="${gpu_index:-}"
                MEM_MB="${mem_mb:-}"
                MEM_PCT="${mem_pct:-}"

                # Resolve gpu-burn binary.
                GPU_BURN_BIN=""
                if command -v gpu_burn >/dev/null 2>&1; then
                  GPU_BURN_BIN="gpu_burn"
                elif command -v gpu-burn >/dev/null 2>&1; then
                  GPU_BURN_BIN="gpu-burn"
                elif [ -x "/app/gpu_burn" ]; then
                  GPU_BURN_BIN="/app/gpu_burn"
                else
                  echo "gpu-burn binary not found (expected gpu_burn, gpu-burn, or /app/gpu_burn)"
                  exit 2
                fi

                # Build argv safely without eval.
                FLAGS_STR=""
                set --

                if [ -n "\${MEM_MB:-}" ] && [ "\${MEM_MB:-0}" -gt 0 ] 2>/dev/null; then
                  set -- "\$@" -m "\${MEM_MB}"
                  FLAGS_STR="\${FLAGS_STR} -m \${MEM_MB}"
                elif [ -n "\${MEM_PCT:-}" ] && [ "\${MEM_PCT:-0}" -gt 0 ] 2>/dev/null; then
                  set -- "\$@" -m "\${MEM_PCT}%"
                  FLAGS_STR="\${FLAGS_STR} -m \${MEM_PCT}%"
                fi

                if [ "\${USE_DOUBLES}" = "true" ]; then
                  set -- "\$@" -d
                  FLAGS_STR="\${FLAGS_STR} -d"
                fi

                if [ "\${USE_TC}" = "true" ]; then
                  set -- "\$@" -tc
                  FLAGS_STR="\${FLAGS_STR} -tc"
                fi

                if [ -n "\${GPU_INDEX:-}" ]; then
                  set -- "\$@" -i "\${GPU_INDEX}"
                  FLAGS_STR="\${FLAGS_STR} -i \${GPU_INDEX}"
                fi

                if [ "\${LIST_GPUS}" = "true" ]; then
                  echo "[gpu-burn] \${GPU_BURN_BIN} -l"
                  "\${GPU_BURN_BIN}" -l || true
                  echo
                fi

                nvidia-smi -L || true

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    echo "[gpu-burn] running: \${GPU_BURN_BIN}\${FLAGS_STR} \${run_on}"
                    "\${GPU_BURN_BIN}" "\$@" "\${run_on}"
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  run_off="\$OFF_SEC"
                  if [ "\$run_off" -gt "\$rem" ]; then run_off="\$rem"; fi
                  if [ "\$run_off" -gt 0 ]; then
                    sleep "\$run_off"
                  fi
                done
            resources:
              requests:
                nvidia.com/gpu: "${gcount}"
                ${cpu_req_yaml}
              limits:
                nvidia.com/gpu: "${gcount}"
                ${cpu_lim_yaml}
      EOF

                k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
                deadline=$(( $(date +%s) + total + TIMEOUT_SLACK_SEC ))
                while :; do
                  now="$(date +%s)"
                  if [ "${now}" -gt "${deadline}" ]; then
                    phase_status="failed"
                    phase_exit_reason="timeout"
                    break
                  fi

                  st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                  if [ "${st}" = "Succeeded" ]; then
                    break
                  fi
                  if [ "${st}" = "Failed" ]; then
                    phase_status="failed"
                    phase_exit_reason="pod failed"
                    break
                  fi
                  sleep 1
                done

                kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
                if [ "${phase_status}" != "ok" ]; then
                  kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
                fi
                kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
              fi










            else
              log "unknown workload template: raw='${TEMPLATE}'"
              phase_status="failed"
              phase_exit_reason="unknown workload template"
            fi
          else
            phase_status="failed"
            phase_exit_reason="unknown phase type"
          fi

          PHASE_END="$(utc_now)"
          log "phase '${PHASE_NAME}' end_utc=${PHASE_END} status=${phase_status}"

          # append phase entry JSON (additive schema)
          # Note: PARAMS_JSON is already JSON text for workload and ramp/sleep (ansible-generated)
          entry_file="${OUT_DIR}/phase_entry_${PHASE_NAME}.json.tmp"
          cat > "${entry_file}" <<EOF
      {
        "name": "$(printf '%s' "${PHASE_NAME}" | sed 's/"/\\"/g')",
        "type": "$(printf '%s' "${PHASE_TYPE}" | sed 's/"/\\"/g')",
        "start_utc": "${PHASE_START}",
        "end_utc": "${PHASE_END}",
        "planned_duration_sec": ${PLANNED_DUR},
        "workload": {
          "template": "$(printf '%s' "${TEMPLATE}" | sed 's/"/\\"/g')",
          "params": ${PARAMS_JSON}
        },
        "k8s": {
          "resource_kind": "$(printf '%s' "${k8s_kind}" | sed 's/"/\\"/g')",
          "resource_name": "$(printf '%s' "${k8s_name}" | sed 's/"/\\"/g')",
          "uid": "$(printf '%s' "${k8s_uid}" | sed 's/"/\\"/g')",
          "node": "$(printf '%s' "${k8s_node}" | sed 's/"/\\"/g')"
        },
        "result": {
          "status": "$(printf '%s' "${phase_status}" | sed 's/"/\\"/g')",
          "exit_reason": "$(printf '%s' "${phase_exit_reason}" | sed 's/"/\\"/g')"
        }
      }
      EOF

          if [ "${first_phase}" -eq 1 ]; then
            cat "${entry_file}" >> "${PHASES_BODY_FILE}"
            first_phase=0
          else
            printf ",\n" >> "${PHASES_BODY_FILE}"
            cat "${entry_file}" >> "${PHASES_BODY_FILE}"
          fi
          rm -f "${entry_file}"

          if [ "${phase_status}" != "ok" ]; then
            # fail fast: write run.json then exit non-zero
            RUN_END="$(utc_now)"
            log "rep=${rep} failed, run_end_utc=${RUN_END}"

            phases_json="${OUT_DIR}/phases.json.tmp"
            {
              printf "[\n"
              cat "${PHASES_BODY_FILE}"
              printf "\n]\n"
            } > "${phases_json}"

            run_json_tmp="${OUT_DIR}/run_compose.json.tmp"
            cat > "${run_json_tmp}" <<EOF
      {
        "apiVersion": "tycho.testing/v1",
        "kind": "RunRecord",
        "plan_id": "${PLAN_ID}",
        "namespace": "${NAMESPACE}",
        "rep": ${rep},
        "run_start_utc": "${RUN_START}",
        "run_end_utc": "${RUN_END}",
        "phases": $(cat "${phases_json}")
      }
      EOF

            write_atomic_json "${OUT_DIR}/run.json" "${run_json_tmp}"
            cp "${OUT_DIR}/run.json" "${OUT_DIR}/run_${SAFE_TS}.json" || true
            cp "${EVENTS_LOG}" "${OUT_DIR}/events_${SAFE_TS}.log" || true
            die "rep=${rep} failed in phase '${PHASE_NAME}'"
          fi

        done < /plan/runner_phases.psv

        RUN_END="$(utc_now)"
        log "rep=${rep} complete run_end_utc=${RUN_END}"

        phases_json="${OUT_DIR}/phases.json.tmp"
        {
          printf "[\n"
          cat "${PHASES_BODY_FILE}"
          printf "\n]\n"
        } > "${phases_json}"

        run_json_tmp="${OUT_DIR}/run_compose.json.tmp"
        cat > "${run_json_tmp}" <<EOF
      {
        "apiVersion": "tycho.testing/v1",
        "kind": "RunRecord",
        "plan_id": "${PLAN_ID}",
        "namespace": "${NAMESPACE}",
        "rep": ${rep},
        "run_start_utc": "${RUN_START}",
        "run_end_utc": "${RUN_END}",
        "phases": $(cat "${phases_json}")
      }
      EOF

        write_atomic_json "${OUT_DIR}/run.json" "${run_json_tmp}"
        cp "${OUT_DIR}/run.json" "${OUT_DIR}/run_${SAFE_TS}.json" || true
        cp "${EVENTS_LOG}" "${OUT_DIR}/events_${SAFE_TS}.log" || true

        # cleanup temps
        rm -f "${PHASES_BODY_FILE}" "${phases_json}" "${run_json_tmp}" || true

        log "rep=${rep} wrote: ${OUT_DIR}/run.json"
        log "rep=${rep} also:  ${OUT_DIR}/run_${SAFE_TS}.json"
        log "rep=${rep} done"

        rep=$(( rep + 1 ))
      done

      log "all repetitions complete"
      exit 0

- name: Build workload_yaml_map for ConfigMap (runner assets are additive)
  set_fact:
    workload_yaml_map:
      runner.sh: "{{ runner_sh }}"
      runner_meta.env: "{{ runner_meta_env }}"
      runner_phases.psv: "{{ runner_phases_psv }}"
      

# NOTE:
# We intentionally do NOT SSH to the NFS server from this role.
# This keeps testing-ansible "localhost only" and avoids SSH auth issues.
# Ensure the NFS directory exists separately (one-time) if your NFS server requires it.

# ---------------------------
# Render manifests
# ---------------------------

- name: Render Namespace manifest
  set_fact:
    ns_manifest: "{{ lookup('template', 'namespace.yaml.j2') }}"

- name: Render ServiceAccount manifest
  set_fact:
    sa_manifest: "{{ lookup('template', 'serviceaccount.yaml.j2') }}"

- name: Render Role manifest
  set_fact:
    role_manifest: "{{ lookup('template', 'role.yaml.j2') }}"

- name: Render RoleBinding manifest
  set_fact:
    rb_manifest: "{{ lookup('template', 'rolebinding.yaml.j2') }}"

- name: Render Plan ConfigMap manifest
  set_fact:
    cm_manifest: "{{ lookup('template', 'plan-configmap.yaml.j2') }}"

- name: Render PV manifest
  set_fact:
    pv_manifest: "{{ lookup('template', 'pv.yaml.j2') }}"

- name: Render PVC manifest
  set_fact:
    pvc_manifest: "{{ lookup('template', 'pvc.yaml.j2') }}"

- name: Render kubectl Job manifest
  set_fact:
    job_manifest: "{{ lookup('template', 'kubectl-job.yaml.j2') }}"

# ---------------------------
# Apply manifests via kubectl
# ---------------------------

- name: Create temp dir for rendered manifests
  tempfile:
    state: directory
    suffix: tycho-testing
  register: tmpdir

- name: Write rendered manifests to files
  copy:
    dest: "{{ tmpdir.path }}/{{ item.name }}"
    content: "{{ item.content }}"
    mode: "0600"
  loop:
    - { name: "00-namespace.yaml",      content: "{{ ns_manifest }}" }
    - { name: "10-serviceaccount.yaml", content: "{{ sa_manifest }}" }
    - { name: "20-role.yaml",           content: "{{ role_manifest }}" }
    - { name: "30-rolebinding.yaml",    content: "{{ rb_manifest }}" }
    - { name: "40-configmap.yaml",      content: "{{ cm_manifest }}" }
    - { name: "50-pv.yaml",             content: "{{ pv_manifest }}" }
    - { name: "60-pvc.yaml",            content: "{{ pvc_manifest }}" }
    - { name: "70-job.yaml",            content: "{{ job_manifest }}" }

- name: Apply all manifests
  ansible.builtin.shell:
    cmd: |
      set -euo pipefail

      ns="{{ plan_ns }}"
      pvc="{{ tycho_testing_pvc_name }}"
      pv="{{ tycho_testing_pv_name }}"
      job="tycho-plan-{{ tycho_test_plan_id }}"

      K="kubectl --request-timeout=20s"

      $K apply -f "{{ tmpdir.path }}/00-namespace.yaml"
      $K apply -f "{{ tmpdir.path }}/10-serviceaccount.yaml"
      $K apply -f "{{ tmpdir.path }}/20-role.yaml"
      $K apply -f "{{ tmpdir.path }}/30-rolebinding.yaml"
      $K apply -f "{{ tmpdir.path }}/40-configmap.yaml"

      # PV is cluster-scoped; idempotent apply
      $K apply -f "{{ tmpdir.path }}/50-pv.yaml"

      # Always ensure the previous job/pods are gone (fast, non-blocking)
      $K -n "${ns}" delete job "${job}" --ignore-not-found=true --wait=false || true
      $K -n "${ns}" delete pod -l "app=tycho-testing,tycho_plan_id={{ tycho_test_plan_id }}" --ignore-not-found=true --wait=false || true
      $K -n "${ns}" delete pod -l "tycho.testing/plan_id={{ tycho_test_plan_id }}" --ignore-not-found=true --wait=false || true

      if [ "{{ tycho_testing_reset | default(false) | bool }}" = "True" ]; then
        echo "[tycho-testing][reset] enabled: recycling PVC and clearing PV claimRef"

        # Bounded wait: ensure no pod is still referencing the PVC (best-effort)
        for i in $(seq 1 30); do
          # list podName|claimNames...
          if $K -n "${ns}" get pod -o jsonpath='{range .items[*]}{.metadata.name}{"|"}{range .spec.volumes[*]}{.persistentVolumeClaim.claimName}{" "}{end}{"\n"}{end}' 2>/dev/null \
            | grep -Eq "\|.*\b${pvc}\b"; then
            sleep 1
          else
            break
          fi
        done

        # Delete PVC (do not wait forever)
        $K -n "${ns}" delete pvc "${pvc}" --ignore-not-found=true --wait=false || true

        # Bounded wait until PVC is actually gone
        for i in $(seq 1 60); do
          if $K -n "${ns}" get pvc "${pvc}" >/dev/null 2>&1; then
            sleep 1
          else
            break
          fi
        done

        # IMPORTANT: PV reclaimPolicy=Retain => PV will be Released with old claimRef.
        # Clear claimRef so the new PVC can bind to the existing PV.
        # (Safe even if claimRef is already empty.)
        $K patch pv "${pv}" --type=merge -p '{"spec":{"claimRef":null}}' >/dev/null 2>&1 || true

      else
        echo "[tycho-testing] normal run: keeping existing PVC (no delete)"
      fi

      # Ensure PVC exists (idempotent apply). If it already exists, this is a no-op.
      $K apply -f "{{ tmpdir.path }}/60-pvc.yaml"

      # Bounded wait for PVC to become Bound (helpful before starting the job)
      for i in $(seq 1 60); do
        phase="$($K -n "${ns}" get pvc "${pvc}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
        if [ "${phase}" = "Bound" ]; then
          break
        fi
        sleep 1
      done

      # Recreate job
      $K apply -f "{{ tmpdir.path }}/70-job.yaml"
    executable: /bin/bash
  register: apply_all


- name: Show kubectl apply output
  debug:
    var: apply_all.stdout_lines

- name: Show PVC status
  shell: |
    set -euo pipefail
    kubectl -n {{ plan_ns }} get pvc {{ tycho_testing_pvc_name }} -o wide
  args:
    executable: /bin/bash
  register: pvc_status
  changed_when: false

- name: Print next commands
  debug:
    msg:
      - "PVC status:\n{{ pvc_status.stdout }}"
      - "Job logs: kubectl -n {{ plan_ns }} logs job/tycho-plan-{{ tycho_test_plan_id }} --tail=200"
      - "If the job fails to write, create the NFS dir: {{ tycho_testing_nfs_export_path }}/{{ tycho_testing_nfs_subdir }} on {{ tycho_testing_nfs_server }}"
