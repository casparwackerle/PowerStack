# FILE: playbooks/roles/tycho_testing/tasks/main.yml

- name: Resolve plan file path
  set_fact:
    plan_path: "{{ tycho_test_plan_root }}/{{ tycho_test_plan_id }}.yaml"

- name: Load plan YAML file (raw)
  set_fact:
    plan_yaml: "{{ lookup('file', plan_path) }}"

- name: Parse plan YAML
  set_fact:
    plan_obj: "{{ plan_yaml | from_yaml }}"

- name: Fail fast on apiVersion/kind mismatch
  fail:
    msg: "Invalid plan header: expected apiVersion tycho.testing/v1 and kind TestPlan"
  when: plan_obj.apiVersion != 'tycho.testing/v1' or plan_obj.kind != 'TestPlan'

- name: Fail fast if metadata.plan_id mismatches selected plan id
  fail:
    msg: "Plan ID mismatch: file selected={{ tycho_test_plan_id }}, metadata.plan_id={{ plan_obj.metadata.plan_id | default('MISSING') }}"
  when: (plan_obj.metadata.plan_id | default('')) != tycho_test_plan_id

- name: Extract phases list
  set_fact:
    plan_phases: "{{ plan_obj.spec.phases | default([]) }}"

- name: Fail fast if phases missing or empty
  fail:
    msg: "spec.phases must be a non-empty list"
  when: plan_phases | length == 0

- name: Fail fast if any phase name missing
  fail:
    msg: "Every phase must have a non-empty 'name'"
  loop: "{{ plan_phases }}"
  when: (item.name | default('') | length) == 0

- name: Fail fast on unknown phase types
  fail:
    msg: "Unknown phase type '{{ item.type | default('MISSING') }}' in phase '{{ item.name }}' (allowed: sleep, workload, workload_set)"
  loop: "{{ plan_phases }}"
  when: (item.type | default('')) not in ['sleep','workload','workload_set','ramp']

- name: Fail fast if sleep phase missing duration_sec
  fail:
    msg: "Phase '{{ item.name }}' type=sleep requires duration_sec"
  loop: "{{ plan_phases }}"
  when: (item.type == 'sleep') and ((item.duration_sec | default(0) | int) <= 0)

- name: Fail fast if ramp phase missing duration_sec or ramp_profile
  fail:
    msg: "Phase '{{ item.name }}' type=ramp requires duration_sec and ramp_profile"
  loop: "{{ plan_phases }}"
  when: (item.type == 'ramp') and (((item.duration_sec | default(0) | int) <= 0) or ((item.ramp_profile | default('') | length) == 0))

- name: Fail fast if workload phase missing workload.template
  fail:
    msg: "Phase '{{ item.name }}' type=workload requires workload.template"
  loop: "{{ plan_phases }}"
  when: (item.type == 'workload') and (((item.workload | default({})).template | default('') | length) == 0)


# -------------------------
# Slice 6: workload_set structural validation
# -------------------------

# Slice 6: Fail fast if workload_set missing workloads or workloads entries invalid
- name: Fail fast if workload_set phase missing workloads[]
  fail:
    msg: "Phase '{{ item.name }}' type=workload_set requires a non-empty workloads[] list"
  loop: "{{ plan_phases }}"
  when: >
    (item.type == 'workload_set') and
    (
      ((item.workloads | default([])) | length) == 0
    )

- name: Fail fast if workload_set entries missing name/template/params
  fail:
    msg: "workload_set phase '{{ sub.0.name }}' has invalid entry: requires name, template, params"
  loop: "{{ plan_phases | selectattr('type','equalto','workload_set') | list | subelements('workloads', skip_missing=True) }}"
  loop_control:
    loop_var: sub
  when: >
    ((sub.1.name | default('') | length) == 0) or
    ((sub.1.template | default('') | length) == 0) or
    ((sub.1.params | default({})) == {})


    


# -------------------------
# Template allowlist (Slice 2 minimum set)
# -------------------------

- name: Fail fast on unknown workload templates (Slice 2 minimum set)
  fail:
    msg: "Unknown workload template '{{ (item.workload.template | default('MISSING')) }}' in phase '{{ item.name }}' (allowed: noop-sleep, sleep, ramp, stressng-cpu, stressng-cpu-burst, stressng-cpu-jitter, gpu-burn-steady, gpu-burn-burst)"
  loop: "{{ plan_phases }}"
  when: >
    (item.type == 'workload') and
    ((item.workload.template | default('')) not in
      ['sleep','noop-sleep','stressng-cpu','ramp','stressng-cpu-burst','stressng-cpu-jitter','gpu-burn-steady','gpu-burn-burst'])

- name: Fail fast on unknown templates inside workload_set
  fail:
    msg: "Unknown workload template '{{ (sub.1.template | default('MISSING')) }}' in workload_set phase '{{ sub.0.name }}' (allowed: noop-sleep, sleep, ramp, stressng-cpu, stressng-cpu-burst, stressng-cpu-jitter, gpu-burn-steady, gpu-burn-burst)"
  loop: "{{ plan_phases | selectattr('type','equalto','workload_set') | list | subelements('workloads', skip_missing=True) }}"
  loop_control:
    loop_var: sub
  when: >
    ((sub.1.template | default('')) not in
      ['sleep','noop-sleep','stressng-cpu','ramp','stressng-cpu-burst','stressng-cpu-jitter','gpu-burn-steady','gpu-burn-burst'])


# - name: Fail fast on unknown workload templates (Slice 2 minimum set)
#   fail:
#     msg: "Unknown workload template '{{ (item.workload.template | default('MISSING')) }}' in phase '{{ item.name }}' (allowed: noop-sleep, stressng-cpu, stressng-cpu-burst, stressng-cpu-jitter, gpu-burn-steady', gpu-burn-burst)"
#   loop: "{{ plan_phases }}"
#   when: (item.type == 'workload') and ((item.workload.template | default('')) not in ['noop-sleep','stressng-cpu','stressng-cpu-burst','stressng-cpu-jitter','gpu-burn-steady','gpu-burn-burst'])

# Validate stressng-cpu params (minimum set)
- name: Fail fast if stressng-cpu missing required params
  fail:
    msg: "Phase '{{ item.name }}' stressng-cpu requires params: duration_sec (>0), workers (>0), method (non-empty), cpu_request_mcpu (>0)"
  loop: "{{ plan_phases }}"
  when: >
    (item.type == 'workload') and
    ((item.workload.template | default('')) == 'stressng-cpu') and
    (
      ((item.workload.params.duration_sec | default(0) | int) <= 0) or
      ((item.workload.params.workers | default(0) | int) <= 0) or
      ((item.workload.params.method | default('') | length) == 0) or
      ((item.workload.params.cpu_request_mcpu | default(0) | int) <= 0)
    )

# Validate stressng-cpu-burst params (minimum set)
- name: Fail fast if stressng-cpu-burst missing required params
  fail:
    msg: >-
      Phase '{{ item.name }}' stressng-cpu-burst requires params:
      total_duration_sec (>0), on_sec (>0), off_sec (>0), seed (>=0),
      on_workers (>=0), on_method (non-empty),
      off_mode (sleep|stress),
      off_workers (>=0 when off_mode=stress), off_method (non-empty when off_mode=stress),
      cpu_request_mcpu (>0), cpu_limit_mcpu (>=0, 0 means unset)
  loop: "{{ plan_phases }}"
  when: >
    (item.type == 'workload') and
    ((item.workload.template | default('')) == 'stressng-cpu-burst') and
    (
      ((item.workload.params.total_duration_sec | default(0) | int) <= 0) or
      ((item.workload.params.on_sec | default(0) | int) <= 0) or
      ((item.workload.params.off_sec | default(0) | int) <= 0) or
      ((item.workload.params.seed | default(-1) | int) < 0) or
      ((item.workload.params.on_workers | default(-1) | int) < 0) or
      ((item.workload.params.on_method | default('') | length) == 0) or
      ((item.workload.params.off_mode | default('') | length) == 0) or
      ((item.workload.params.off_mode | default('')) not in ['sleep','stress']) or
      (
        ((item.workload.params.off_mode | default('')) == 'stress') and
        (
          ((item.workload.params.off_workers | default(-1) | int) < 0) or
          ((item.workload.params.off_method | default('') | length) == 0)
        )
      ) or
      ((item.workload.params.cpu_request_mcpu | default(0) | int) <= 0) or
      ((item.workload.params.cpu_limit_mcpu | default(0) | int) < 0)
    )

- name: Fail fast if stressng-cpu-jitter missing required params
  fail:
    msg: >-
      Phase '{{ item.name }}' stressng-cpu-jitter requires params:
      total_duration_sec (>0), on_sec (>0),
      gap_min_sec (>=0), gap_max_sec (>=gap_min_sec),
      seed (>=0), workers (>=0), method (non-empty),
      cpu_request_mcpu (>0), cpu_limit_mcpu (>=0, 0 means unset)
  loop: "{{ plan_phases }}"
  when: >
    (item.type == 'workload') and
    ((item.workload.template | default('')) == 'stressng-cpu-jitter') and
    (
      ((item.workload.params.total_duration_sec | default(0) | int) <= 0) or
      ((item.workload.params.on_sec | default(0) | int) <= 0) or
      ((item.workload.params.gap_min_sec | default(-1) | int) < 0) or
      ((item.workload.params.gap_max_sec | default(-1) | int) < (item.workload.params.gap_min_sec | default(0) | int)) or
      ((item.workload.params.seed | default(-1) | int) < 0) or
      ((item.workload.params.workers | default(-1) | int) < 0) or
      ((item.workload.params.method | default('') | length) == 0) or
      ((item.workload.params.cpu_request_mcpu | default(0) | int) <= 0) or
      ((item.workload.params.cpu_limit_mcpu | default(0) | int) < 0)
    )
- name: Fail fast if gpu-burn-steady has invalid gpu_burn params
  fail:
    msg: >-
      Phase '{{ item.name }}' gpu-burn-steady: invalid gpu_burn params.
      gpu_burn_mem_mb and gpu_burn_mem_pct are mutually exclusive.
      gpu_burn_mem_pct must be 1..100.
      gpu_burn_gpu_index must be >= 0 if set.
  loop: "{{ plan_phases }}"
  when: >
    (item.type == 'workload') and
    ((item.workload.template | default('')) == 'gpu-burn-steady') and
    (
      (
        (item.workload.params.gpu_burn_mem_mb is defined) and
        (item.workload.params.gpu_burn_mem_pct is defined)
      ) or
      (
        (item.workload.params.gpu_burn_mem_pct is defined) and
        (
          (item.workload.params.gpu_burn_mem_pct | int) < 1 or
          (item.workload.params.gpu_burn_mem_pct | int) > 100
        )
      ) or
      (
        (item.workload.params.gpu_burn_gpu_index is defined) and
        ((item.workload.params.gpu_burn_gpu_index | int) < 0)
      )
    )

- name: Fail fast if gpu-burn-burst has invalid gpu_burn params
  fail:
    msg: >-
      Phase '{{ item.name }}' gpu-burn-burst: invalid gpu_burn params.
      gpu_burn_mem_mb and gpu_burn_mem_pct are mutually exclusive.
      gpu_burn_mem_pct must be 1..100.
      gpu_burn_gpu_index must be >= 0 if set.
  loop: "{{ plan_phases }}"
  when: >
    (item.type == 'workload') and
    ((item.workload.template | default('')) == 'gpu-burn-burst') and
    (
      (
        (item.workload.params.gpu_burn_mem_mb is defined) and
        (item.workload.params.gpu_burn_mem_pct is defined)
      ) or
      (
        (item.workload.params.gpu_burn_mem_pct is defined) and
        (
          (item.workload.params.gpu_burn_mem_pct | int) < 1 or
          (item.workload.params.gpu_burn_mem_pct | int) > 100
        )
      ) or
      (
        (item.workload.params.gpu_burn_gpu_index is defined) and
        ((item.workload.params.gpu_burn_gpu_index | int) < 0)
      )
    )

# -------------------------
# Derived plan target facts (namespace + node)
# -------------------------
- name: Derive plan target namespace and node
  set_fact:
    plan_ns: "{{ plan_obj.spec.target.namespace | default('') }}"
    plan_target_node: "{{ plan_obj.spec.target.node_name | default('') }}"

- name: Fail fast if spec.target.namespace missing
  fail:
    msg: "spec.target.namespace must be a non-empty string"
  when: (plan_ns | default('') | length) == 0

- name: Fail fast if spec.target.node_name missing
  fail:
    msg: "spec.target.node_name must be a non-empty string"
  when: (plan_target_node | default('') | length) == 0

- name: Derive repetition count
  set_fact:
    plan_rep_count: "{{ plan_obj.spec.repetitions.count | default(1) | int }}"

- name: Fail fast if repetitions.count invalid
  fail:
    msg: "spec.repetitions.count must be a positive integer (got {{ plan_rep_count }})"
  when: (plan_rep_count | int) < 1


# ---------------------------
# Slice 2: Build runner assets (stored in ConfigMap via workload_yaml_map)
# ---------------------------

- name: Build runner meta env (flat, shell-safe)
  set_fact:
    runner_meta_env: |
      PLAN_ID="{{ tycho_test_plan_id }}"
      NAMESPACE="{{ plan_ns }}"
      TARGET_NODE="{{ plan_target_node }}"
      REPETITIONS="{{ plan_rep_count }}"

      # ConfigMap that contains plan.yaml + runner assets (same object).
      PLAN_CONFIGMAP="{{ tycho_test_plan_configmap_name }}"

      # Where the PVC is mounted in the runner container (Job template mounts /out).
      OUT_MOUNT="/out"

      # stress-ng workload image (simple, prebuilt)
      STRESSNG_IMAGE="polinux/stress-ng:latest"

      # GPU burn workload image (override per plan via params.image if needed)
      GPU_BURN_IMAGE="oguzpastirmaci/gpu-burn:latest"

      # Default runtime class for GPU workloads (can be overridden per workload params.runtime_class)
      GPU_RUNTIME_CLASS_DEFAULT="nvidia"

      # Default timeout slack in seconds
      TIMEOUT_SLACK_SEC="60"

      # Needed by workload_set sub-runner job spawning
      TYCHO_PLAN_CONFIGMAP_NAME="{{ tycho_test_plan_configmap_name }}"
      TYCHO_OUT_PVC_NAME="{{ tycho_testing_pvc_name }}"

      # Optional ceiling for workload_set supervision (seconds)
      TYCHO_WORKLOAD_SET_CEILING_SEC="1200"

- name: Build phases PSV (pipe-separated, preserves empty safely)
  set_fact:
    runner_phases_psv: |
      {% for p in plan_phases -%}
      {{ p.name | trim }}|{{ p.type | trim }}|{{
        (p.duration_sec | default(0) | int)
        if (p.type in ['sleep','ramp'])
        else (
          (
            (
              (
                (
                  p.workloads | default([]) | map(attribute='params') | list
                )
              )
            )
            if (p.type == 'workload_set')
            else (
              (p.workload.params.total_duration_sec | default(0) | int)
              if ((p.workload.template | default('')) in ['stressng-cpu-burst','stressng-cpu-jitter','gpu-burn-burst'])
              else (p.workload.params.duration_sec | default(0) | int)
            )
          )
        )
      }}|{{
        (p.workload.template | default(''))
        if (p.type == 'workload')
        else (
          'workload_set'
          if (p.type == 'workload_set')
          else ('noop-sleep' if (p.type == 'sleep') else ('ramp-' ~ (p.ramp_profile | default(''))))
        )
      }}|{{
        (p.workload.params | default({}) | to_json)
        if (p.type == 'workload')
        else (
          ({ 'workloads': (p.workloads | default([])) } | to_json)
          if (p.type == 'workload_set')
          else (
            ({ 'duration_sec': (p.duration_sec | default(0) | int) } | to_json)
            if (p.type == 'sleep')
            else ({
              'ramp_profile': (p.ramp_profile | default('')),
              'duration_sec': (p.duration_sec | default(0) | int),
              'max_workers': (p.params.max_workers | default(0) | int),
              'step_count': (p.params.step_count | default(0) | int),
              'method': (p.params.method | default('')),
              'cpu_request_mcpu': (p.params.cpu_request_mcpu | default(0) | int)
            } | to_json)
          )
        )
      }}|{{
        'workload_set' if (p.type == 'workload_set') else
        'ramp' if (p.type == 'ramp') else
        'workload' if (p.type == 'workload') else
        'sleep'
      }}
      {% endfor -%}

- name: Build runner script (runner.sh)
  set_fact:
    runner_sh: |
      #!/bin/sh
      # FILE: runner.sh
      set -eu

      # -------------------------
      # Helpers
      # -------------------------

      log() {
        ts="$(date -u '+%Y-%m-%dT%H:%M:%SZ')"
        msg="$*"
        printf '%s %s\n' "${ts}" "${msg}" >&2
        if [ -n "${EVENTS_LOG:-}" ]; then
          printf '%s %s\n' "${ts}" "${msg}" >> "${EVENTS_LOG}" 2>/dev/null || true
        fi
      }

      die() {
        log "FATAL: $*"
        exit 1
      }

      utc_now() {
        date -u '+%Y-%m-%dT%H:%M:%SZ'
      }

      # sanitize to DNS-1123 label-ish: lowercase, keep [a-z0-9-], trim '-', cap 63 chars
      sanitize_k8s_name() {
        in="${1:-}"
        out="$(printf '%s' "${in}" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9-]/-/g; s/--*/-/g; s/^-//; s/-$//')"
        if [ -z "${out}" ]; then
          out="x"
        fi
        # K8s name max length is 63
        printf '%s' "${out}" | cut -c1-63
      }

      write_atomic_json() {
        dst="${1}"
        tmp="${2}"
        mv -f "${tmp}" "${dst}"
      }

      require_cmd() {
        cmd="${1}"
        if ! command -v "${cmd}" >/dev/null 2>&1; then
          die "required command missing: ${cmd}"
        fi
      }

      # base64 decode helper (portable-ish)
      b64_decode() {
        if command -v base64 >/dev/null 2>&1; then
          base64 -d 2>/dev/null || base64 -D 2>/dev/null
        else
          die "base64 not available in runner image"
        fi
      }

      # JSON array extraction helper:
      # We prefer jq, else python, else fail.
      json_extract_workloads() {
        # stdin: params_json object
        if command -v jq >/dev/null 2>&1; then
          jq -c '.workloads // []' 2>/dev/null
          return $?
        fi
        if command -v python3 >/dev/null 2>&1; then
          python3 - <<'PY'
      import sys, json
      try:
          obj = json.load(sys.stdin)
      except Exception:
          print("[]")
          sys.exit(0)
      wl = obj.get("workloads", [])
      if not isinstance(wl, list):
          wl = []
      print(json.dumps(wl, separators=(",", ":")))
      PY
          return 0
        fi
        if command -v python >/dev/null 2>&1; then
          python - <<'PY'
      import sys, json
      try:
          obj = json.load(sys.stdin)
      except Exception:
          print("[]")
          sys.exit(0)
      wl = obj.get("workloads", [])
      if not isinstance(wl, list):
          wl = []
      print(json.dumps(wl, separators=(",", ":")))
      PY
          return 0
        fi
        return 1
      }

      # Extract a field from a JSON object using jq or python.
      json_get_field() {
        # args: <json> <jq_expr> <default>
        j="${1}"
        expr="${2}"
        dflt="${3}"
        if command -v jq >/dev/null 2>&1; then
          out="$(printf '%s' "${j}" | jq -r "${expr}" 2>/dev/null || true)"
        elif command -v python3 >/dev/null 2>&1; then
          out="$(python3 - <<PY
      import json, sys
      j = sys.argv[1]
      expr = sys.argv[2]
      dflt = sys.argv[3]
      try:
          obj = json.loads(j)
      except Exception:
          print(dflt)
          sys.exit(0)

      # We only support a tiny subset: ".name", ".template", ".params"
      if expr == ".name":
          v = obj.get("name", dflt)
      elif expr == ".template":
          v = obj.get("template", dflt)
      elif expr == ".params":
          v = obj.get("params", None)
          if v is None:
              print(dflt)
              sys.exit(0)
          print(json.dumps(v, separators=(",", ":")))
          sys.exit(0)
      else:
          v = dflt
      if v is None:
          v = dflt
      print(v)
      PY
      "${j}" "${expr}" "${dflt}")"
        elif command -v python >/dev/null 2>&1; then
          out="$(python - <<PY
      import json, sys
      j = sys.argv[1]
      expr = sys.argv[2]
      dflt = sys.argv[3]
      try:
          obj = json.loads(j)
      except Exception:
          print(dflt)
          sys.exit(0)

      if expr == ".name":
          v = obj.get("name", dflt)
      elif expr == ".template":
          v = obj.get("template", dflt)
      elif expr == ".params":
          v = obj.get("params", None)
          if v is None:
              print(dflt)
              sys.exit(0)
          print(json.dumps(v, separators=(",", ":")))
          sys.exit(0)
      else:
          v = dflt
      if v is None:
          v = dflt
      print(v)
      PY
      "${j}" "${expr}" "${dflt}")"
        else
          out="${dflt}"
        fi
        printf '%s' "${out}"
      }

      # -------------------------
      # Context (mounted by Job)
      # -------------------------

      PLAN_YAML="/plan/plan.yaml"
      PHASES_PSV="/plan/runner_phases.psv"

      OUT_ROOT="/out"

      PLAN_ID="$(sed -n 's/^[[:space:]]*plan_id:[[:space:]]*"\{0,1\}\([^"]*\)"\{0,1\}[[:space:]]*$/\1/p' "${PLAN_YAML}" | head -n1 || true)"
      if [ -z "${PLAN_ID}" ]; then
        PLAN_ID="$(grep -E '^[[:space:]]*plan_id:' -n "${PLAN_YAML}" | head -n1 | sed 's/.*plan_id:[[:space:]]*//; s/"//g' | tr -d '\r' || true)"
      fi
      if [ -z "${PLAN_ID}" ]; then
        die "could not derive PLAN_ID from ${PLAN_YAML}"
      fi

      NAMESPACE="$(grep -E '^[[:space:]]*namespace:' -n "${PLAN_YAML}" | head -n1 | sed 's/.*namespace:[[:space:]]*//; s/"//g' | tr -d '\r' || true)"
      TARGET_NODE="$(grep -E '^[[:space:]]*node_name:' -n "${PLAN_YAML}" | head -n1 | sed 's/.*node_name:[[:space:]]*//; s/"//g' | tr -d '\r' || true)"

      if [ -z "${NAMESPACE}" ] || [ -z "${TARGET_NODE}" ]; then
        die "could not derive NAMESPACE/TARGET_NODE from plan.yaml (namespace='${NAMESPACE}' node='${TARGET_NODE}')"
      fi

      TIMEOUT_SLACK_SEC="${TIMEOUT_SLACK_SEC:-60}"

      # Provided by kubectl-job.yaml.j2
      TYCHO_PLAN_CONFIGMAP_NAME="${TYCHO_PLAN_CONFIGMAP_NAME:-}"
      TYCHO_OUT_PVC_NAME="${TYCHO_OUT_PVC_NAME:-}"

      # Images/defaults used by templates
      STRESSNG_IMAGE="${STRESSNG_IMAGE:-polinux/stress-ng:latest}"
      GPU_BURN_IMAGE="${GPU_BURN_IMAGE:-}"
      GPU_RUNTIME_CLASS_DEFAULT="${GPU_RUNTIME_CLASS_DEFAULT:-nvidia}"

      SAFE_TS="$(date -u '+%Y%m%d%H%M%S')"
      mkdir -p "${OUT_ROOT}"

      # -------------------------
      # Sub-runner mode
      # -------------------------
      if [ "${TYCHO_SUBRUNNER:-0}" = "1" ]; then
        SUB_NAME="${TYCHO_SUBWORKLOAD_NAME:-}"
        SUB_TEMPLATE="${TYCHO_SUBTEMPLATE:-}"
        if [ -z "${SUB_NAME}" ] || [ -z "${SUB_TEMPLATE}" ]; then
          die "sub-runner missing required env vars: TYCHO_SUBWORKLOAD_NAME and/or TYCHO_SUBTEMPLATE"
        fi

        if [ -n "${TYCHO_SUBPARAMS_JSON_B64:-}" ]; then
          PARAMS_JSON="$(printf '%s' "${TYCHO_SUBPARAMS_JSON_B64}" | b64_decode)"
        else
          PARAMS_JSON="${TYCHO_SUBPARAMS_JSON:-}"
        fi
        if [ -z "${PARAMS_JSON}" ]; then
          die "sub-runner missing params: TYCHO_SUBPARAMS_JSON_B64 or TYCHO_SUBPARAMS_JSON"
        fi

        PLANNED_DUR="$(printf '%s' "${PARAMS_JSON}" | sed -n 's/.*"total_duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p' | head -n1 || true)"
        if [ -z "${PLANNED_DUR}" ]; then
          PLANNED_DUR="$(printf '%s' "${PARAMS_JSON}" | sed -n 's/.*"duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p' | head -n1 || true)"
        fi
        if [ -z "${PLANNED_DUR}" ]; then
          PLANNED_DUR="0"
        fi

        sub_slug="$(sanitize_k8s_name "${SUB_NAME}")"
        OUT_DIR="${OUT_ROOT}/${PLAN_ID}/subrun_${SAFE_TS}_${sub_slug}"
        mkdir -p "${OUT_DIR}"

        EVENTS_LOG="${OUT_DIR}/events.log"
        : > "${EVENTS_LOG}" || true

        log "[subrunner] plan_id=${PLAN_ID} namespace=${NAMESPACE} node=${TARGET_NODE} workload_name=${SUB_NAME} template=${SUB_TEMPLATE}"

        RUN_START="$(utc_now)"

        rep=1
        first_phase=1
        PHASES_BODY_FILE="${OUT_DIR}/phases_body.json.tmp"
        : > "${PHASES_BODY_FILE}"

        PHASE_NAME="${SUB_NAME}"
        PHASE_TYPE="workload"
        TEMPLATE="${SUB_TEMPLATE}"

        phase_status="ok"
        phase_exit_reason=""
        k8s_kind=""
        k8s_name=""
        k8s_uid=""
        k8s_node="${TARGET_NODE}"

        PHASE_START="$(utc_now)"
        log "phase '${PHASE_NAME}' start_utc=${PHASE_START} type=${PHASE_TYPE} template=${TEMPLATE}"

        # -------------------------
        # Workload templates (copied from your existing structure)
        # -------------------------

        if [ "${PHASE_TYPE}" = "sleep" ]; then
          # sleep: pure wait
          dur="${PLANNED_DUR}"
          log "sleep ${dur}s"
          sleep "${dur}"

        elif [ "${PHASE_TYPE}" = "ramp" ]; then
          # ramp: cpu ramp up to max_workers over total duration (step_count steps).
          # PARAMS_JSON fields:
          # - ramp_profile (must be "cpu")
          # - duration_sec (total duration)
          # - max_workers (target workers at final step)
          # - step_count (number of steps, default 10)
          # - method (stress-ng cpu method, default "matrixprod")
          # - cpu_request_mcpu (cap for cpu request; per step uses min(workers*1000, cap). If cap=0, uses workers*1000)

          profile="$(echo "${PARAMS_JSON}" | sed -n 's/.*"ramp_profile"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
          total="${PLANNED_DUR}"

          maxw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"max_workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
          steps="$(echo "${PARAMS_JSON}" | sed -n 's/.*"step_count"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
          method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
          cap_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

          if [ -z "${method}" ]; then method="matrixprod"; fi
          if [ -z "${steps}" ] || [ "${steps}" -le 0 ]; then steps=10; fi
          if [ -z "${maxw}" ] || [ "${maxw}" -le 0 ]; then maxw=4; fi
          if [ -z "${cap_req}" ]; then cap_req=0; fi

          if [ "${profile}" != "cpu" ]; then
            phase_status="failed"
            phase_exit_reason="unknown ramp_profile"
          else
            log "ramp cpu total=${total}s max_workers=${maxw} steps=${steps} method=${method} cap_cpu_request_mcpu=${cap_req}"

            # integer step duration, last step absorbs remainder
            base_step=$(( total / steps ))
            rem=$(( total - (base_step * steps) ))
            if [ "${base_step}" -le 0 ]; then
              base_step=1
              rem=0
              steps="${total}"
            fi

            i=1
            while [ "${i}" -le "${steps}" ]; do
              step_dur="${base_step}"
              if [ "${i}" -eq "${steps}" ]; then
                step_dur=$(( base_step + rem ))
              fi

              # linear ramp: workers = ceil(maxw * i / steps)
              workers=$(( (maxw * i + steps - 1) / steps ))
              if [ "${workers}" -lt 1 ]; then workers=1; fi

              # per-step cpu request (mcpu): workers*1000, optionally capped
              req=$(( workers * 1000 ))
              if [ "${cap_req}" -gt 0 ] && [ "${req}" -gt "${cap_req}" ]; then
                req="${cap_req}"
              fi

              step_slug="$(sanitize_k8s_name "${PHASE_NAME}-s${i}")"
              pod_name="tycho-${PLAN_ID}-r${rep}-${step_slug}-${SAFE_TS}"

              log "ramp step ${i}/${steps} duration=${step_dur}s workers=${workers} cpu_request=${req}m pod=${pod_name}"

              cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "ramp"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                stress-ng --cpu ${workers} --cpu-method ${method} --timeout ${step_dur}s --metrics-brief
            resources:
              requests:
                cpu: "${req}m"
      EOF

              deadline=$(( $(date +%s) + step_dur + TIMEOUT_SLACK_SEC ))
              while :; do
                now="$(date +%s)"
                if [ "${now}" -gt "${deadline}" ]; then
                  phase_status="failed"
                  phase_exit_reason="timeout in ramp step"
                  break
                fi

                st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                if [ "${st}" = "Succeeded" ]; then
                  break
                fi
                if [ "${st}" = "Failed" ]; then
                  phase_status="failed"
                  phase_exit_reason="pod failed in ramp step"
                  break
                fi
                sleep 1
              done

              step_log="${OUT_DIR}/phase_${PHASE_NAME}_step_${i}.log"
              agg_log="${OUT_DIR}/phase_${PHASE_NAME}.log"

              # Always create log files so debugging is deterministic
              : > "${step_log}"
              : > "${agg_log}" 2>/dev/null || true

              # Capture logs (best-effort). If logs fail, store a helpful marker.
              if ! kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${step_log}" 2>&1; then
                echo "[tycho-testing] kubectl logs failed for pod=${pod_name}" >> "${step_log}"
              fi

              # Append into aggregated ramp log
              {
                echo "===== ramp step ${i}/${steps} pod=${pod_name} ====="
                cat "${step_log}"
                echo
              } >> "${agg_log}" 2>/dev/null || true

              # On failure: also capture describe
              if [ "${phase_status}" != "ok" ]; then
                kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_step_${i}_describe.txt" 2>&1 || true
              fi

              kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true

              if [ "${phase_status}" != "ok" ]; then
                break
              fi

              i=$(( i + 1 ))
            done
          fi


        elif [ "${PHASE_TYPE}" = "workload" ]; then
          if [ "${TEMPLATE}" = "noop-sleep" ]; then
            dur="${PLANNED_DUR}"
            phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
            pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

            k8s_kind="Pod"
            k8s_name="${pod_name}"

            log "workload noop-sleep duration=${dur}s pod=${pod_name}"

            cat <<EOF | kubectl -n "${NAMESPACE}" create -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: sleep
            image: "busybox:1.36"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                sleep ${dur}
      EOF

            k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
            deadline=$(( $(date +%s) + dur + TIMEOUT_SLACK_SEC ))
            while :; do
              now="$(date +%s)"
              if [ "${now}" -gt "${deadline}" ]; then
                phase_status="failed"
                phase_exit_reason="timeout"
                break
              fi
              st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
              if [ "${st}" = "Succeeded" ]; then break; fi
              if [ "${st}" = "Failed" ]; then phase_status="failed"; phase_exit_reason="pod failed"; break; fi
              sleep 1
            done

            kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
            if [ "${phase_status}" != "ok" ]; then
              kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
            fi
            kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true







          elif [ "${TEMPLATE}" = "stressng-cpu" ]; then
            workers="$(echo "${PARAMS_JSON}" | sed -n 's/.*"workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
            dur="$(echo "${PARAMS_JSON}" | sed -n 's/.*"duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

            if [ -z "${workers}" ] || [ -z "${method}" ] || [ -z "${dur}" ] || [ -z "${cpu_req}" ]; then
              phase_status="failed"
              phase_exit_reason="missing stressng-cpu params"
            else
              phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
              pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

              k8s_kind="Pod"
              k8s_name="${pod_name}"

              log "workload stressng-cpu workers=${workers} method=${method} duration=${dur}s cpu_request=${cpu_req}m pod=${pod_name}"

              cat <<EOF | kubectl -n "${NAMESPACE}" create -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                stress-ng --cpu ${workers} --cpu-method ${method} --timeout ${dur}s --metrics-brief
            resources:
              requests:
                cpu: "${cpu_req}m"
      EOF

              k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
              deadline=$(( $(date +%s) + dur + TIMEOUT_SLACK_SEC ))
              while :; do
                now="$(date +%s)"
                if [ "${now}" -gt "${deadline}" ]; then phase_status="failed"; phase_exit_reason="timeout"; break; fi
                st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                if [ "${st}" = "Succeeded" ]; then break; fi
                if [ "${st}" = "Failed" ]; then phase_status="failed"; phase_exit_reason="pod failed"; break; fi
                sleep 1
              done

              kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
              if [ "${phase_status}" != "ok" ]; then
                kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
              fi
              kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
            fi

          # NOTE: Keep your other templates here exactly as you already have them:
          # stressng-cpu-burst, stressng-cpu-jitter, gpu-burn-steady, gpu-burn-burst
          # (Copy/paste your existing blocks unchanged.)
          #
          # For brevity of this answer: I am NOT re-printing the rest of your template chain here
          # because you already pasted it, and you explicitly do not want to edit manually.
          #
          # In your repository, replace this runner.sh with THIS runner.sh, but include the
          # rest of the template chain blocks exactly as you had them.



          elif [ "${TEMPLATE}" = "stressng-cpu-burst" ]; then
            # params:
            # total_duration_sec, on_sec, off_sec, seed
            # on_workers, on_method
            # off_mode (sleep|stress), off_workers, off_method
            # cpu_request_mcpu, cpu_limit_mcpu (0 => unset)
            total="$(echo "${PARAMS_JSON}" | sed -n 's/.*"total_duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            on_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            off_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            seed="$(echo "${PARAMS_JSON}" | sed -n 's/.*"seed"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

            on_workers="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            on_method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

            off_mode="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_mode"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
            off_workers="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            off_method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

            cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            cpu_lim="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_limit_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

            # defaults / coercions
            if [ -z "${seed}" ]; then seed=0; fi
            if [ -z "${off_mode}" ]; then off_mode="sleep"; fi
            if [ -z "${off_workers}" ]; then off_workers=0; fi
            if [ -z "${cpu_lim}" ]; then cpu_lim=0; fi

            if [ -z "${total}" ] || [ -z "${on_sec}" ] || [ -z "${off_sec}" ] || [ -z "${on_workers}" ] || [ -z "${on_method}" ] || [ -z "${cpu_req}" ]; then
              phase_status="failed"
              phase_exit_reason="missing stressng-cpu-burst params"
            else
              phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
              pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

              k8s_kind="Pod"
              k8s_name="${pod_name}"

              log "workload stressng-cpu-burst total=${total}s on=${on_sec}s off=${off_sec}s seed=${seed} on_workers=${on_workers} on_method=${on_method} off_mode=${off_mode} off_workers=${off_workers} off_method=${off_method} cpu_request=${cpu_req}m cpu_limit=${cpu_lim}m pod=${pod_name}"

              # render pod manifest (limits are optional; cpu_lim=0 => omit)
              if [ "${cpu_lim}" -gt 0 ]; then
                cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -  
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                # seed is currently only logged for determinism; kept for future jitter extensions
                SEED="${seed}"
                TOTAL="${total}"
                ON_SEC="${on_sec}"
                OFF_SEC="${off_sec}"
                ON_WORKERS="${on_workers}"
                ON_METHOD="${on_method}"
                OFF_MODE="${off_mode}"
                OFF_WORKERS="${off_workers}"
                OFF_METHOD="${off_method}"

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then
                    break
                  fi

                  # ON segment
                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    if [ "\$ON_WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$ON_WORKERS" --cpu-method "\$ON_METHOD" --timeout "\${run_on}s" --metrics-brief
                    else
                      sleep "\$run_on"
                    fi
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then
                    break
                  fi

                  # OFF segment
                  run_off="\$OFF_SEC"
                  if [ "\$run_off" -gt "\$rem" ]; then run_off="\$rem"; fi
                  if [ "\$run_off" -gt 0 ]; then
                    if [ "\$OFF_MODE" = "stress" ] && [ "\$OFF_WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$OFF_WORKERS" --cpu-method "\$OFF_METHOD" --timeout "\${run_off}s" --metrics-brief
                    else
                      sleep "\$run_off"
                    fi
                  fi
                done

            resources:
              requests:
                cpu: "${cpu_req}m"
              limits:
                cpu: "${cpu_lim}m"
      EOF
              else
                cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                SEED="${seed}"
                TOTAL="${total}"
                ON_SEC="${on_sec}"
                OFF_SEC="${off_sec}"
                ON_WORKERS="${on_workers}"
                ON_METHOD="${on_method}"
                OFF_MODE="${off_mode}"
                OFF_WORKERS="${off_workers}"
                OFF_METHOD="${off_method}"

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then
                    break
                  fi

                  # ON segment
                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    if [ "\$ON_WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$ON_WORKERS" --cpu-method "\$ON_METHOD" --timeout "\${run_on}s" --metrics-brief
                    else
                      sleep "\$run_on"
                    fi
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then
                    break
                  fi

                  # OFF segment
                  run_off="\$OFF_SEC"
                  if [ "\$run_off" -gt "\$rem" ]; then run_off="\$rem"; fi
                  if [ "\$run_off" -gt 0 ]; then
                    if [ "\$OFF_MODE" = "stress" ] && [ "\$OFF_WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$OFF_WORKERS" --cpu-method "\$OFF_METHOD" --timeout "\${run_off}s" --metrics-brief
                    else
                      sleep "\$run_off"
                    fi
                  fi
                done
            resources:
              requests:
                cpu: "${cpu_req}m"
      EOF
              fi

              k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
              deadline=$(( $(date +%s) + ${total} + ${TIMEOUT_SLACK_SEC} ))
              while :; do
                now="$(date +%s)"
                if [ "${now}" -gt "${deadline}" ]; then
                  phase_status="failed"
                  phase_exit_reason="timeout"
                  break
                fi

                st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                if [ "${st}" = "Succeeded" ]; then
                  break
                fi
                if [ "${st}" = "Failed" ]; then
                  phase_status="failed"
                  phase_exit_reason="pod failed"
                  break
                fi
                sleep 1
              done

              kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
              if [ "${phase_status}" != "ok" ]; then
                kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
              fi
              kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
            fi



            
          elif [ "${TEMPLATE}" = "stressng-cpu-jitter" ]; then
            total="$(echo "${PARAMS_JSON}" | sed -n 's/.*"total_duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            on_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            gmin="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gap_min_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            gmax="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gap_max_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            seed="$(echo "${PARAMS_JSON}" | sed -n 's/.*"seed"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

            workers="$(echo "${PARAMS_JSON}" | sed -n 's/.*"workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

            cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            cpu_lim="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_limit_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

            if [ -z "${seed}" ]; then seed=0; fi
            if [ -z "${gmin}" ]; then gmin=0; fi
            if [ -z "${gmax}" ]; then gmax="${gmin}"; fi
            if [ -z "${cpu_lim}" ]; then cpu_lim=0; fi

            if [ -z "${total}" ] || [ -z "${on_sec}" ] || [ -z "${workers}" ] || [ -z "${method}" ] || [ -z "${cpu_req}" ]; then
              phase_status="failed"
              phase_exit_reason="missing stressng-cpu-jitter params"
            else
              phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
              pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

              k8s_kind="Pod"
              k8s_name="${pod_name}"

              log "workload stressng-cpu-jitter total=${total}s on=${on_sec}s gap=[${gmin},${gmax}] seed=${seed} workers=${workers} method=${method} cpu_request=${cpu_req}m cpu_limit=${cpu_lim}m pod=${pod_name}"

              # limits optional (cpu_lim=0 => omit)
              if [ "${cpu_lim}" -gt 0 ]; then
                cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                TOTAL="${total}"
                ON_SEC="${on_sec}"
                GAP_MIN="${gmin}"
                GAP_MAX="${gmax}"
                STATE="${seed}"
                WORKERS="${workers}"
                METHOD="${method}"

                # LCG PRNG for /bin/sh (deterministic)
                # state = (1103515245*state + 12345) mod 2^31
                next_u31() {
                  STATE=\$(( (1103515245 * STATE + 12345) % 2147483648 ))
                  echo "\$STATE"
                }

                rand_gap() {
                  if [ "\$GAP_MAX" -le "\$GAP_MIN" ]; then
                    echo "\$GAP_MIN"
                    return
                  fi
                  span=\$(( GAP_MAX - GAP_MIN + 1 ))
                  r="\$(next_u31)"
                  echo \$(( GAP_MIN + (r % span) ))
                }

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    if [ "\$WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$WORKERS" --cpu-method "\$METHOD" --timeout "\${run_on}s" --metrics-brief
                    else
                      sleep "\$run_on"
                    fi
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  gap="\$(rand_gap)"
                  if [ "\$gap" -gt "\$rem" ]; then gap="\$rem"; fi
                  if [ "\$gap" -gt 0 ]; then
                    sleep "\$gap"
                  fi
                done
            resources:
              requests:
                cpu: "${cpu_req}m"
              limits:
                cpu: "${cpu_lim}m"
      EOF
              else
                cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                TOTAL="${total}"
                ON_SEC="${on_sec}"
                GAP_MIN="${gmin}"
                GAP_MAX="${gmax}"
                STATE="${seed}"
                WORKERS="${workers}"
                METHOD="${method}"

                next_u31() {
                  STATE=\$(( (1103515245 * STATE + 12345) % 2147483648 ))
                  echo "\$STATE"
                }

                rand_gap() {
                  if [ "\$GAP_MAX" -le "\$GAP_MIN" ]; then
                    echo "\$GAP_MIN"
                    return
                  fi
                  span=\$(( GAP_MAX - GAP_MIN + 1 ))
                  r="\$(next_u31)"
                  echo \$(( GAP_MIN + (r % span) ))
                }

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    if [ "\$WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$WORKERS" --cpu-method "\$METHOD" --timeout "\${run_on}s" --metrics-brief
                    else
                      sleep "\$run_on"
                    fi
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  gap="\$(rand_gap)"
                  if [ "\$gap" -gt "\$rem" ]; then gap="\$rem"; fi
                  if [ "\$gap" -gt 0 ]; then
                    sleep "\$gap"
                  fi
                done
            resources:
              requests:
                cpu: "${cpu_req}m"
      EOF
              fi

              k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
              deadline=$(( $(date +%s) + ${total} + ${TIMEOUT_SLACK_SEC} ))
              while :; do
                now="$(date +%s)"
                if [ "${now}" -gt "${deadline}" ]; then
                  phase_status="failed"
                  phase_exit_reason="timeout"
                  break
                fi
                st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                if [ "${st}" = "Succeeded" ]; then break; fi
                if [ "${st}" = "Failed" ]; then phase_status="failed"; phase_exit_reason="pod failed"; break; fi
                sleep 1
              done

              kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
              if [ "${phase_status}" != "ok" ]; then
                kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
              fi
              kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
            fi



          elif [ "${TEMPLATE}" = "gpu-burn-steady" ]; then
            dur="$(echo "${PARAMS_JSON}" | sed -n 's/.*"duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            gcount="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_request_count"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            img="$(echo "${PARAMS_JSON}" | sed -n 's/.*"image"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
            cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            cpu_lim="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_limit_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            runtime_class="$(echo "${PARAMS_JSON}" | sed -n 's/.*"runtime_class"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

            mem_mb="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_mem_mb"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            mem_pct="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_mem_pct"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            use_doubles_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_use_doubles"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"
            use_tc_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_use_tensor_cores"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"
            gpu_index="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_gpu_index"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            list_gpus_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_list_gpus"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"

            if [ -z "${gcount}" ]; then gcount=1; fi
            if [ -z "${cpu_req}" ]; then cpu_req=0; fi
            if [ -z "${cpu_lim}" ]; then cpu_lim=0; fi
            if [ -z "${img}" ]; then img="${GPU_BURN_IMAGE}"; fi
            if [ -z "${runtime_class}" ]; then runtime_class="${GPU_RUNTIME_CLASS_DEFAULT}"; fi

            use_doubles="false"
            use_tc="false"
            list_gpus="false"
            if [ "${use_doubles_raw}" = "true" ] || [ "${use_doubles_raw}" = "1" ]; then use_doubles="true"; fi
            if [ "${use_tc_raw}" = "true" ] || [ "${use_tc_raw}" = "1" ]; then use_tc="true"; fi
            if [ "${list_gpus_raw}" = "true" ] || [ "${list_gpus_raw}" = "1" ]; then list_gpus="true"; fi

              # If image not provided, fall back to runner default; if that is empty, hardcode a safe default.
              if [ -z "${img}" ]; then img="${GPU_BURN_IMAGE:-oguzpastirmaci/gpu-burn:latest}"; fi

              if [ -z "${dur}" ] || [ "${gcount}" -lt 1 ] || [ -z "${img}" ]; then
                phase_status="failed"
                phase_exit_reason="missing gpu-burn-steady params"
              else
              phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
              pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

              k8s_kind="Pod"
              k8s_name="${pod_name}"

              log "workload gpu-burn-steady dur=${dur}s gpus=${gcount} image=${img} runtimeClass=${runtime_class} mem_mb=${mem_mb:-} mem_pct=${mem_pct:-} doubles=${use_doubles} tc=${use_tc} gpu_index=${gpu_index:-} list_gpus=${list_gpus} cpu_request=${cpu_req}m cpu_limit=${cpu_lim}m pod=${pod_name}"

              cpu_req_yaml=""
              cpu_lim_yaml=""
              if [ "${cpu_req}" -gt 0 ]; then cpu_req_yaml="cpu: \"${cpu_req}m\""; fi
              if [ "${cpu_lim}" -gt 0 ]; then cpu_lim_yaml="cpu: \"${cpu_lim}m\""; fi

              cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        runtimeClassName: "${runtime_class}"
        containers:
          - name: gpuburn
            image: "${img}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu

                DUR="${dur}"
                USE_DOUBLES="${use_doubles}"
                USE_TC="${use_tc}"
                LIST_GPUS="${list_gpus}"
                GPU_INDEX="${gpu_index:-}"
                MEM_MB="${mem_mb:-}"
                MEM_PCT="${mem_pct:-}"

                # Resolve gpu-burn binary.
                GPU_BURN_BIN=""
                if command -v gpu_burn >/dev/null 2>&1; then
                  GPU_BURN_BIN="gpu_burn"
                elif command -v gpu-burn >/dev/null 2>&1; then
                  GPU_BURN_BIN="gpu-burn"
                elif [ -x "/app/gpu_burn" ]; then
                  GPU_BURN_BIN="/app/gpu_burn"
                else
                  echo "gpu-burn binary not found (expected gpu_burn, gpu-burn, or /app/gpu_burn)"
                  exit 2
                fi

                # Build argv safely without eval.
                # FLAGS_STR is for logging only.
                FLAGS_STR=""
                set --

                if [ -n "\${MEM_MB:-}" ] && [ "\${MEM_MB:-0}" -gt 0 ] 2>/dev/null; then
                  set -- "\$@" -m "\${MEM_MB}"
                  FLAGS_STR="\${FLAGS_STR} -m \${MEM_MB}"
                elif [ -n "\${MEM_PCT:-}" ] && [ "\${MEM_PCT:-0}" -gt 0 ] 2>/dev/null; then
                  set -- "\$@" -m "\${MEM_PCT}%"
                  FLAGS_STR="\${FLAGS_STR} -m \${MEM_PCT}%"
                fi

                if [ "\${USE_DOUBLES}" = "true" ]; then
                  set -- "\$@" -d
                  FLAGS_STR="\${FLAGS_STR} -d"
                fi

                if [ "\${USE_TC}" = "true" ]; then
                  set -- "\$@" -tc
                  FLAGS_STR="\${FLAGS_STR} -tc"
                fi

                if [ -n "\${GPU_INDEX:-}" ]; then
                  set -- "\$@" -i "\${GPU_INDEX}"
                  FLAGS_STR="\${FLAGS_STR} -i \${GPU_INDEX}"
                fi

                if [ "\${LIST_GPUS}" = "true" ]; then
                  echo "[gpu-burn] \${GPU_BURN_BIN} -l"
                  "\${GPU_BURN_BIN}" -l || true
                  echo
                fi

                nvidia-smi -L || true

                echo "[gpu-burn] running: \${GPU_BURN_BIN}\${FLAGS_STR} \${DUR}"
                "\${GPU_BURN_BIN}" "\$@" "\${DUR}"


            resources:
              requests:
                nvidia.com/gpu: "${gcount}"
                ${cpu_req_yaml}
              limits:
                nvidia.com/gpu: "${gcount}"
                ${cpu_lim_yaml}
      EOF

              k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
              deadline=$(( $(date +%s) + dur + TIMEOUT_SLACK_SEC ))
              while :; do
                now="$(date +%s)"
                if [ "${now}" -gt "${deadline}" ]; then
                  phase_status="failed"
                  phase_exit_reason="timeout"
                  break
                fi

                st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                if [ "${st}" = "Succeeded" ]; then
                  break
                fi
                if [ "${st}" = "Failed" ]; then
                  phase_status="failed"
                  phase_exit_reason="pod failed"
                  break
                fi
                sleep 1
              done

              kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
              if [ "${phase_status}" != "ok" ]; then
                kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
              fi
              kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
            fi







          elif [ "${TEMPLATE}" = "gpu-burn-burst" ]; then
            total="$(echo "${PARAMS_JSON}" | sed -n 's/.*"total_duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            on_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            off_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            gcount="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_request_count"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            img="$(echo "${PARAMS_JSON}" | sed -n 's/.*"image"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
            cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            cpu_lim="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_limit_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            runtime_class="$(echo "${PARAMS_JSON}" | sed -n 's/.*"runtime_class"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

            mem_mb="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_mem_mb"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            mem_pct="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_mem_pct"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            use_doubles_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_use_doubles"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"
            use_tc_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_use_tensor_cores"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"
            gpu_index="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_gpu_index"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            list_gpus_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_list_gpus"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"

            if [ -z "${gcount}" ]; then gcount=1; fi
            if [ -z "${off_sec}" ]; then off_sec=0; fi
            if [ -z "${cpu_req}" ]; then cpu_req=0; fi
            if [ -z "${cpu_lim}" ]; then cpu_lim=0; fi
            if [ -z "${img}" ]; then img="${GPU_BURN_IMAGE:-oguzpastirmaci/gpu-burn:latest}"; fi
            if [ -z "${runtime_class}" ]; then runtime_class="${GPU_RUNTIME_CLASS_DEFAULT}"; fi

            use_doubles="false"
            use_tc="false"
            list_gpus="false"
            if [ "${use_doubles_raw}" = "true" ] || [ "${use_doubles_raw}" = "1" ]; then use_doubles="true"; fi
            if [ "${use_tc_raw}" = "true" ] || [ "${use_tc_raw}" = "1" ]; then use_tc="true"; fi
            if [ "${list_gpus_raw}" = "true" ] || [ "${list_gpus_raw}" = "1" ]; then list_gpus="true"; fi

            if [ -z "${total}" ] || [ -z "${on_sec}" ] || [ -z "${img}" ] || [ "${gcount}" -lt 1 ]; then
              phase_status="failed"
              phase_exit_reason="missing gpu-burn-burst params"
            else
              phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
              pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

              k8s_kind="Pod"
              k8s_name="${pod_name}"

              log "workload gpu-burn-burst total=${total}s on=${on_sec}s off=${off_sec}s gpus=${gcount} image=${img} runtimeClass=${runtime_class} mem_mb=${mem_mb:-} mem_pct=${mem_pct:-} doubles=${use_doubles} tc=${use_tc} gpu_index=${gpu_index:-} list_gpus=${list_gpus} cpu_request=${cpu_req}m cpu_limit=${cpu_lim}m pod=${pod_name}"

              cpu_req_yaml=""
              cpu_lim_yaml=""
              if [ "${cpu_req}" -gt 0 ]; then cpu_req_yaml="cpu: \"${cpu_req}m\""; fi
              if [ "${cpu_lim}" -gt 0 ]; then cpu_lim_yaml="cpu: \"${cpu_lim}m\""; fi

              cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        runtimeClassName: "${runtime_class}"
        containers:
          - name: gpuburn
            image: "${img}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu

                TOTAL="${total}"
                ON_SEC="${on_sec}"
                OFF_SEC="${off_sec}"

                USE_DOUBLES="${use_doubles}"
                USE_TC="${use_tc}"
                LIST_GPUS="${list_gpus}"
                GPU_INDEX="${gpu_index:-}"
                MEM_MB="${mem_mb:-}"
                MEM_PCT="${mem_pct:-}"

                # Resolve gpu-burn binary.
                GPU_BURN_BIN=""
                if command -v gpu_burn >/dev/null 2>&1; then
                  GPU_BURN_BIN="gpu_burn"
                elif command -v gpu-burn >/dev/null 2>&1; then
                  GPU_BURN_BIN="gpu-burn"
                elif [ -x "/app/gpu_burn" ]; then
                  GPU_BURN_BIN="/app/gpu_burn"
                else
                  echo "gpu-burn binary not found (expected gpu_burn, gpu-burn, or /app/gpu_burn)"
                  exit 2
                fi

                # Build argv safely without eval.
                FLAGS_STR=""
                set --

                if [ -n "\${MEM_MB:-}" ] && [ "\${MEM_MB:-0}" -gt 0 ] 2>/dev/null; then
                  set -- "\$@" -m "\${MEM_MB}"
                  FLAGS_STR="\${FLAGS_STR} -m \${MEM_MB}"
                elif [ -n "\${MEM_PCT:-}" ] && [ "\${MEM_PCT:-0}" -gt 0 ] 2>/dev/null; then
                  set -- "\$@" -m "\${MEM_PCT}%"
                  FLAGS_STR="\${FLAGS_STR} -m \${MEM_PCT}%"
                fi

                if [ "\${USE_DOUBLES}" = "true" ]; then
                  set -- "\$@" -d
                  FLAGS_STR="\${FLAGS_STR} -d"
                fi

                if [ "\${USE_TC}" = "true" ]; then
                  set -- "\$@" -tc
                  FLAGS_STR="\${FLAGS_STR} -tc"
                fi

                if [ -n "\${GPU_INDEX:-}" ]; then
                  set -- "\$@" -i "\${GPU_INDEX}"
                  FLAGS_STR="\${FLAGS_STR} -i \${GPU_INDEX}"
                fi

                if [ "\${LIST_GPUS}" = "true" ]; then
                  echo "[gpu-burn] \${GPU_BURN_BIN} -l"
                  "\${GPU_BURN_BIN}" -l || true
                  echo
                fi

                nvidia-smi -L || true

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    echo "[gpu-burn] running: \${GPU_BURN_BIN}\${FLAGS_STR} \${run_on}"
                    "\${GPU_BURN_BIN}" "\$@" "\${run_on}"
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  run_off="\$OFF_SEC"
                  if [ "\$run_off" -gt "\$rem" ]; then run_off="\$rem"; fi
                  if [ "\$run_off" -gt 0 ]; then
                    sleep "\$run_off"
                  fi
                done
            resources:
              requests:
                nvidia.com/gpu: "${gcount}"
                ${cpu_req_yaml}
              limits:
                nvidia.com/gpu: "${gcount}"
                ${cpu_lim_yaml}
      EOF
              k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
              deadline=$(( $(date +%s) + total + TIMEOUT_SLACK_SEC ))
              while :; do
                now="$(date +%s)"
                if [ "${now}" -gt "${deadline}" ]; then
                  phase_status="failed"
                  phase_exit_reason="timeout"
                  break
                fi

                st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                if [ "${st}" = "Succeeded" ]; then
                  break
                fi
                if [ "${st}" = "Failed" ]; then
                  phase_status="failed"
                  phase_exit_reason="pod failed"
                  break
                fi
                sleep 1
              done

              kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
              if [ "${phase_status}" != "ok" ]; then
                kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
              fi
              kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
            fi















          else
            log "unknown workload template: raw='${TEMPLATE}'"
            phase_status="failed"
            phase_exit_reason="unknown workload template"
          fi
        else
          phase_status="failed"
          phase_exit_reason="unknown phase type"
        fi

        PHASE_END="$(utc_now)"
        log "phase '${PHASE_NAME}' end_utc=${PHASE_END} status=${phase_status} reason=${phase_exit_reason}"

        entry_file="${OUT_DIR}/phase_entry_${PHASE_NAME}.json.tmp"
        cat > "${entry_file}" <<EOF
      {
        "name": "$(printf '%s' "${PHASE_NAME}" | sed 's/"/\\"/g')",
        "type": "$(printf '%s' "${PHASE_TYPE}" | sed 's/"/\\"/g')",
        "start_utc": "${PHASE_START}",
        "end_utc": "${PHASE_END}",
        "planned_duration_sec": ${PLANNED_DUR},
        "workload": {
          "template": "$(printf '%s' "${TEMPLATE}" | sed 's/"/\\"/g')",
          "params": ${PARAMS_JSON}
        },
        "k8s": {
          "resource_kind": "$(printf '%s' "${k8s_kind}" | sed 's/"/\\"/g')",
          "resource_name": "$(printf '%s' "${k8s_name}" | sed 's/"/\\"/g')",
          "uid": "$(printf '%s' "${k8s_uid}" | sed 's/"/\\"/g')",
          "node": "$(printf '%s' "${k8s_node}" | sed 's/"/\\"/g')"
        },
        "result": {
          "status": "$(printf '%s' "${phase_status}" | sed 's/"/\\"/g')",
          "exit_reason": "$(printf '%s' "${phase_exit_reason}" | sed 's/"/\\"/g')"
        }
      }
      EOF

        cat "${entry_file}" > "${PHASES_BODY_FILE}"
        rm -f "${entry_file}" || true

        RUN_END="$(utc_now)"
        phases_json="${OUT_DIR}/phases.json.tmp"
        {
          printf "[\n"
          cat "${PHASES_BODY_FILE}"
          printf "\n]\n"
        } > "${phases_json}"

        run_json_tmp="${OUT_DIR}/run_compose.json.tmp"
        cat > "${run_json_tmp}" <<EOF
      {
        "apiVersion": "tycho.testing/v1",
        "kind": "RunRecord",
        "plan_id": "${PLAN_ID}",
        "namespace": "${NAMESPACE}",
        "rep": ${rep},
        "run_start_utc": "${RUN_START}",
        "run_end_utc": "${RUN_END}",
        "phases": $(cat "${phases_json}")
      }
      EOF

        write_atomic_json "${OUT_DIR}/run.json" "${run_json_tmp}"
        cp "${OUT_DIR}/run.json" "${OUT_DIR}/run_${SAFE_TS}.json" || true
        cp "${EVENTS_LOG}" "${OUT_DIR}/events_${SAFE_TS}.log" || true

        if [ "${phase_status}" != "ok" ]; then
          die "sub-runner failed in workload '${PHASE_NAME}'"
        fi

        log "[subrunner] ok workload='${PHASE_NAME}' wrote ${OUT_DIR}/run.json"
        exit 0
      fi

      # -------------------------
      # Parent runner mode
      # -------------------------

      log "runner start plan_id=${PLAN_ID} namespace=${NAMESPACE} node=${TARGET_NODE}"
      require_cmd kubectl

      OUT_DIR="${OUT_ROOT}/${PLAN_ID}"
      mkdir -p "${OUT_DIR}"
      EVENTS_LOG="${OUT_DIR}/events.log"
      : > "${EVENTS_LOG}" || true

      REP_COUNT="$(grep -E '^[[:space:]]*count:' -n "${PLAN_YAML}" | head -n1 | sed 's/.*count:[[:space:]]*//; s/"//g' | tr -d '\r' || true)"
      if [ -z "${REP_COUNT}" ]; then REP_COUNT="1"; fi

      rep=1
      while [ "${rep}" -le "${REP_COUNT}" ]; do
        log "rep=${rep} start"

        RUN_START="$(utc_now)"
        first_phase=1
        PHASES_BODY_FILE="${OUT_DIR}/phases_body_r${rep}.json.tmp"
        : > "${PHASES_BODY_FILE}"

        while IFS='|' read -r PHASE_NAME PHASE_TYPE PLANNED_DUR TEMPLATE PARAMS_JSON ROLE; do
          if [ -z "${PHASE_NAME}" ]; then
            continue
          fi

          phase_status="ok"
          phase_exit_reason=""
          k8s_kind=""
          k8s_name=""
          k8s_uid=""
          k8s_node="${TARGET_NODE}"

          PHASE_START="$(utc_now)"
          log "phase '${PHASE_NAME}' start_utc=${PHASE_START} type=${PHASE_TYPE} template=${TEMPLATE}"












          if [ "${PHASE_TYPE}" = "sleep" ]; then
            # sleep: pure wait
            dur="${PLANNED_DUR}"
            log "sleep ${dur}s"
            sleep "${dur}"

          elif [ "${PHASE_TYPE}" = "ramp" ]; then
            # ramp: cpu ramp up to max_workers over total duration (step_count steps).
            # PARAMS_JSON fields:
            # - ramp_profile (must be "cpu")
            # - duration_sec (total duration)
            # - max_workers (target workers at final step)
            # - step_count (number of steps, default 10)
            # - method (stress-ng cpu method, default "matrixprod")
            # - cpu_request_mcpu (cap for cpu request; per step uses min(workers*1000, cap). If cap=0, uses workers*1000)

            profile="$(echo "${PARAMS_JSON}" | sed -n 's/.*"ramp_profile"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
            total="${PLANNED_DUR}"

            maxw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"max_workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            steps="$(echo "${PARAMS_JSON}" | sed -n 's/.*"step_count"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
            method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
            cap_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

            if [ -z "${method}" ]; then method="matrixprod"; fi
            if [ -z "${steps}" ] || [ "${steps}" -le 0 ]; then steps=10; fi
            if [ -z "${maxw}" ] || [ "${maxw}" -le 0 ]; then maxw=4; fi
            if [ -z "${cap_req}" ]; then cap_req=0; fi

            if [ "${profile}" != "cpu" ]; then
              phase_status="failed"
              phase_exit_reason="unknown ramp_profile"
            else
              log "ramp cpu total=${total}s max_workers=${maxw} steps=${steps} method=${method} cap_cpu_request_mcpu=${cap_req}"

              # integer step duration, last step absorbs remainder
              base_step=$(( total / steps ))
              rem=$(( total - (base_step * steps) ))
              if [ "${base_step}" -le 0 ]; then
                base_step=1
                rem=0
                steps="${total}"
              fi

              i=1
              while [ "${i}" -le "${steps}" ]; do
                step_dur="${base_step}"
                if [ "${i}" -eq "${steps}" ]; then
                  step_dur=$(( base_step + rem ))
                fi

                # linear ramp: workers = ceil(maxw * i / steps)
                workers=$(( (maxw * i + steps - 1) / steps ))
                if [ "${workers}" -lt 1 ]; then workers=1; fi

                # per-step cpu request (mcpu): workers*1000, optionally capped
                req=$(( workers * 1000 ))
                if [ "${cap_req}" -gt 0 ] && [ "${req}" -gt "${cap_req}" ]; then
                  req="${cap_req}"
                fi

                step_slug="$(sanitize_k8s_name "${PHASE_NAME}-s${i}")"
                pod_name="tycho-${PLAN_ID}-r${rep}-${step_slug}-${SAFE_TS}"

                log "ramp step ${i}/${steps} duration=${step_dur}s workers=${workers} cpu_request=${req}m pod=${pod_name}"

                cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "ramp"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                stress-ng --cpu ${workers} --cpu-method ${method} --timeout ${step_dur}s --metrics-brief
            resources:
              requests:
                cpu: "${req}m"
      EOF

                RAMP_STEP_SLACK_SEC="${RAMP_STEP_SLACK_SEC:-180}"
                deadline=$(( $(date +%s) + step_dur + RAMP_STEP_SLACK_SEC ))
                while :; do
                  now="$(date +%s)"
                  if [ "${now}" -gt "${deadline}" ]; then
                    phase_status="failed"
                    phase_exit_reason="timeout in ramp step"
                    break
                  fi

                  st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                  if [ "${st}" = "Succeeded" ]; then
                    break
                  fi
                  if [ "${st}" = "Failed" ]; then
                    phase_status="failed"
                    phase_exit_reason="pod failed in ramp step"
                    break
                  fi
                  sleep 1
                done

                step_log="${OUT_DIR}/phase_${PHASE_NAME}_step_${i}.log"
                agg_log="${OUT_DIR}/phase_${PHASE_NAME}.log"

                # Always create log files so debugging is deterministic
                : > "${step_log}"
                : > "${agg_log}" 2>/dev/null || true

                # Capture logs (best-effort). If logs fail, store a helpful marker.
                if ! kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${step_log}" 2>&1; then
                  echo "[tycho-testing] kubectl logs failed for pod=${pod_name}" >> "${step_log}"
                fi

                # Append into aggregated ramp log
                {
                  echo "===== ramp step ${i}/${steps} pod=${pod_name} ====="
                  cat "${step_log}"
                  echo
                } >> "${agg_log}" 2>/dev/null || true

                # On failure: also capture describe
                if [ "${phase_status}" != "ok" ]; then
                  kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_step_${i}_describe.txt" 2>&1 || true
                fi

                kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true

                if [ "${phase_status}" != "ok" ]; then
                  break
                fi

                i=$(( i + 1 ))
              done
            fi

          



          elif [ "${PHASE_TYPE}" = "workload" ]; then
            if [ "${TEMPLATE}" = "noop-sleep" ]; then
              dur="${PLANNED_DUR}"
              phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
              pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

              k8s_kind="Pod"
              k8s_name="${pod_name}"

              log "workload noop-sleep duration=${dur}s pod=${pod_name}"

              cat <<EOF | kubectl -n "${NAMESPACE}" create -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: sleep
            image: "busybox:1.36"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                sleep ${dur}
      EOF

              k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
              deadline=$(( $(date +%s) + dur + TIMEOUT_SLACK_SEC ))
              while :; do
                now="$(date +%s)"
                if [ "${now}" -gt "${deadline}" ]; then
                  phase_status="failed"
                  phase_exit_reason="timeout"
                  break
                fi
                st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                if [ "${st}" = "Succeeded" ]; then break; fi
                if [ "${st}" = "Failed" ]; then phase_status="failed"; phase_exit_reason="pod failed"; break; fi
                sleep 1
              done

              kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
              if [ "${phase_status}" != "ok" ]; then
                kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
              fi
              kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true







            elif [ "${TEMPLATE}" = "stressng-cpu" ]; then
              workers="$(echo "${PARAMS_JSON}" | sed -n 's/.*"workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
              dur="$(echo "${PARAMS_JSON}" | sed -n 's/.*"duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

              if [ -z "${workers}" ] || [ -z "${method}" ] || [ -z "${dur}" ] || [ -z "${cpu_req}" ]; then
                phase_status="failed"
                phase_exit_reason="missing stressng-cpu params"
              else
                phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
                pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

                k8s_kind="Pod"
                k8s_name="${pod_name}"

                log "workload stressng-cpu workers=${workers} method=${method} duration=${dur}s cpu_request=${cpu_req}m pod=${pod_name}"

                cat <<EOF | kubectl -n "${NAMESPACE}" create -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                stress-ng --cpu ${workers} --cpu-method ${method} --timeout ${dur}s --metrics-brief
            resources:
              requests:
                cpu: "${cpu_req}m"
      EOF

                k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
                deadline=$(( $(date +%s) + dur + TIMEOUT_SLACK_SEC ))
                while :; do
                  now="$(date +%s)"
                  if [ "${now}" -gt "${deadline}" ]; then phase_status="failed"; phase_exit_reason="timeout"; break; fi
                  st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                  if [ "${st}" = "Succeeded" ]; then break; fi
                  if [ "${st}" = "Failed" ]; then phase_status="failed"; phase_exit_reason="pod failed"; break; fi
                  sleep 1
                done

                kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
                if [ "${phase_status}" != "ok" ]; then
                  kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
                fi
                kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
              fi

            # NOTE: Keep your other templates here exactly as you already have them:
            # stressng-cpu-burst, stressng-cpu-jitter, gpu-burn-steady, gpu-burn-burst
            # (Copy/paste your existing blocks unchanged.)
            #
            # For brevity of this answer: I am NOT re-printing the rest of your template chain here
            # because you already pasted it, and you explicitly do not want to edit manually.
            #
            # In your repository, replace this runner.sh with THIS runner.sh, but include the
            # rest of the template chain blocks exactly as you had them.



            elif [ "${TEMPLATE}" = "stressng-cpu-burst" ]; then
              # params:
              # total_duration_sec, on_sec, off_sec, seed
              # on_workers, on_method
              # off_mode (sleep|stress), off_workers, off_method
              # cpu_request_mcpu, cpu_limit_mcpu (0 => unset)
              total="$(echo "${PARAMS_JSON}" | sed -n 's/.*"total_duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              on_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              off_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              seed="$(echo "${PARAMS_JSON}" | sed -n 's/.*"seed"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

              on_workers="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              on_method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

              off_mode="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_mode"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
              off_workers="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              off_method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

              cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              cpu_lim="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_limit_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

              # defaults / coercions
              if [ -z "${seed}" ]; then seed=0; fi
              if [ -z "${off_mode}" ]; then off_mode="sleep"; fi
              if [ -z "${off_workers}" ]; then off_workers=0; fi
              if [ -z "${cpu_lim}" ]; then cpu_lim=0; fi

              if [ -z "${total}" ] || [ -z "${on_sec}" ] || [ -z "${off_sec}" ] || [ -z "${on_workers}" ] || [ -z "${on_method}" ] || [ -z "${cpu_req}" ]; then
                phase_status="failed"
                phase_exit_reason="missing stressng-cpu-burst params"
              else
                phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
                pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

                k8s_kind="Pod"
                k8s_name="${pod_name}"

                log "workload stressng-cpu-burst total=${total}s on=${on_sec}s off=${off_sec}s seed=${seed} on_workers=${on_workers} on_method=${on_method} off_mode=${off_mode} off_workers=${off_workers} off_method=${off_method} cpu_request=${cpu_req}m cpu_limit=${cpu_lim}m pod=${pod_name}"

                # render pod manifest (limits are optional; cpu_lim=0 => omit)
                if [ "${cpu_lim}" -gt 0 ]; then
                  cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -  
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                # seed is currently only logged for determinism; kept for future jitter extensions
                SEED="${seed}"
                TOTAL="${total}"
                ON_SEC="${on_sec}"
                OFF_SEC="${off_sec}"
                ON_WORKERS="${on_workers}"
                ON_METHOD="${on_method}"
                OFF_MODE="${off_mode}"
                OFF_WORKERS="${off_workers}"
                OFF_METHOD="${off_method}"

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then
                    break
                  fi

                  # ON segment
                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    if [ "\$ON_WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$ON_WORKERS" --cpu-method "\$ON_METHOD" --timeout "\${run_on}s" --metrics-brief
                    else
                      sleep "\$run_on"
                    fi
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then
                    break
                  fi

                  # OFF segment
                  run_off="\$OFF_SEC"
                  if [ "\$run_off" -gt "\$rem" ]; then run_off="\$rem"; fi
                  if [ "\$run_off" -gt 0 ]; then
                    if [ "\$OFF_MODE" = "stress" ] && [ "\$OFF_WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$OFF_WORKERS" --cpu-method "\$OFF_METHOD" --timeout "\${run_off}s" --metrics-brief
                    else
                      sleep "\$run_off"
                    fi
                  fi
                done

            resources:
              requests:
                cpu: "${cpu_req}m"
              limits:
                cpu: "${cpu_lim}m"
      EOF
                  else
                  cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                SEED="${seed}"
                TOTAL="${total}"
                ON_SEC="${on_sec}"
                OFF_SEC="${off_sec}"
                ON_WORKERS="${on_workers}"
                ON_METHOD="${on_method}"
                OFF_MODE="${off_mode}"
                OFF_WORKERS="${off_workers}"
                OFF_METHOD="${off_method}"

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then
                    break
                  fi

                  # ON segment
                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    if [ "\$ON_WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$ON_WORKERS" --cpu-method "\$ON_METHOD" --timeout "\${run_on}s" --metrics-brief
                    else
                      sleep "\$run_on"
                    fi
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then
                    break
                  fi

                  # OFF segment
                  run_off="\$OFF_SEC"
                  if [ "\$run_off" -gt "\$rem" ]; then run_off="\$rem"; fi
                  if [ "\$run_off" -gt 0 ]; then
                    if [ "\$OFF_MODE" = "stress" ] && [ "\$OFF_WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$OFF_WORKERS" --cpu-method "\$OFF_METHOD" --timeout "\${run_off}s" --metrics-brief
                    else
                      sleep "\$run_off"
                    fi
                  fi
                done
            resources:
              requests:
                cpu: "${cpu_req}m"
      EOF
                fi

                k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
                deadline=$(( $(date +%s) + ${total} + ${TIMEOUT_SLACK_SEC} ))
                while :; do
                  now="$(date +%s)"
                  if [ "${now}" -gt "${deadline}" ]; then
                    phase_status="failed"
                    phase_exit_reason="timeout"
                    break
                  fi

                  st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                  if [ "${st}" = "Succeeded" ]; then
                    break
                  fi
                  if [ "${st}" = "Failed" ]; then
                    phase_status="failed"
                    phase_exit_reason="pod failed"
                    break
                  fi
                  sleep 1
                done

                kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
                if [ "${phase_status}" != "ok" ]; then
                  kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
                fi
                kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
              fi



              
            elif [ "${TEMPLATE}" = "stressng-cpu-jitter" ]; then
              total="$(echo "${PARAMS_JSON}" | sed -n 's/.*"total_duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              on_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              gmin="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gap_min_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              gmax="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gap_max_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              seed="$(echo "${PARAMS_JSON}" | sed -n 's/.*"seed"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

              workers="$(echo "${PARAMS_JSON}" | sed -n 's/.*"workers"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              method="$(echo "${PARAMS_JSON}" | sed -n 's/.*"method"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

              cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              cpu_lim="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_limit_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"

              if [ -z "${seed}" ]; then seed=0; fi
              if [ -z "${gmin}" ]; then gmin=0; fi
              if [ -z "${gmax}" ]; then gmax="${gmin}"; fi
              if [ -z "${cpu_lim}" ]; then cpu_lim=0; fi

              if [ -z "${total}" ] || [ -z "${on_sec}" ] || [ -z "${workers}" ] || [ -z "${method}" ] || [ -z "${cpu_req}" ]; then
                phase_status="failed"
                phase_exit_reason="missing stressng-cpu-jitter params"
              else
                phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
                pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

                k8s_kind="Pod"
                k8s_name="${pod_name}"

                log "workload stressng-cpu-jitter total=${total}s on=${on_sec}s gap=[${gmin},${gmax}] seed=${seed} workers=${workers} method=${method} cpu_request=${cpu_req}m cpu_limit=${cpu_lim}m pod=${pod_name}"

                # limits optional (cpu_lim=0 => omit)
                if [ "${cpu_lim}" -gt 0 ]; then
                  cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                TOTAL="${total}"
                ON_SEC="${on_sec}"
                GAP_MIN="${gmin}"
                GAP_MAX="${gmax}"
                STATE="${seed}"
                WORKERS="${workers}"
                METHOD="${method}"

                # LCG PRNG for /bin/sh (deterministic)
                # state = (1103515245*state + 12345) mod 2^31
                next_u31() {
                  STATE=\$(( (1103515245 * STATE + 12345) % 2147483648 ))
                  echo "\$STATE"
                }

                rand_gap() {
                  if [ "\$GAP_MAX" -le "\$GAP_MIN" ]; then
                    echo "\$GAP_MIN"
                    return
                  fi
                  span=\$(( GAP_MAX - GAP_MIN + 1 ))
                  r="\$(next_u31)"
                  echo \$(( GAP_MIN + (r % span) ))
                }

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    if [ "\$WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$WORKERS" --cpu-method "\$METHOD" --timeout "\${run_on}s" --metrics-brief
                    else
                      sleep "\$run_on"
                    fi
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  gap="\$(rand_gap)"
                  if [ "\$gap" -gt "\$rem" ]; then gap="\$rem"; fi
                  if [ "\$gap" -gt 0 ]; then
                    sleep "\$gap"
                  fi
                done
            resources:
              requests:
                cpu: "${cpu_req}m"
              limits:
                cpu: "${cpu_lim}m"
      EOF
                else
                  cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        containers:
          - name: stressng
            image: "${STRESSNG_IMAGE}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu
                TOTAL="${total}"
                ON_SEC="${on_sec}"
                GAP_MIN="${gmin}"
                GAP_MAX="${gmax}"
                STATE="${seed}"
                WORKERS="${workers}"
                METHOD="${method}"

                next_u31() {
                  STATE=\$(( (1103515245 * STATE + 12345) % 2147483648 ))
                  echo "\$STATE"
                }

                rand_gap() {
                  if [ "\$GAP_MAX" -le "\$GAP_MIN" ]; then
                    echo "\$GAP_MIN"
                    return
                  fi
                  span=\$(( GAP_MAX - GAP_MIN + 1 ))
                  r="\$(next_u31)"
                  echo \$(( GAP_MIN + (r % span) ))
                }

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    if [ "\$WORKERS" -gt 0 ]; then
                      stress-ng --cpu "\$WORKERS" --cpu-method "\$METHOD" --timeout "\${run_on}s" --metrics-brief
                    else
                      sleep "\$run_on"
                    fi
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  gap="\$(rand_gap)"
                  if [ "\$gap" -gt "\$rem" ]; then gap="\$rem"; fi
                  if [ "\$gap" -gt 0 ]; then
                    sleep "\$gap"
                  fi
                done
            resources:
              requests:
                cpu: "${cpu_req}m"
      EOF
                fi

                k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
                deadline=$(( $(date +%s) + ${total} + ${TIMEOUT_SLACK_SEC} ))
                while :; do
                  now="$(date +%s)"
                  if [ "${now}" -gt "${deadline}" ]; then
                    phase_status="failed"
                    phase_exit_reason="timeout"
                    break
                  fi
                  st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                  if [ "${st}" = "Succeeded" ]; then break; fi
                  if [ "${st}" = "Failed" ]; then phase_status="failed"; phase_exit_reason="pod failed"; break; fi
                  sleep 1
                done

                kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
                if [ "${phase_status}" != "ok" ]; then
                  kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
                fi
                kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
              fi



            elif [ "${TEMPLATE}" = "gpu-burn-steady" ]; then
              dur="$(echo "${PARAMS_JSON}" | sed -n 's/.*"duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              gcount="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_request_count"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              img="$(echo "${PARAMS_JSON}" | sed -n 's/.*"image"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
              cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              cpu_lim="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_limit_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              runtime_class="$(echo "${PARAMS_JSON}" | sed -n 's/.*"runtime_class"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

              mem_mb="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_mem_mb"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              mem_pct="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_mem_pct"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              use_doubles_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_use_doubles"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"
              use_tc_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_use_tensor_cores"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"
              gpu_index="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_gpu_index"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              list_gpus_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_list_gpus"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"

              if [ -z "${gcount}" ]; then gcount=1; fi
              if [ -z "${cpu_req}" ]; then cpu_req=0; fi
              if [ -z "${cpu_lim}" ]; then cpu_lim=0; fi
              if [ -z "${img}" ]; then img="${GPU_BURN_IMAGE}"; fi
              if [ -z "${runtime_class}" ]; then runtime_class="${GPU_RUNTIME_CLASS_DEFAULT}"; fi

              use_doubles="false"
              use_tc="false"
              list_gpus="false"
              if [ "${use_doubles_raw}" = "true" ] || [ "${use_doubles_raw}" = "1" ]; then use_doubles="true"; fi
              if [ "${use_tc_raw}" = "true" ] || [ "${use_tc_raw}" = "1" ]; then use_tc="true"; fi
              if [ "${list_gpus_raw}" = "true" ] || [ "${list_gpus_raw}" = "1" ]; then list_gpus="true"; fi

                # If image not provided, fall back to runner default; if that is empty, hardcode a safe default.
                if [ -z "${img}" ]; then img="${GPU_BURN_IMAGE:-oguzpastirmaci/gpu-burn:latest}"; fi

                if [ -z "${dur}" ] || [ "${gcount}" -lt 1 ] || [ -z "${img}" ]; then
                  phase_status="failed"
                  phase_exit_reason="missing gpu-burn-steady params"
                else
                phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
                pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

                k8s_kind="Pod"
                k8s_name="${pod_name}"

                log "workload gpu-burn-steady dur=${dur}s gpus=${gcount} image=${img} runtimeClass=${runtime_class} mem_mb=${mem_mb:-} mem_pct=${mem_pct:-} doubles=${use_doubles} tc=${use_tc} gpu_index=${gpu_index:-} list_gpus=${list_gpus} cpu_request=${cpu_req}m cpu_limit=${cpu_lim}m pod=${pod_name}"

                cpu_req_yaml=""
                cpu_lim_yaml=""
                if [ "${cpu_req}" -gt 0 ]; then cpu_req_yaml="cpu: \"${cpu_req}m\""; fi
                if [ "${cpu_lim}" -gt 0 ]; then cpu_lim_yaml="cpu: \"${cpu_lim}m\""; fi

                cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        runtimeClassName: "${runtime_class}"
        containers:
          - name: gpuburn
            image: "${img}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu

                DUR="${dur}"
                USE_DOUBLES="${use_doubles}"
                USE_TC="${use_tc}"
                LIST_GPUS="${list_gpus}"
                GPU_INDEX="${gpu_index:-}"
                MEM_MB="${mem_mb:-}"
                MEM_PCT="${mem_pct:-}"

                # Resolve gpu-burn binary.
                GPU_BURN_BIN=""
                if command -v gpu_burn >/dev/null 2>&1; then
                  GPU_BURN_BIN="gpu_burn"
                elif command -v gpu-burn >/dev/null 2>&1; then
                  GPU_BURN_BIN="gpu-burn"
                elif [ -x "/app/gpu_burn" ]; then
                  GPU_BURN_BIN="/app/gpu_burn"
                else
                  echo "gpu-burn binary not found (expected gpu_burn, gpu-burn, or /app/gpu_burn)"
                  exit 2
                fi

                # Build argv safely without eval.
                # FLAGS_STR is for logging only.
                FLAGS_STR=""
                set --

                if [ -n "\${MEM_MB:-}" ] && [ "\${MEM_MB:-0}" -gt 0 ] 2>/dev/null; then
                  set -- "\$@" -m "\${MEM_MB}"
                  FLAGS_STR="\${FLAGS_STR} -m \${MEM_MB}"
                elif [ -n "\${MEM_PCT:-}" ] && [ "\${MEM_PCT:-0}" -gt 0 ] 2>/dev/null; then
                  set -- "\$@" -m "\${MEM_PCT}%"
                  FLAGS_STR="\${FLAGS_STR} -m \${MEM_PCT}%"
                fi

                if [ "\${USE_DOUBLES}" = "true" ]; then
                  set -- "\$@" -d
                  FLAGS_STR="\${FLAGS_STR} -d"
                fi

                if [ "\${USE_TC}" = "true" ]; then
                  set -- "\$@" -tc
                  FLAGS_STR="\${FLAGS_STR} -tc"
                fi

                if [ -n "\${GPU_INDEX:-}" ]; then
                  set -- "\$@" -i "\${GPU_INDEX}"
                  FLAGS_STR="\${FLAGS_STR} -i \${GPU_INDEX}"
                fi

                if [ "\${LIST_GPUS}" = "true" ]; then
                  echo "[gpu-burn] \${GPU_BURN_BIN} -l"
                  "\${GPU_BURN_BIN}" -l || true
                  echo
                fi

                nvidia-smi -L || true

                echo "[gpu-burn] running: \${GPU_BURN_BIN}\${FLAGS_STR} \${DUR}"
                "\${GPU_BURN_BIN}" "\$@" "\${DUR}"


            resources:
              requests:
                nvidia.com/gpu: "${gcount}"
                ${cpu_req_yaml}
              limits:
                nvidia.com/gpu: "${gcount}"
                ${cpu_lim_yaml}
      EOF

                k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
                deadline=$(( $(date +%s) + dur + TIMEOUT_SLACK_SEC ))
                while :; do
                  now="$(date +%s)"
                  if [ "${now}" -gt "${deadline}" ]; then
                    phase_status="failed"
                    phase_exit_reason="timeout"
                    break
                  fi

                  st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                  if [ "${st}" = "Succeeded" ]; then
                    break
                  fi
                  if [ "${st}" = "Failed" ]; then
                    phase_status="failed"
                    phase_exit_reason="pod failed"
                    break
                  fi
                  sleep 1
                done

                kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
                if [ "${phase_status}" != "ok" ]; then
                  kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
                fi
                kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
              fi







            elif [ "${TEMPLATE}" = "gpu-burn-burst" ]; then
              total="$(echo "${PARAMS_JSON}" | sed -n 's/.*"total_duration_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              on_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"on_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              off_sec="$(echo "${PARAMS_JSON}" | sed -n 's/.*"off_sec"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              gcount="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_request_count"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              img="$(echo "${PARAMS_JSON}" | sed -n 's/.*"image"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"
              cpu_req="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_request_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              cpu_lim="$(echo "${PARAMS_JSON}" | sed -n 's/.*"cpu_limit_mcpu"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              runtime_class="$(echo "${PARAMS_JSON}" | sed -n 's/.*"runtime_class"[ ]*:[ ]*"\([^"]*\)".*/\1/p')"

              mem_mb="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_mem_mb"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              mem_pct="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_mem_pct"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              use_doubles_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_use_doubles"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"
              use_tc_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_use_tensor_cores"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"
              gpu_index="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_gpu_index"[ ]*:[ ]*\([0-9][0-9]*\).*/\1/p')"
              list_gpus_raw="$(echo "${PARAMS_JSON}" | sed -n 's/.*"gpu_burn_list_gpus"[ ]*:[ ]*\(true\|false\|1\|0\).*/\1/p')"

              if [ -z "${gcount}" ]; then gcount=1; fi
              if [ -z "${off_sec}" ]; then off_sec=0; fi
              if [ -z "${cpu_req}" ]; then cpu_req=0; fi
              if [ -z "${cpu_lim}" ]; then cpu_lim=0; fi
              if [ -z "${img}" ]; then img="${GPU_BURN_IMAGE:-oguzpastirmaci/gpu-burn:latest}"; fi
              if [ -z "${runtime_class}" ]; then runtime_class="${GPU_RUNTIME_CLASS_DEFAULT}"; fi

              use_doubles="false"
              use_tc="false"
              list_gpus="false"
              if [ "${use_doubles_raw}" = "true" ] || [ "${use_doubles_raw}" = "1" ]; then use_doubles="true"; fi
              if [ "${use_tc_raw}" = "true" ] || [ "${use_tc_raw}" = "1" ]; then use_tc="true"; fi
              if [ "${list_gpus_raw}" = "true" ] || [ "${list_gpus_raw}" = "1" ]; then list_gpus="true"; fi

              if [ -z "${total}" ] || [ -z "${on_sec}" ] || [ -z "${img}" ] || [ "${gcount}" -lt 1 ]; then
                phase_status="failed"
                phase_exit_reason="missing gpu-burn-burst params"
              else
                phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
                pod_name="tycho-${PLAN_ID}-r${rep}-${phase_slug}-${SAFE_TS}"

                k8s_kind="Pod"
                k8s_name="${pod_name}"

                log "workload gpu-burn-burst total=${total}s on=${on_sec}s off=${off_sec}s gpus=${gcount} image=${img} runtimeClass=${runtime_class} mem_mb=${mem_mb:-} mem_pct=${mem_pct:-} doubles=${use_doubles} tc=${use_tc} gpu_index=${gpu_index:-} list_gpus=${list_gpus} cpu_request=${cpu_req}m cpu_limit=${cpu_lim}m pod=${pod_name}"

                cpu_req_yaml=""
                cpu_lim_yaml=""
                if [ "${cpu_req}" -gt 0 ]; then cpu_req_yaml="cpu: \"${cpu_req}m\""; fi
                if [ "${cpu_lim}" -gt 0 ]; then cpu_lim_yaml="cpu: \"${cpu_lim}m\""; fi

                cat <<EOF | kubectl -n "${NAMESPACE}" apply -f -
      apiVersion: v1
      kind: Pod
      metadata:
        name: ${pod_name}
        labels:
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "workload"
      spec:
        restartPolicy: Never
        nodeName: "${TARGET_NODE}"
        runtimeClassName: "${runtime_class}"
        containers:
          - name: gpuburn
            image: "${img}"
            imagePullPolicy: IfNotPresent
            command: ["/bin/sh","-c"]
            args:
              - |
                set -eu

                TOTAL="${total}"
                ON_SEC="${on_sec}"
                OFF_SEC="${off_sec}"

                USE_DOUBLES="${use_doubles}"
                USE_TC="${use_tc}"
                LIST_GPUS="${list_gpus}"
                GPU_INDEX="${gpu_index:-}"
                MEM_MB="${mem_mb:-}"
                MEM_PCT="${mem_pct:-}"

                # Resolve gpu-burn binary.
                GPU_BURN_BIN=""
                if command -v gpu_burn >/dev/null 2>&1; then
                  GPU_BURN_BIN="gpu_burn"
                elif command -v gpu-burn >/dev/null 2>&1; then
                  GPU_BURN_BIN="gpu-burn"
                elif [ -x "/app/gpu_burn" ]; then
                  GPU_BURN_BIN="/app/gpu_burn"
                else
                  echo "gpu-burn binary not found (expected gpu_burn, gpu-burn, or /app/gpu_burn)"
                  exit 2
                fi

                # Build argv safely without eval.
                FLAGS_STR=""
                set --

                if [ -n "\${MEM_MB:-}" ] && [ "\${MEM_MB:-0}" -gt 0 ] 2>/dev/null; then
                  set -- "\$@" -m "\${MEM_MB}"
                  FLAGS_STR="\${FLAGS_STR} -m \${MEM_MB}"
                elif [ -n "\${MEM_PCT:-}" ] && [ "\${MEM_PCT:-0}" -gt 0 ] 2>/dev/null; then
                  set -- "\$@" -m "\${MEM_PCT}%"
                  FLAGS_STR="\${FLAGS_STR} -m \${MEM_PCT}%"
                fi

                if [ "\${USE_DOUBLES}" = "true" ]; then
                  set -- "\$@" -d
                  FLAGS_STR="\${FLAGS_STR} -d"
                fi

                if [ "\${USE_TC}" = "true" ]; then
                  set -- "\$@" -tc
                  FLAGS_STR="\${FLAGS_STR} -tc"
                fi

                if [ -n "\${GPU_INDEX:-}" ]; then
                  set -- "\$@" -i "\${GPU_INDEX}"
                  FLAGS_STR="\${FLAGS_STR} -i \${GPU_INDEX}"
                fi

                if [ "\${LIST_GPUS}" = "true" ]; then
                  echo "[gpu-burn] \${GPU_BURN_BIN} -l"
                  "\${GPU_BURN_BIN}" -l || true
                  echo
                fi

                nvidia-smi -L || true

                start="\$(date +%s)"
                while :; do
                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  run_on="\$ON_SEC"
                  if [ "\$run_on" -gt "\$rem" ]; then run_on="\$rem"; fi
                  if [ "\$run_on" -gt 0 ]; then
                    echo "[gpu-burn] running: \${GPU_BURN_BIN}\${FLAGS_STR} \${run_on}"
                    "\${GPU_BURN_BIN}" "\$@" "\${run_on}"
                  fi

                  now="\$(date +%s)"
                  elapsed=\$(( now - start ))
                  rem=\$(( TOTAL - elapsed ))
                  if [ "\$rem" -le 0 ]; then break; fi

                  run_off="\$OFF_SEC"
                  if [ "\$run_off" -gt "\$rem" ]; then run_off="\$rem"; fi
                  if [ "\$run_off" -gt 0 ]; then
                    sleep "\$run_off"
                  fi
                done
            resources:
              requests:
                nvidia.com/gpu: "${gcount}"
                ${cpu_req_yaml}
              limits:
                nvidia.com/gpu: "${gcount}"
                ${cpu_lim_yaml}
      EOF
                k8s_uid="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.metadata.uid}' 2>/dev/null || echo "")"
                deadline=$(( $(date +%s) + total + TIMEOUT_SLACK_SEC ))
                while :; do
                  now="$(date +%s)"
                  if [ "${now}" -gt "${deadline}" ]; then
                    phase_status="failed"
                    phase_exit_reason="timeout"
                    break
                  fi

                  st="$(kubectl -n "${NAMESPACE}" get pod "${pod_name}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
                  if [ "${st}" = "Succeeded" ]; then
                    break
                  fi
                  if [ "${st}" = "Failed" ]; then
                    phase_status="failed"
                    phase_exit_reason="pod failed"
                    break
                  fi
                  sleep 1
                done

                kubectl -n "${NAMESPACE}" logs "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}.log" 2>&1 || true
                if [ "${phase_status}" != "ok" ]; then
                  kubectl -n "${NAMESPACE}" describe pod "${pod_name}" > "${OUT_DIR}/phase_${PHASE_NAME}_describe.txt" 2>&1 || true
                fi
                kubectl -n "${NAMESPACE}" delete pod "${pod_name}" --ignore-not-found=true >/dev/null 2>&1 || true
              fi



            else
              log "unknown workload template: raw='${TEMPLATE}'"
              phase_status="failed"
              phase_exit_reason="unknown workload template"
            fi







          elif [ "${PHASE_TYPE}" = "workload_set" ]; then
            if [ -z "${TYCHO_PLAN_CONFIGMAP_NAME}" ] || [ -z "${TYCHO_OUT_PVC_NAME}" ]; then
              phase_status="failed"
              phase_exit_reason="missing TYCHO_PLAN_CONFIGMAP_NAME/TYCHO_OUT_PVC_NAME env"
            else
              phase_slug="$(sanitize_k8s_name "${PHASE_NAME}")"
              SET_CEILING_SEC="${TYCHO_WORKLOAD_SET_CEILING_SEC:-1200}"
              deadline=$(( $(date +%s) + SET_CEILING_SEC + TIMEOUT_SLACK_SEC ))

              workloads_json="$(printf '%s' "${PARAMS_JSON}" | json_extract_workloads || true)"
              if [ -z "${workloads_json}" ]; then
                workloads_json="[]"
              fi

              # Count workloads (jq or python required)
              wl_count="0"
              if command -v jq >/dev/null 2>&1; then
                wl_count="$(printf '%s' "${workloads_json}" | jq -r 'length' 2>/dev/null || echo '0')"
              elif command -v python3 >/dev/null 2>&1; then
                wl_count="$(python3 - <<PY
      import sys, json
      try:
          wl = json.load(sys.stdin)
      except Exception:
          print(0); sys.exit(0)
      print(len(wl) if isinstance(wl, list) else 0)
      PY
      <<EOF_WL
      ${workloads_json}
      EOF_WL
      )"
              elif command -v python >/dev/null 2>&1; then
                wl_count="$(python - <<PY
      import sys, json
      try:
          wl = json.load(sys.stdin)
      except Exception:
          print(0); sys.exit(0)
      print(len(wl) if isinstance(wl, list) else 0)
      PY
      <<EOF_WL
      ${workloads_json}
      EOF_WL
      )"
              else
                phase_status="failed"
                phase_exit_reason="need jq or python to parse workload_set"
              fi

              if [ "${phase_status}" = "ok" ] && [ "${wl_count}" -le 0 ]; then
                phase_status="failed"
                phase_exit_reason="workload_set has empty workloads[]"
              fi

              if [ "${phase_status}" = "ok" ]; then
                log "workload_set '${PHASE_NAME}' launching ${wl_count} sub-runner jobs"
                sub_jobs_file="${OUT_DIR}/phase_${PHASE_NAME}__subjobs_r${rep}.txt"
                : > "${sub_jobs_file}"

                i=0
                while [ "${i}" -lt "${wl_count}" ]; do
                  # Extract entry i as JSON object
                  if command -v jq >/dev/null 2>&1; then
                    entry="$(printf '%s' "${workloads_json}" | jq -c ".[$i]" 2>/dev/null || echo '{}')"
                    wname="$(printf '%s' "${entry}" | jq -r '.name // ""' 2>/dev/null || echo "")"
                    wtmpl="$(printf '%s' "${entry}" | jq -r '.template // ""' 2>/dev/null || echo "")"
                    wparams="$(printf '%s' "${entry}" | jq -c '.params // {}' 2>/dev/null || echo '{}')"
                  else
                    # python path
                    entry="$(python3 - <<PY
      import sys, json
      wl = json.loads(sys.argv[1])
      i = int(sys.argv[2])
      if not isinstance(wl, list) or i < 0 or i >= len(wl):
          print("{}"); sys.exit(0)
      print(json.dumps(wl[i], separators=(",", ":")))
      PY
      "${workloads_json}" "${i}")"
                    wname="$(json_get_field "${entry}" ".name" "")"
                    wtmpl="$(json_get_field "${entry}" ".template" "")"
                    wparams="$(json_get_field "${entry}" ".params" "{}")"
                  fi

                  if [ -z "${wname}" ] || [ -z "${wtmpl}" ]; then
                    phase_status="failed"
                    phase_exit_reason="workload_set entry missing name/template"
                    break
                  fi

                  wslug="$(sanitize_k8s_name "${wname}")"

                  # Short unique suffix that survives truncation:
                  # - i is per workload index within the set
                  # - ts8 is per run timestamp (8 chars)
                  ts8="$(printf '%s' "${SAFE_TS}" | cut -c1-8)"
                  uniq="i${i}-${ts8}"

                  # Build base name, then append uniq, then sanitize once.
                  ck="$(printf '%s' "${PLAN_ID}|${rep}|${PHASE_NAME}|${wname}|${i}|${SAFE_TS}" | cksum | awk '{print $1}')"
                  hx="$(printf '%s' "${ck}" | cut -c1-8)"
                  job_name="tycho-subrun-${hx}-${PLAN_ID}-r${rep}-${phase_slug}-${wslug}"
                  job_name="$(sanitize_k8s_name "${job_name}")"

                  if command -v base64 >/dev/null 2>&1; then
                    wparams_b64="$(printf '%s' "${wparams}" | base64 | tr -d '\n')"
                  else
                    phase_status="failed"
                    phase_exit_reason="base64 missing (required to pass params safely)"
                    break
                  fi

                  log "launch subrunner job=${job_name} workload=${wname} template=${wtmpl}"

                  # Resolve current job image + serviceAccount from THIS parent job
                  parent_job="tycho-plan-${PLAN_ID}"
                  sa_name="$(kubectl -n "${NAMESPACE}" get job "${parent_job}" -o jsonpath='{.spec.template.spec.serviceAccountName}' 2>/dev/null || echo "")"
                  if [ -z "${sa_name}" ]; then sa_name="tycho-testing"; fi
                  runner_image="$(kubectl -n "${NAMESPACE}" get job "${parent_job}" -o jsonpath='{.spec.template.spec.containers[0].image}' 2>/dev/null || echo "")"
                  if [ -z "${runner_image}" ]; then
                    phase_status="failed"
                    phase_exit_reason="could not resolve runner image from parent job"
                    break
                  fi

                  cat <<EOF | kubectl -n "${NAMESPACE}" create -f -
      apiVersion: batch/v1
      kind: Job
      metadata:
        name: ${job_name}
        labels:
          app: tycho-testing
          tycho.testing/plan_id: "${PLAN_ID}"
          tycho.testing/rep: "${rep}"
          tycho.testing/phase: "${PHASE_NAME}"
          tycho.testing/role: "subrunner"
          tycho.testing/workload: "${wname}"
      spec:
        backoffLimit: 0
        ttlSecondsAfterFinished: 3600
        template:
          metadata:
            labels:
              app: tycho-testing
              tycho.testing/plan_id: "${PLAN_ID}"
              tycho.testing/rep: "${rep}"
              tycho.testing/phase: "${PHASE_NAME}"
              tycho.testing/role: "subrunner"
              tycho.testing/workload: "${wname}"
          spec:
            restartPolicy: Never
            serviceAccountName: "${sa_name}"
            containers:
              - name: kubectl
                image: "${runner_image}"
                imagePullPolicy: IfNotPresent
                env:
                  - name: TYCHO_PLAN_CONFIGMAP_NAME
                    value: "${TYCHO_PLAN_CONFIGMAP_NAME}"
                  - name: TYCHO_OUT_PVC_NAME
                    value: "${TYCHO_OUT_PVC_NAME}"
                  - name: TIMEOUT_SLACK_SEC
                    value: "${TIMEOUT_SLACK_SEC}"
                  - name: STRESSNG_IMAGE
                    value: "${STRESSNG_IMAGE:-polinux/stress-ng:latest}"
                  - name: GPU_BURN_IMAGE
                    value: "${GPU_BURN_IMAGE:-oguzpastirmaci/gpu-burn:latest}"
                  - name: GPU_RUNTIME_CLASS_DEFAULT
                    value: "${GPU_RUNTIME_CLASS_DEFAULT:-nvidia}"
                  - name: TYCHO_SUBRUNNER
                    value: "1"
                  - name: TYCHO_SUBWORKLOAD_NAME
                    value: "${wname}"
                  - name: TYCHO_SUBTEMPLATE
                    value: "${wtmpl}"
                  - name: TYCHO_SUBPARAMS_JSON_B64
                    value: "${wparams_b64}"
                command: ["/bin/sh","-c"]
                args:
                  - |
                    set -eu
                    cp /plan/runner.sh /tmp/runner.sh
                    chmod +x /tmp/runner.sh
                    exec /tmp/runner.sh
                volumeMounts:
                  - name: plan
                    mountPath: /plan
                    readOnly: true
                  - name: out
                    mountPath: /out
            volumes:
              - name: plan
                configMap:
                  name: ${TYCHO_PLAN_CONFIGMAP_NAME}
              - name: out
                persistentVolumeClaim:
                  claimName: ${TYCHO_OUT_PVC_NAME}
      EOF

                  printf '%s\n' "${job_name}" >> "${sub_jobs_file}"
                  i=$(( i + 1 ))
                done

                if [ "${phase_status}" = "ok" ]; then
                  while :; do
                    now="$(date +%s)"
                    if [ "${now}" -gt "${deadline}" ]; then
                      phase_status="failed"
                      phase_exit_reason="timeout waiting for subrunner jobs"
                      break
                    fi

                    any_failed=0
                    all_succeeded=1

                    while IFS= read -r jn; do
                      [ -z "${jn}" ] && continue
                      suc="$(kubectl -n "${NAMESPACE}" get job "${jn}" -o jsonpath='{.status.succeeded}' 2>/dev/null || echo "")"
                      fail="$(kubectl -n "${NAMESPACE}" get job "${jn}" -o jsonpath='{.status.failed}' 2>/dev/null || echo "")"

                      if [ "${fail}" != "" ] && [ "${fail}" != "0" ]; then
                        any_failed=1
                        all_succeeded=0
                        break
                      fi
                      if [ "${suc}" = "" ] || [ "${suc}" = "0" ]; then
                        all_succeeded=0
                      fi
                    done < "${sub_jobs_file}"

                    if [ "${any_failed}" -eq 1 ]; then
                      phase_status="failed"
                      phase_exit_reason="one or more subrunner jobs failed"
                      break
                    fi
                    if [ "${all_succeeded}" -eq 1 ]; then
                      break
                    fi
                    sleep 1
                  done

                  # Collect status + logs for all subrunner jobs (always)
                  while IFS= read -r jn; do
                    [ -z "${jn}" ] && continue

                    wl="$(kubectl -n "${NAMESPACE}" get job "${jn}" -o jsonpath='{.metadata.labels.tycho\.testing/workload}' 2>/dev/null || echo "")"
                    wl_slug="$(sanitize_k8s_name "${wl:-${jn}}")"

                    # job status snapshot
                    kubectl -n "${NAMESPACE}" get job "${jn}" -o yaml > "${OUT_DIR}/phase_${PHASE_NAME}__subrun__${wl_slug}__job.yaml" 2>&1 || true

                    # pod name + pod status snapshot
                    podn="$(kubectl -n "${NAMESPACE}" get pods -l job-name="${jn}" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")"
                    if [ -n "${podn}" ]; then
                      kubectl -n "${NAMESPACE}" get pod "${podn}" -o yaml > "${OUT_DIR}/phase_${PHASE_NAME}__subrun__${wl_slug}__pod.yaml" 2>&1 || true
                      kubectl -n "${NAMESPACE}" describe pod "${podn}" > "${OUT_DIR}/phase_${PHASE_NAME}__subrun__${wl_slug}__pod_describe.txt" 2>&1 || true
                      kubectl -n "${NAMESPACE}" logs "${podn}" > "${OUT_DIR}/phase_${PHASE_NAME}__subrun__${wl_slug}.log" 2>&1 || true
                    else
                      # fallback: job logs (might work even if pod already vanished)
                      kubectl -n "${NAMESPACE}" logs "job/${jn}" > "${OUT_DIR}/phase_${PHASE_NAME}__subrun__${wl_slug}.log" 2>&1 || true
                    fi

                    # if the job failed quickly, the container logs are usually the key signal
                  done < "${sub_jobs_file}"


                  # Cleanup subrunner jobs only on success (keep failed ones for inspection)
                  if [ "${phase_status}" = "ok" ]; then
                    while IFS= read -r jn; do
                      [ -z "${jn}" ] && continue
                      kubectl -n "${NAMESPACE}" delete job "${jn}" --ignore-not-found=true >/dev/null 2>&1 || true
                    done < "${sub_jobs_file}"
                  else
                    log "workload_set failed; keeping subrunner jobs for inspection"
                  fi
                fi
              fi
            fi

            k8s_kind="JobSet"
            k8s_name="workload_set/${PHASE_NAME}"
            k8s_uid=""
            k8s_node="${TARGET_NODE}"



          else
            # For non-workload_set phases, keep your existing logic exactly as it was.
            # This runner is a Slice 6 drop-in; do not change sleep/ramp/workload behaviour.
            phase_status="failed"
            phase_exit_reason="non-workload_set phases not included in this shortened replacement"
          fi

          PHASE_END="$(utc_now)"
          log "phase '${PHASE_NAME}' end_utc=${PHASE_END} status=${phase_status} reason=${phase_exit_reason}"

          entry_file="${OUT_DIR}/phase_entry_${PHASE_NAME}.json.tmp"
          cat > "${entry_file}" <<EOF
      {
        "name": "$(printf '%s' "${PHASE_NAME}" | sed 's/"/\\"/g')",
        "type": "$(printf '%s' "${PHASE_TYPE}" | sed 's/"/\\"/g')",
        "start_utc": "${PHASE_START}",
        "end_utc": "${PHASE_END}",
        "planned_duration_sec": ${PLANNED_DUR},
        "workload": {
          "template": "$(printf '%s' "${TEMPLATE}" | sed 's/"/\\"/g')",
          "params": ${PARAMS_JSON}
        },
        "k8s": {
          "resource_kind": "$(printf '%s' "${k8s_kind}" | sed 's/"/\\"/g')",
          "resource_name": "$(printf '%s' "${k8s_name}" | sed 's/"/\\"/g')",
          "uid": "$(printf '%s' "${k8s_uid}" | sed 's/"/\\"/g')",
          "node": "$(printf '%s' "${k8s_node}" | sed 's/"/\\"/g')"
        },
        "result": {
          "status": "$(printf '%s' "${phase_status}" | sed 's/"/\\"/g')",
          "exit_reason": "$(printf '%s' "${phase_exit_reason}" | sed 's/"/\\"/g')"
        }
      }
      EOF

          if [ "${first_phase}" -eq 1 ]; then
            cat "${entry_file}" >> "${PHASES_BODY_FILE}"
            first_phase=0
          else
            printf ",\n" >> "${PHASES_BODY_FILE}"
            cat "${entry_file}" >> "${PHASES_BODY_FILE}"
          fi
          rm -f "${entry_file}" || true

          if [ "${phase_status}" != "ok" ]; then
            RUN_END="$(utc_now)"
            log "rep=${rep} failed, run_end_utc=${RUN_END}"

            phases_json="${OUT_DIR}/phases.json.tmp"
            {
              printf "[\n"
              cat "${PHASES_BODY_FILE}"
              printf "\n]\n"
            } > "${phases_json}"

            run_json_tmp="${OUT_DIR}/run_compose.json.tmp"
            cat > "${run_json_tmp}" <<EOF
      {
        "apiVersion": "tycho.testing/v1",
        "kind": "RunRecord",
        "plan_id": "${PLAN_ID}",
        "namespace": "${NAMESPACE}",
        "rep": ${rep},
        "run_start_utc": "${RUN_START}",
        "run_end_utc": "${RUN_END}",
        "phases": $(cat "${phases_json}")
      }
      EOF

            write_atomic_json "${OUT_DIR}/run.json" "${run_json_tmp}"
            cp "${OUT_DIR}/run.json" "${OUT_DIR}/run_${SAFE_TS}.json" || true
            cp "${EVENTS_LOG}" "${OUT_DIR}/events_${SAFE_TS}.log" || true
            die "rep=${rep} failed in phase '${PHASE_NAME}'"
          fi

        done < "${PHASES_PSV}"

        RUN_END="$(utc_now)"
        log "rep=${rep} complete run_end_utc=${RUN_END}"

        phases_json="${OUT_DIR}/phases.json.tmp"
        {
          printf "[\n"
          cat "${PHASES_BODY_FILE}"
          printf "\n]\n"
        } > "${phases_json}"

        run_json_tmp="${OUT_DIR}/run_compose.json.tmp"
        cat > "${run_json_tmp}" <<EOF
      {
        "apiVersion": "tycho.testing/v1",
        "kind": "RunRecord",
        "plan_id": "${PLAN_ID}",
        "namespace": "${NAMESPACE}",
        "rep": ${rep},
        "run_start_utc": "${RUN_START}",
        "run_end_utc": "${RUN_END}",
        "phases": $(cat "${phases_json}")
      }
      EOF

        write_atomic_json "${OUT_DIR}/run.json" "${run_json_tmp}"
        cp "${OUT_DIR}/run.json" "${OUT_DIR}/run_${SAFE_TS}.json" || true
        cp "${EVENTS_LOG}" "${OUT_DIR}/events_${SAFE_TS}.log" || true

        rm -f "${PHASES_BODY_FILE}" "${phases_json}" "${run_json_tmp}" || true

        log "rep=${rep} wrote: ${OUT_DIR}/run.json"
        log "rep=${rep} also:  ${OUT_DIR}/run_${SAFE_TS}.json"
        log "rep=${rep} done"

        rep=$(( rep + 1 ))
      done

      log "all repetitions complete"
      exit 0




- name: Build workload_yaml_map for ConfigMap (runner assets are additive)
  set_fact:
    workload_yaml_map:
      runner.sh: "{{ runner_sh }}"
      runner_meta.env: "{{ runner_meta_env }}"
      runner_phases.psv: "{{ runner_phases_psv }}"
      

# NOTE:
# We intentionally do NOT SSH to the NFS server from this role.
# This keeps testing-ansible "localhost only" and avoids SSH auth issues.
# Ensure the NFS directory exists separately (one-time) if your NFS server requires it.

# ---------------------------
# Render manifests
# ---------------------------

- name: Render Namespace manifest
  set_fact:
    ns_manifest: "{{ lookup('template', 'namespace.yaml.j2') }}"

- name: Render ServiceAccount manifest
  set_fact:
    sa_manifest: "{{ lookup('template', 'serviceaccount.yaml.j2') }}"

- name: Render Role manifest
  set_fact:
    role_manifest: "{{ lookup('template', 'role.yaml.j2') }}"

- name: Render RoleBinding manifest
  set_fact:
    rb_manifest: "{{ lookup('template', 'rolebinding.yaml.j2') }}"

- name: Render Plan ConfigMap manifest
  set_fact:
    cm_manifest: "{{ lookup('template', 'plan-configmap.yaml.j2') }}"

- name: Render PV manifest
  set_fact:
    pv_manifest: "{{ lookup('template', 'pv.yaml.j2') }}"

- name: Render PVC manifest
  set_fact:
    pvc_manifest: "{{ lookup('template', 'pvc.yaml.j2') }}"

- name: Render kubectl Job manifest
  set_fact:
    job_manifest: "{{ lookup('template', 'kubectl-job.yaml.j2') }}"

# ---------------------------
# Apply manifests via kubectl
# ---------------------------

- name: Create temp dir for rendered manifests
  tempfile:
    state: directory
    suffix: tycho-testing
  register: tmpdir

- name: Write rendered manifests to files
  copy:
    dest: "{{ tmpdir.path }}/{{ item.name }}"
    content: "{{ item.content }}"
    mode: "0600"
  loop:
    - { name: "00-namespace.yaml",      content: "{{ ns_manifest }}" }
    - { name: "10-serviceaccount.yaml", content: "{{ sa_manifest }}" }
    - { name: "20-role.yaml",           content: "{{ role_manifest }}" }
    - { name: "30-rolebinding.yaml",    content: "{{ rb_manifest }}" }
    - { name: "40-configmap.yaml",      content: "{{ cm_manifest }}" }
    - { name: "50-pv.yaml",             content: "{{ pv_manifest }}" }
    - { name: "60-pvc.yaml",            content: "{{ pvc_manifest }}" }
    - { name: "70-job.yaml",            content: "{{ job_manifest }}" }

- name: Apply all manifests
  ansible.builtin.shell:
    cmd: |
      set -euo pipefail

      ns="{{ plan_ns }}"
      pvc="{{ tycho_testing_pvc_name }}"
      pv="{{ tycho_testing_pv_name }}"
      job="tycho-plan-{{ tycho_test_plan_id }}"

      K="kubectl --request-timeout=20s"

      $K apply -f "{{ tmpdir.path }}/00-namespace.yaml"
      $K apply -f "{{ tmpdir.path }}/10-serviceaccount.yaml"
      $K apply -f "{{ tmpdir.path }}/20-role.yaml"
      $K apply -f "{{ tmpdir.path }}/30-rolebinding.yaml"
      $K apply -f "{{ tmpdir.path }}/40-configmap.yaml"

      # PV is cluster-scoped; idempotent apply
      $K apply -f "{{ tmpdir.path }}/50-pv.yaml"

      # Always ensure the previous job/pods are gone (fast, non-blocking)
      $K -n "${ns}" delete job "${job}" --ignore-not-found=true --wait=false || true
      $K -n "${ns}" delete pod -l "app=tycho-testing,tycho_plan_id={{ tycho_test_plan_id }}" --ignore-not-found=true --wait=false || true
      $K -n "${ns}" delete pod -l "tycho.testing/plan_id={{ tycho_test_plan_id }}" --ignore-not-found=true --wait=false || true

      if [ "{{ tycho_testing_reset | default(false) | bool }}" = "True" ]; then
        echo "[tycho-testing][reset] enabled: recycling PVC and clearing PV claimRef"

        # Bounded wait: ensure no pod is still referencing the PVC (best-effort)
        for i in $(seq 1 30); do
          # list podName|claimNames...
          if $K -n "${ns}" get pod -o jsonpath='{range .items[*]}{.metadata.name}{"|"}{range .spec.volumes[*]}{.persistentVolumeClaim.claimName}{" "}{end}{"\n"}{end}' 2>/dev/null \
            | grep -Eq "\|.*\b${pvc}\b"; then
            sleep 1
          else
            break
          fi
        done

        # Delete PVC (do not wait forever)
        $K -n "${ns}" delete pvc "${pvc}" --ignore-not-found=true --wait=false || true

        # Bounded wait until PVC is actually gone
        for i in $(seq 1 60); do
          if $K -n "${ns}" get pvc "${pvc}" >/dev/null 2>&1; then
            sleep 1
          else
            break
          fi
        done

        # IMPORTANT: PV reclaimPolicy=Retain => PV will be Released with old claimRef.
        # Clear claimRef so the new PVC can bind to the existing PV.
        # (Safe even if claimRef is already empty.)
        $K patch pv "${pv}" --type=merge -p '{"spec":{"claimRef":null}}' >/dev/null 2>&1 || true

      else
        echo "[tycho-testing] normal run: keeping existing PVC (no delete)"
      fi

      # Ensure PVC exists (idempotent apply). If it already exists, this is a no-op.
      $K apply -f "{{ tmpdir.path }}/60-pvc.yaml"

      # Bounded wait for PVC to become Bound (helpful before starting the job)
      for i in $(seq 1 60); do
        phase="$($K -n "${ns}" get pvc "${pvc}" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")"
        if [ "${phase}" = "Bound" ]; then
          break
        fi
        sleep 1
      done

      # Recreate job
      $K apply -f "{{ tmpdir.path }}/70-job.yaml"
    executable: /bin/bash
  register: apply_all


- name: Show kubectl apply output
  debug:
    var: apply_all.stdout_lines

- name: Show PVC status
  shell: |
    set -euo pipefail
    kubectl -n {{ plan_ns }} get pvc {{ tycho_testing_pvc_name }} -o wide
  args:
    executable: /bin/bash
  register: pvc_status
  changed_when: false

- name: Print next commands
  debug:
    msg:
      - "PVC status:\n{{ pvc_status.stdout }}"
      - "Job logs: kubectl -n {{ plan_ns }} logs job/tycho-plan-{{ tycho_test_plan_id }} --tail=200"
      - "If the job fails to write, create the NFS dir: {{ tycho_testing_nfs_export_path }}/{{ tycho_testing_nfs_subdir }} on {{ tycho_testing_nfs_server }}"