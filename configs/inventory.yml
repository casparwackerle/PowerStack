k3s_cluster:
  children:
    server:
      hosts:
        160.85.30.104:                  # This is the public IP of the control plane node
           node_name: ho1
           internal_ip: 192.168.0.104   # Internal IP for the control plane
           external_ip: 160.85.30.104   # External IP for the control plane
           BMC_ip: 160.85.30.101
           disk_for_persistent_storage: /dev/sdd
    agent:
      hosts:
        160.85.30.105:                  # Public IP of worker node 1
           node_name: ho2
           internal_ip: 192.168.0.105   # Internal IP of worker node 1
           BMC_ip: 160.85.30.102
           disk_for_testing: /dev/sdb
        160.85.30.106:                  # Public IP of worker node 2
           node_name: ho3
           internal_ip: 192.168.0.106   # Internal IP of worker node 2
           BMC_ip: 160.85.30.103
           disk_for_testing: /dev/sdb

  # Required Vars
  vars:
    # ansible
    control_node_name: ho1
    ansible_port: 22
    ansible_user: ubuntu
    k3s_version: v1.30.2+k3s1
    token: "{{ ansible_vault.token }}"
    api_endpoint: "{{ hostvars[groups['server'][0]]['ansible_host'] | default(groups['server'][0]) }}"
    extra_server_args: "--node-ip={{ hostvars[inventory_hostname]['internal_ip'] }}  --tls-san={{ hostvars[inventory_hostname]['external_ip'] }}"
    extra_agent_args: "--node-ip={{ hostvars[inventory_hostname]['internal_ip'] }}"
    cluster_context: "powerstack"
    
    # rancher
    rancher_hostname: rancher.local
    bootstrapPassword: "{{ ansible_vault.bootstrapPassword }}"

    # NFS on server disk (disk to be formatted is specified above)
    nfs_network: 192.168.0.0/24
    export_path: /mnt/data

    # kubernetes pv and pvc
    storageclass_name: local-nfs
    storage_accessmode: ReadWriteMany
    
    # persistentVolumeReclaimPolicy: Retain
    pv_name: nfs-pv
    pvc_name: nfs-pvc
    storageclass_size: 150Gi            # Must fit on SSD and be more than the sum of all PV
    pv_size_grafana: 10Gi         
    pvc_size_grafana: 10Gi              # CANNOT exceed corresponding PV size
    pv_size_prometheus: 50Gi      
    pvc_size_prometheus: 50Gi           # CANNOT exceed corresponding PV size
    pv_size_alertmanager: 5Gi
    pvc_size_alertmanager: 5Gi          # CANNOT exceed corresponding PV size
    
    # Monitoring Stack
    monitoring_stack_repo_url: https://prometheus-community.github.io/helm-charts
    #grafana_admin_password: {{ ansible_vault.grafanaAdminPassword }}
    monitoring_namespace: monitoring
    testing_namespace: testing  #careful: Testing scripts are not adjusted automatically
    prometheus_scrape_interval: 10s

    # NodePorts. MUST BE BETWEEN 30000 AND 32767
    #rancher_custom_nodeport: 30001     # does not work, reachable instead on {{rancher_hostname}}
    prometheus_custom_nodeport: 30002
    grafana_custom_nodeport: 30003
    alertmanager_custom_nodeport: 30004
      
    # Kepler
    kepler_namespace: kepler
    kepler_repo_url: https://sustainable-computing-io.github.io/kepler-helm-chart
    
    # benchmarking
    benchmarking_namespace: benchmarking
    k_bench_repo: https://github.com/vmware-tanzu/k-bench.git
    perf_tests_repo: https://github.com/kubernetes/perf-tests.git
    kubectl_version: v3.31.3

    # Optional vars
    
    # api_port: 6443
    # k3s_server_location: /var/lib/rancher/k3s
    # systemd_dir: /etc/systemd/system
    # extra_service_envs: [ 'ENV_VAR1=VALUE1', 'ENV_VAR2=VALUE2' ]
    # user_kubectl: true, by default kubectl is symlinked and configured for use by ansible_user. Set to false to only kubectl via root user.

    # Manifests or Airgap should be either full paths or relative to the playbook directory.
    # List of locally available manifests to apply to the cluster, useful for PVCs or Traefik modifications.
    # extra_manifests: [ '/path/to/manifest1.yaml', '/path/to/manifest2.yaml' ]
    # airgap_dir: /tmp/k3s-airgap-images

    # server_config_yaml:  |
    #   This is now an inner yaml file. Maintain the indentation.
    #   YAML here will be placed as the content of /etc/rancher/k3s/config.yaml
    #   See https://docs.k3s.io/installation/configuration#configuration-file
    # registries_config_yaml:  |
    #   Containerd can be configured to connect to private registries and use them to pull images as needed by the kubelet.
    #   YAML here will be placed as the content of /etc/rancher/k3s/registries.yaml
    #   See https://docs.k3s.io/installation/private-registry
