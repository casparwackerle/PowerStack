\chapter{Background and Related Research}
\label{ch:background}

% This chapter surveys existing research and practical knowledge about server-level
% energy measurement, hardware and software telemetry sources, and attribution tools.
% It provides the empirical and factual basis for the conceptual foundations in
% Chapter~\ref{ch:concepts}. This chapter MUST NOT contain Tycho design decisions,
% conceptual attribution models, or implementation details.

\noindent This chapter summarises the current state of research and industrial knowledge on server-level energy measurement. Its focus is limited to what the literature reports about available telemetry sources, measurement techniques, and existing attribution tools. The discussion is descriptive rather than conceptual: it does not introduce attribution principles, methodological reasoning, or design considerations, which are addressed in \chapref{ch:concepts}. Extended background material is available in \hyperref[appendix_vt2]{Appendix~A} and the present chapter integrates only those findings that are directly relevant for understanding the research landscape.

\section{Energy Measurement in Modern Server Systems}
\label{sec:energy_measurement_systems}

The energy consumption of modern servers arises from a heterogeneous set of subsystems, including CPUs, GPUs, memory, storage devices, network interfaces, and platform management components. Prior research highlights that these subsystems expose highly unequal visibility into their power behaviour, since measurement capabilities, granularity, and accuracy differ significantly across hardware generations and vendors \parencite{lin2020taxonomy, long2022review}. Some domains provide direct telemetry, while others can only be approximated through software-derived activity metrics. As a result, no single interface offers complete or temporally consistent power information, and most studies rely on a single source or combine multiple sources to approximate system-level consumption. This fragmented measurement landscape forms the basis for much of the existing work on power modelling, validation, and multi-source energy estimation in server environments.

\subsection{Energy Attribution in Multi-Tenant Environments}
\label{subsec:attribution_context}

Several studies identify containerised and multi-tenant systems as challenging environments for energy attribution. Containers share the host kernel and rely on common processor, memory, storage, and network subsystems, which removes the isolation boundaries present in virtual machines and prevents direct measurement of per-container power. Research reports that workloads running concurrently on the same node create interference effects across hardware domains, leading to utilisation patterns that correlate only loosely with actual energy consumption \parencite{lin2020taxonomy}. Modern orchestration platforms further increase attribution difficulty through highly dynamic execution behaviour: containers are created, destroyed, and rescheduled at high frequency, often numbering in the thousands on large clusters. These rapid lifecycle changes produce volatile metadata and short-lived resource traces that are difficult to align with node-level telemetry. Collectively, the literature treats container-level energy attribution as an estimation problem constrained by incomplete observability, heterogeneous measurement quality, and continuous runtime churn.

\subsection{Telemetry Layers in Contemporary Architectures}
\label{subsec:telemetry_layers}

Modern servers expose power and activity information through two largely independent telemetry layers. The first consists of in-band mechanisms that are visible to the operating system, including on-die energy counters, GPU management interfaces, and kernel-level resource statistics. These interfaces typically offer higher sampling rates and finer granularity, but their accuracy and coverage vary across hardware generations and vendors. Prior work notes that in-band telemetry often represents estimated rather than directly measured power and that several domains, such as network and storage devices, expose only partial or indirect information.

The second layer is out-of-band telemetry provided by baseboard management controllers through interfaces such as IPMI or Redfish. These systems aggregate sensor readings independently of the host and report stable, whole-system power values at coarse temporal resolution. Empirical studies show that out-of-band telemetry provides useful system-level accuracy, although update intervals and measurement precision differ substantially between vendors \parencite{wang2019empirical}. Compared with instrument-based measurements, which remain the benchmark for high-fidelity evaluation but are impractical at scale, both in-band and out-of-band methods represent trade-offs between granularity, availability, and measurement reliability.

Combined, these layers form a heterogeneous telemetry landscape in which sampling rates, accuracy, and domain coverage differ significantly, motivating the use of multi-source measurement approaches in research.

\subsection{Challenges for Container-Level Measurement}
\label{subsec:container_challenges}

Existing research identifies several factors that complicate accurate energy measurement for containerised workloads. Large-scale trace analyses show that cloud environments exhibit substantial churn, with many tasks being short-lived and resource demands changing rapidly over time \parencite{reissHeterogeneityDynamicityClouds2012}. Such dynamism limits the observability of fine-grained resource usage and makes it difficult to capture short execution intervals with sufficient temporal resolution.

Monitoring studies further report inconsistencies across the different layers that expose resource information for containers. In multi-cloud settings, observability often depends on heterogeneous monitoring stacks, leading to fragmented visibility and non-uniform coverage of system activity \parencite{waseemContainerizationMultiCloudEnvironment2025}. Even within a single host, performance counters obtained from container-level interfaces may diverge from system-level measurements. Empirical evaluations demonstrate that container-level CPU and I/O counters can underestimate actual activity by a non-negligible margin, and that co-located workloads introduce contention effects that distort these metrics \parencite{casalicchioStateoftheartContainerTechnologies2020}.

These findings indicate that container-level measurement operates under conditions of rapid workload turnover, heterogeneous monitoring behaviour, and imperfect resource visibility. As a consequence, the literature treats container energy attribution as a problem constrained by incomplete and potentially biased measurement signals rather than as a directly measurable quantity.


\section{Hardware and Software Telemetry Sources}
\label{sec:measurement_techniques}

This section outlines the primary telemetry sources used to observe power and resource behaviour in modern server systems. It summarises established research on external measurement devices, firmware-level interfaces, on-die energy counters, accelerator telemetry, and kernel-exposed resource metrics. The emphasis is on reporting the properties and empirical characteristics documented in prior work, without interpreting these signals conceptually or analysing their temporal behaviour, which are addressed in later sections. A comprehensive technical discussion is provided in \appchapterref{A}{vt2_Chapter2}; the present section extracts only the findings relevant for understanding the measurement landscape.

\subsection{Direct Hardware Measurement}
\label{subsec:direct_measurement}

Direct physical instrumentation remains the most accurate method for measuring server power consumption. External power meters or inline shunt-based devices can capture node-level energy usage with high fidelity, and research frequently uses such instrumentation as a ground truth for validating software-reported power values. Studies employing dedicated measurement setups, such as custom DIMM-level sensing boards, demonstrate that high-frequency sampling and component-level granularity are technically feasible but require bespoke hardware and non-trivial integration effort \parencite{desrochers2016validation}. Lin et al.\ classify these approaches as offering very high data credibility but only coarse spatial granularity and limited scalability in operational environments \parencite{lin2020taxonomy}.

Recent work on specialised sensors, such as the PowerSensor3 platform\parencite{van2025powersensor3} for high-rate voltage and current monitoring of GPUs and other accelerators, illustrates ongoing interest in hardware-centric power measurement. However, these systems share the same fundamental drawback: deployment across production servers is complex, costly, and incompatible with large-scale or multi-tenant settings. As a consequence, direct instrumentation is predominantly used in controlled experiments or for validation of other telemetry sources, rather than as a primary measurement mechanism in real-world server infrastructures.

\subsection{Legacy Telemetry Interfaces (ACPI, IPMI)}
\label{subsec:legacy_telemetry}

Early power-related telemetry on server platforms was primarily exposed through ACPI and IPMI. ACPI provides a standardised interface for configuring and controlling hardware power states, but it does not offer real-time energy or power readings. The interface exposes only abstract performance and idle states defined by the firmware \parencite{uefi_acpi_6_6}, and these states do not include the instantaneous power information required for empirical energy measurement. Consequently, ACPI has seen little use in modern power estimation research.

IPMI, accessed through the baseboard management controller, represents an older class of out-of-band telemetry that predates Redfish. Although widely supported across server hardware, IPMI power values are known to be coarse, slowly refreshed, and often inaccurate when compared with external instrumentation. Empirical studies report multi-second averaging windows, substantial quantisation effects, and unreliable idle power readings \parencite{kavanagh2016accuracy, kavanagh2019rapid}. These limitations, together with the availability of more precise alternatives, have led IPMI to be largely superseded by Redfish on contemporary server platforms.

\subsection{Redfish Power Telemetry}
\label{subsec:redfish}

Redfish is the modern out-of-band management interface available on contemporary server platforms and is designed as the successor to IPMI. It exposes system-level telemetry through a RESTful API implemented on the baseboard management controller (BMC), providing access to whole-node power readings derived from on-board sensors. Prior work consistently shows that Redfish delivers higher precision than IPMI, with lower quantisation artefacts and more stable readings across power ranges \parencite{wang2019empirical}. In controlled experiments, Redfish achieved a mean absolute percentage error of roughly three percent when compared to a high-accuracy power analyser, outperforming IPMI in all evaluated power intervals.

A key limitation of Redfish is its temporal granularity. Empirical studies report that power values exhibit non-negligible staleness, with refresh delays of approximately 200\,ms \parencite{wang2019empirical}. This latency restricts the ability of Redfish to capture short bursts of activity or rapid fluctuations in dynamic workloads. Accuracy and responsiveness also vary across vendors, reflecting differences in embedded sensors, BMC firmware, and management controller architectures.

The interface is widely deployed in real-world infrastructure. Modern enterprise servers from Dell, HPE, Lenovo, Cisco, and Supermicro routinely expose power telemetry via Redfish as part of their standard BMC firmware \parencite{herrlinAccessingOnboardServer2021}. Out-of-band monitoring studies further highlight that Redfish avoids the overheads and failure modes associated with in-band agents \parencite{aliRedfishNagiosScalableOutofBand2022}. In practice, Redfish implementations tend to provide stable low-frequency updates suitable for coarse-grained power reporting.

Preliminary measurements conducted for this thesis also observed irregular update intervals on the evaluated hardware, occasionally extending into the multi-second range. While this behaviour is specific to a single system and not generalisable, it reinforces the literature’s position that Redfish telemetry exhibits meaningful vendor-dependent variability and remains unsuitable for fine-grained temporal correlation.

Overall, Redfish provides accessible, reliable whole-node power telemetry at coarse temporal resolutions, making it valuable for long-interval monitoring and for validating other measurement sources, but inappropriate for attributing energy consumption to short-lived or rapidly fluctuating containerised workloads.

\subsection{RAPL Power Domains}
\label{subsec:rapl}

Running Average Power Limit (RAPL) provides hardware-backed energy counters for several internal power domains of a processor package. Originally introduced by Intel and later adopted in a compatible form by AMD, RAPL exposes energy measurements via model-specific registers that can be accessed directly or through higher-level interfaces such as the Linux \texttt{powercap} framework or the \texttt{perf-events} subsystem \parencite{intel-sdm, raffin2024dissecting}. Raffin et~al.\ provide a detailed comparison of these access mechanisms, noting that MSR, powercap, perf-events, and eBPF differ mainly in convenience, required privileges, and robustness; all can retrieve equivalent RAPL readings when implemented correctly \parencite{raffin2024dissecting}. They recommend accessing RAPL via the powercap interface, which is easiest to implement reliably and suffers from no overhead penalties when compared with more low-level methods.

Intel platforms typically expose several well-established RAPL domains, including the processor package, the core subsystem, and (on many server architectures) a DRAM domain \parencite{hackenberg2015energy}. These domains have been validated extensively against external measurement equipment. Studies report that the combination of package and DRAM energy tracks CPU-and-memory power with good accuracy from Haswell onwards, which has led to RAPL becoming the primary fine-grained energy source in server-oriented research \parencite{hackenberg2013power, desrochers2016validation, alt2024experimental, kennes2023measuring}. More recent work on hybrid architectures such as Alder Lake confirms that RAPL continues to correlate well with external measurements under load, while precision decreases somewhat in low-power regimes \parencite{schone2024energy}. Across these studies, RAPL is generally regarded as sufficiently accurate for scientific analysis when its domain boundaries and update characteristics are considered \parencite{raffin2024dissecting}.

AMD implements a RAPL-compatible interface with a similar programming model but a reduced set of domains. Zen 1 through Zen 4 processors expose package and core domains only, without a dedicated DRAM domain \parencite{schone2021energy, raffin2024dissecting}. Sch\"one et~al.\ show that, as a consequence, memory-related energy may not be represented explicitly in AMD’s RAPL output, leading to a smaller portion of total system energy being observable through the package domain alone \parencite{schone2021energy}. This limitation primarily concerns domain completeness rather than measurement correctness: for compute-intensive workloads, package-domain values behave consistently, but workloads with significant memory activity exhibit a larger gap relative to whole-system measurements because DRAM energy is not separately reported. Raffin et~al.\ further note that, on the evaluated Zen-based server, different kernel interfaces initially exposed inconsistent domain sets; this was later corrected upstream, illustrating that AMD support is evolving and still maturing within the Linux ecosystem \parencite{raffin2024dissecting}.

Technical considerations also apply to both Intel and AMD platforms. RAPL counters have finite width and wrap after sufficiently large energy accumulation, requiring consumers to implement overflow correction \parencite{khan2018rapl, raffin2024dissecting}. The counters do not include timestamps, and empirical work shows that actual update intervals may deviate from nominal values, complicating precise temporal correlation with other telemetry \parencite{hackenberg2013power, jay2023experimental}. On some Intel platforms, security hardening measures such as energy filtering reduce temporal granularity for certain domains to mitigate side-channel risks \parencite{lipp2021platypus, intel2023, schone2024energy}. In virtualised environments, RAPL access may be trapped by the hypervisor, increasing latency and introducing small deviations from bare-metal behaviour \parencite{jay2023experimental}.

In summary, RAPL provides a widely used and comparatively fine-grained source of processor-side energy telemetry. Intel platforms typically offer multiple validated domains, including DRAM, enabling a broader view of CPU-and-memory energy. AMD platforms expose fewer domains and therefore provide a more limited perspective on total system power, particularly for memory-intensive workloads. These differences in domain coverage, measurement scope, and software integration need to be taken into account when using RAPL as a basis for energy analysis.

%--------------------------------------------------------------------
\subsection{GPU Telemetry (NVML)}
\label{subsec:nvml}

NVIDIA GPUs expose power, utilization, and device-state information through the
\textit{NVIDIA Management Library} (NVML), which forms the basis of commonly used tools
such as \texttt{nvidia-smi}.  
In Kubernetes and other distributed environments, NVML is the most widely supported
interface for obtaining GPU-level telemetry without additional hardware support.

NVML provides several metrics relevant to energy analysis.  
\emph{Instantaneous power} represents a smoothed estimate of board-level power draw, while
\emph{energy counters} are available only on selected data-center GPUs and implement a
coarse-grained cumulative measurement.  
\emph{GPU utilization}, frequently misinterpreted, denotes the percentage of time during
which the GPU reports any active workload, not the fraction of compute resources used
\parencite{weakleyMonitoringCharacterizingGPU2025}.  
Additional fields include memory utilization, temperature, clock frequencies, and throttle
state.

Recent empirical studies show that NVML telemetry is shaped by internal sampling and
averaging behaviour rather than by high-frequency sensor access.  
Yang~et~al.\ demonstrate across more than seventy devices—from Ampere to Hopper—that NVML
produces fresh power samples only intermittently and applies temporal smoothing, leading
to underrepresentation of short-lived activity and delayed adjustment during sudden power
changes.  
Despite these limitations, steady-state power values typically deviate by only a few
percent from external measurements on modern data-center GPUs.

A detailed analysis on the Grace--Hopper GH200 further clarifies these effects:
Hernandez~et~al.\ show that NVML reflects an internal one-second averaging interval on
this architecture, causing transient peaks to be smoothed out and short kernels to be
misestimated by more than twenty percent
\parencite{hernandezPreliminaryStudyFineGrained2025}.  
Higher-frequency interfaces such as the Linux \texttt{hwmon} subsystem reveal fine-grained
fluctuations that NVML cannot represent.

Overall, NVML provides broadly accessible and reasonably accurate GPU telemetry for
medium-granularity power and utilization assessment, but its internal averaging,
architecture-dependent update behaviour, and limited temporal fidelity impose clear
constraints.  
These characteristics define the practical scope within which NVML-based GPU measurements
can be interpreted, while more

%--------------------------------------------------------------------
\subsection{Software-Exposed Resource Metrics}
\label{subsec:software_metrics}

% This merged section replaces three previous subsections.

% Placeholder (1 page):
% - Summarise kernel-exposed CPU time accounting, I/O statistics, network counters.
% - Mention missing or unusable telemetry for NICs, storage, PCIe.
% - Describe how literature treats model-based estimation (regression, AI models).
% - Emphasise limitations such as missing domains and poor applicability.
% - DO NOT explain conceptual interpretation of resource counters 
%   (reserved for Chapter 3).
% - DO NOT mix with attribution philosophies.

%====================================================================
\section{Temporal Behaviour of Telemetry Sources}
\label{sec:temporal_behaviour}
A comprehensive treatment can be found in \appchapterref{A}{vt2_Chapter2}, but the following discussion focuses on the aspects relevant for the present thesis.

% This section synthesises multi-source timing behaviour based on empirical research.
% It must NOT introduce conceptual timing theory (Chapter 3).

%--------------------------------------------------------------------
\subsection{Sampling Characteristics and Update Cycles} --------->> MERGE WITH NEXT SECTION:
\label{subsec:temporal_sampling}

% Placeholder (0.5–0.7 page):
% - Describe research findings on RAPL, NVML, Redfish update intervals.
% - Include empirical observations of nondeterministic refresh times.
% - DO NOT explain sampling vs event-time (Chapter 3).
% - DO NOT introduce timing models.

%--------------------------------------------------------------------
\subsection{Sensor-Internal Averaging and Missing Timestamps}
\label{subsec:averaging_timestamps}

% Placeholder (0.5 page):
% - Summarise research showing lack of timestamps in RAPL and NVML.
% - Mention internal sensor averaging reported in literature.
% - DO NOT describe conceptual implications for attribution (Chapter 3).

%--------------------------------------------------------------------
\subsection{Domain Boundary Ambiguity}
\label{subsec:domain_ambiguity}

% Placeholder (0.5 page):
% - Summarise research showing uncertain boundaries of RAPL domains.
% - Mention MIG-related ambiguity for GPU domains.
% - DO NOT explain conceptual importance of domains (Chapter 3).

%--------------------------------------------------------------------
\subsection{Validation Methodologies in Prior Research}
\label{subsec:validation_methods}

% Placeholder (0.5 page):
% - Summarise how prior studies validated measurements (meters, cross-domain comparison).
% - Discuss known limitations.
% - DO NOT discuss how validation will be performed in this thesis.
% - Keep strictly historical/literature-based.

%====================================================================
\section{Existing Tools and Related Work}
\label{sec:related_tools}
\appchapterref{A}{vt2_Chapter4}
% Expected length: 3–4 pages.
% DO NOT discuss Tycho or Tycho architecture.
% DO summarise empirical findings from prior work (Kepler, Kubewatt, others).

%--------------------------------------------------------------------
\subsection{General Tools (Brief Overview)} ->>>>In “Existing Tools,” potentially merge “General Tools” + short mentions of other tools into a single paragraph
\label{subsec:general_tools}

% Placeholder (0.3 page):
% - Briefly summarise Scaphandre, Smartwatts, and 1–2 other tools.
% - Emphasise their measurement scope and known limitations.
% - DO NOT provide conceptual attribution explanation (Chapter 3).
% - Keep this high-level and concise.

%--------------------------------------------------------------------
\subsection{Kepler}
\label{subsec:kepler}

% Placeholder (1.5–2.0 pages):
% - Describe Kepler’s architecture based purely on literature:
%   * metric sources
%   * ratio-based attribution strategy
%   * sampling behaviour
% - Summarise empirical misattribution issues identified by research and VT2:
%   * idle power artefacts
%   * latency mismatch
%   * short-lived workload instability
%   * system-process handling issues
% - Emphasise Kepler's shift toward deployability (literature statements).
% - DO NOT mention Tycho, Tycho improvements, or motivation for Tycho.

%--------------------------------------------------------------------
\subsection{Kubewatt}
\label{subsec:kubewatt}

% Placeholder (1.0–1.5 pages):
% - Summarise Kubewatt’s findings validating Kepler:
%   * incorrect idle attribution
%   * metadata/race-condition problems
%   * visibility issues with completed pods
% - Summarise Kubewatt’s improvements:
%   * static vs dynamic separation
%   * simplified proportional models
% - Summarise Kubewatt’s limitations as reported in thesis:
%   * missing domains
%   * limited metric scope
%   * no calibration
% - DO NOT reference Tycho or compare to Tycho.

%====================================================================
\section{Research Gaps}
\label{sec:research_gaps}

% This section synthesises gaps identified throughout Chapter 2.
% ABSOLUTELY NO Tycho discussion.
% NO conceptual discussion (that belongs to Chapter 3).

%--------------------------------------------------------------------
\subsection{Gap 1: Temporal Misalignment}
\label{subsec:gap_temporal}

% Placeholder (0.5 page):
% - Integrate research showing misaligned update intervals and delays.
% - DO NOT discuss strategies for alignment (Chapter 3 or 4).

%--------------------------------------------------------------------
\subsection{Gap 2: Missing Timestamps and Averaging}
\label{subsec:gap_timestamps}

% Placeholder (0.3 page):
% - Summarise lack of timestamps and internal averaging as documented by research.

%--------------------------------------------------------------------
\subsection{Gap 3: Domain Boundary Ambiguity}
\label{subsec:gap_boundaries}

% Placeholder (0.3–0.5 page):
% - Integrate findings on poorly documented boundaries (RAPL, MIG).

%--------------------------------------------------------------------
\subsection{Gap 4: Metadata-Lifecycle Inconsistencies}
\label{subsec:gap_metadata}

% Placeholder (0.3–0.5 page):
% - Synthesise research showing cgroup/pod lifecycle inconsistencies.

%--------------------------------------------------------------------
\subsection{Gap 5: Idle Power Attribution Issues}
\label{subsec:gap_idle}

% Placeholder (0.3 page):
% - Highlight known issues in idle power handling.

%--------------------------------------------------------------------
\subsection{Gap 6: Limited Multi-Domain Integration}
\label{subsec:gap_multidomain}

% Placeholder (0.3 page):
% - Summarise research noting lack of integrated CPU–GPU–system attribution.

%--------------------------------------------------------------------
\subsection{Gap 7: Missing Calibration and Uncertainty Treatment}
\label{subsec:gap_calibration}

% Placeholder (0.3–0.5 page):
% - Summarise research calling for calibration or uncertainty-aware methods.

%====================================================================
\section{Summary}
\label{sec:background_summary}

% Placeholder (0.5 page):
% - Summarise fundamental insights: heterogeneous telemetry behaviour, 
%   incomplete domain coverage, lifecycle inconsistency, lack of calibration.
% - Prepare the reader for Chapter 3, stating explicitly that Chapter 3
%   provides the conceptual foundations needed to understand the design 
%   of an accuracy-oriented system (without yet describing Tycho).

