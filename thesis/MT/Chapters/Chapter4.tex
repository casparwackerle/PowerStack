\chapter{System Architecture}
\label{ch:architecture}

\section{Guiding Principles}
\label{subsec:guiding_principles}

Tycho’s architecture is shaped by a small set of foundational principles that govern how measurements are interpreted, combined and ultimately attributed. These principles are architectural in nature: they articulate \emph{how} the system must reason about observations, not \emph{how} it is implemented. They establish the conceptual baseline that the subsequent sections refine in detail.

\begin{itemize}[leftmargin=1.2em]
    \item \textbf{Accuracy-first temporal coherence.}
    Architectural decisions prioritise the reconstruction of temporally coherent views of system behaviour. Observations are treated as samples of an underlying physical process, and the architecture is designed to preserve their temporal meaning rather than force periodic alignment.

    \item \textbf{Domain-aware interpretation.}
    Metric sources differ in semantics and cadence. The architecture respects these differences and avoids imposing artificial synchrony or uniform sampling behaviour across heterogeneous domains.

    \item \textbf{Transparency of assumptions.}
    All modelling assumptions must be explicit, inspectable and externally visible. The architecture prohibits implicit corrections or hidden inference steps that would obscure how measurements lead to attribution results.

    \item \textbf{Uncertainty as a first-class concept.}
    Missing, stale or delayed information is treated as uncertainty rather than error. Architectural components convey and preserve uncertainty so that later stages may interpret it correctly.

    \item \textbf{Separation of observation, timing and attribution.}
    Measurement collection, temporal interpretation and energy attribution form distinct architectural layers. This separation prevents cross-coupling, clarifies responsibilities and ensures that improvements in one layer do not implicitly alter the behaviour of others.
\end{itemize}
\section{Traceability to Requirements}
\label{subsec:req_traceability}

The architectural structure introduced in this chapter provides a direct response to the requirements established in \S~\ref{sec:conceptual_requirements}. Each requirement class corresponds to specific architectural mechanisms, ensuring that the system design follows from formal constraints rather than implementation convenience.

\textbf{Requirement: Temporal Coherence.}
Satisfied through event-time reconstruction, independent collector timelines, and window-based temporal alignment.

\textbf{Requirement: Domain-Level Consistency.}
Addressed by per-domain interpretation layers, domain-aware handling of metric semantics, and explicit decomposition of node-level signals.

\textbf{Requirement: Cross-Domain Reconciliation.}
Supported by a unified temporal model, window-level aggregation boundaries, and explicit reconciliation logic across domains during analysis.

\textbf{Requirement: Consistent Metric Interpretation.}
Ensured by separating observation from interpretation, enforcing stable metric semantics within each domain, and isolating heterogeneous metrics into dedicated processing paths.

\textbf{Requirement: Transparent Modelling Assumptions.}
Realised through explicit modelling steps, external visibility of assumptions, and separation between measured and inferred quantities.

\textbf{Requirement: Lifecycle-Robust Attribution.}
Enabled by metadata freshness guarantees, stable process–container mapping, and attribution rules that remain valid under workload churn.

\textbf{Requirement: Uncertainty-Aware Attribution.}
Supported by explicit treatment of stale or missing data, uncertainty propagation in window evaluation, and preservation of unexplained residuals.

\section{High-Level Architecture}
\label{sec:high_level_architecture}

\subsection{Subsystem Overview}
\label{subsec:subsystem_overview}

Tycho is organised into a small set of subsystems, each with a distinct responsibility. The following overview introduces these subsystems without yet describing their interactions.

\textbf{Timing engine.}
Defines the temporal reference used throughout the system and provides the notion of analysis windows. It is responsible for deciding when a window is complete and ready to be evaluated.

\textbf{Metric collectors.}
Acquire observations from hardware and software sources and attach timestamps in the global temporal reference. They expose their output as streams of samples without coordinating with each other.

\textbf{Metadata subsystem.}
Maintains the mapping between operating-system level entities and workload identities. It tracks relationships between processes, cgroups, containers and pods over time.

\textbf{Buffering and storage layer.}
Stores recent observations in bounded histories so that samples relevant to a given window can be retrieved efficiently. It treats metric streams and metadata as read-mostly records.

\textbf{Analysis engine.}
Interprets temporally aligned observations and metadata to produce energy estimates for each analysis window. It forms the logical bridge between measurement and attribution.

\textbf{Calibration framework.}
Derives auxiliary information about typical delays, update patterns and idle behaviour. It produces constraints and characterisations that other subsystems rely on for interpretation.

\textbf{Exporter.}
Exposes the results of the analysis engine to external monitoring systems as metrics ready for scraping and downstream processing.

\subsection{Dataflow and Control Flow}
\label{subsec:dataflow_control}

Before Tycho enters normal operation, external calibration scripts determine approximate delay characteristics for all relevant metric sources. At startup, Tycho’s internal calibration component derives suitable polling frequencies for metric collectors and metadata acquisition, providing the initial operating parameters for the system.

During runtime, control flow originates in the timing engine. It triggers each collector according to its calibrated polling frequency, but collectors operate independently: they sample their respective domains without synchronising with each other, and each sample is appended to the appropriate buffer together with its timestamp and quality indicators. In parallel, metadata acquisition proceeds on its own schedule, refreshing the mappings between processes, cgroups and workload identities in the metadata cache.

The timing engine also governs when analysis occurs. At regular intervals—constituting fixed-length analysis windows—it initiates a new evaluation cycle irrespective of how many samples have been collected. Each cycle begins by estimating idle behaviour for the relevant hardware domains based on the buffered observations. The analysis engine then interprets the buffered metric samples, the metadata cache and the idle characterisations, taking calibrated delays into account when reconstructing the temporal structure of the window. It produces per-window energy estimates for all domains and workloads.

Once analysis completes, the exporter publishes the resulting metrics in a form suitable for ingestion by external monitoring systems. Calibration remains active in the background throughout the system’s lifetime: it observes collector behaviour and derived quantities over longer time spans and refines its characterisations when needed, informing both the timing and analysis components without altering any collected data.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/drawio/tycho_architecture_high.png}
    \caption[Subsystem Architecure, Dataflow and Control Flow]{Subsystem Architecure, Dataflow and Control Flow}
    \label{vt1_fig:tycho_architecture_high}
\end{figure}

\section{Temporal Model and Timing Engine}
\label{sec:timing_engine}

Tycho’s temporal architecture provides a coherent framework for relating heterogeneous metric streams to fixed-duration analysis windows. It establishes a common time base, defines how collectors operate, and specifies how windows are formed and interpreted. The model is intentionally simple: collectors run independently, timestamps reflect poll time, and all temporal reasoning occurs during analysis.

% ----------------------------------------------------------------------
\subsection{Event-Time Model and Timestamp Semantics}
\label{subsec:event_time}

Tycho adopts a single monotonic time base for all temporal coordination. Collectors timestamp each sample at the moment of observation; these timestamps reflect poll time, not the physical instant at which the underlying hardware event occurred. Event time is therefore a modelling construct used by the analysis engine when interpreting delay, freshness and update behaviour.

This separation keeps collectors lightweight and domain-agnostic. Each collector reports only what it directly observes; the analysis engine later interprets these timestamps in context, using calibration-derived delay characteristics to approximate underlying temporal structure.
% ----------------------------------------------------------------------
\subsection{Independent Collector Schedules}
\label{subsec:independent_timelines}

Tycho employs independent, domain-aware sampling schedules. During startup the timing engine configures one schedule per collector, after which each collector operates autonomously on its own periodic trigger. No global poll loop exists and collectors do not synchronise with one another. They push samples only when a new observation is available.

This decoupling avoids artificial temporal alignment and preserves each domain’s intrinsic update behaviour. Collector timestamps are placed directly on the global monotonic time axis, allowing later reconstruction without imposing shared cadence or shared sampling semantics.

% ----------------------------------------------------------------------
\subsection{Window Construction and Analysis Triggering}
\label{subsec:window_construction}

Analysis proceeds in fixed-duration windows defined solely by periodic triggers from the timing engine. If the triggers occur at monotonic times \(T_0, T_1, T_2, \dots\), window \(W_i\) is the half-open interval \([T_i, T_{i+1})\). Window duration is nominally constant but may drift slightly, which is acceptable for attribution.

When a window closes, the analysis engine performs two conceptual phases:

\begin{enumerate}[label=(\roman*)]
\item \emph{idle characterisation}, using long-term buffered history across all relevant domains, and  
\item \emph{window reconstruction and attribution}, using all samples whose timestamps precede \(T_{i+1}\).
\end{enumerate}

Only energy for the current window is attributed and exported, but additional historical samples inform delay interpretation, idle estimation and interpolation.

Tycho treats domains asymmetrically: CPU and software metrics are always required; GPU and Redfish domains contribute when available. Samples too old to fall within the current window do not contribute directly but may still inform background characterisation. Windows remain valid when optional domains are absent.

A sample is considered stale relative to a window when its poll timestamp predates \(T_i\) by more than a domain-specific tolerance. Stale samples are ignored for direct reconstruction but do not invalidate the window.

\begin{figure}[H]
    \centering

    % Define custom color
    \definecolor{windowblue}{HTML}{BDC6FF}
    \colorlet{windowblueA}{windowblue!40}

    \begin{tikzpicture}[
        >=Stealth,
        scale=1,
        every node/.style={font=\small}
    ]

    % Time axis
    \draw[->] (0,0) -- (11,0) node[anchor=west] {time};

    % Window boundaries
    \draw[very thick] (3,0.2) -- (3,-0.2);
    \draw[very thick] (8,0.2) -- (8,-0.2);
    \node[below] at (3,-0.2) {$T_i$};
    \node[below] at (8,-0.2) {$T_{i+1}$};

    % Window highlight with your color
    \draw[fill=windowblueA, draw=none] (3,0.3) rectangle (8,4.1);
    \node[below] at (5.5,4.1) {Window $W_i = [T_i, T_{i+1})$};

    % Collector lines
    \node[left] at (0,1) {Collector C};
    \draw (0,1) -- (10.5,1);

    \node[left] at (0,2) {Collector B};
    \draw (0,2) -- (10.5,2);

    \node[left] at (0,3) {Collector A};
    \draw (0,3) -- (10.5,3);

    % Samples for A
    \foreach \x/\style in {1/gray, 3.5/black, 6.2/black, 9/gray} {
        \draw[thick,\style] (\x,0.8) -- (\x,1.2);
    }

    % Samples for B
    \foreach \x/\style in {2.5/gray, 3.2/black, 4.1/black, 7.9/black, 9.5/gray} {
        \draw[thick,\style] (\x,1.8) -- (\x,2.2);
    }

    % Samples for C
    \foreach \x/\style in {2/gray, 5.0/black, 8.5/gray} {
        \draw[thick,\style] (\x,2.8) -- (\x,3.2);
    }

    \node[gray] at (1.0,0.4) {outside window};
    \node[gray] at (9.3,0.4) {outside window};

    \end{tikzpicture}

    \caption{Analysis window $W_i$ in relation to collectors}
    \label{fig:window_alignment}
\end{figure}


\subsection{Comparison to Kepler Timing Model}
\label{subsec:kepler_comparison}

Kepler employs a synchronous timing model in which all metric domains (except Redfish) are sampled within a single periodic poll cycle (default: 3 seconds). This fixed-length interval defines both the sampling cadence and the logical unit of attribution. Redfish updates occur at a much slower rate (default: 60 seconds), and the most recent Redfish value is reused across multiple attribution intervals. Export occurs on a separate cadence, which may not align with the attribution window.

Tycho diverges fundamentally: collectors run independently, analysis windows are defined by attribution triggers rather than poll cycles, heterogeneous update patterns are supported natively, and export occurs immediately after each attribution step. This structure enables finer temporal resolution, avoids dependence on synchronous polling behaviour, and eliminates inconsistencies between data collection and publishing intervals.

Figures~\ref{vt1_fig:tycho_timingDiagram} and \ref{vt1_fig:kepler_timingDiagram} illustrate the respective timing behaviour of Tycho and Kepler, highlighting their polling patterns, sampling semantics and analysis-window alignment. Figures~\ref{vt1_fig:tycho_timingDiagram_high} and \ref{vt1_fig:kepler_timingDiagram_high} provide a higher-level view to show the Prometheus export behaviour more clearly.

\begin{figure}[H]
    \centering
    \begin{subfigure}{1\textwidth}
        \includegraphics[width=\textwidth]{Figures/drawio/tycho_timingDiagram.png}
        \caption{Tycho Timing Model}
        \label{vt1_fig:tycho_timingDiagram}
    \end{subfigure}
    \begin{subfigure}{1\textwidth}
        \includegraphics[width=\textwidth]{Figures/drawio/kepler_timingDiagram.png}
        \caption{Kepler Timing Model}
        \label{vt1_fig:kepler_timingDiagram}
    \end{subfigure}
    \caption[Comparison between Tycho and KeplerTiming Model]{Comparison: Tycho and Kepler Timing Model}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.85\textwidth}
        \includegraphics[width=\textwidth]{Figures/drawio/tycho_timingDiagram_high.png}
        \caption{Tycho Prometheus Export Timing Model}
        \label{vt1_fig:tycho_timingDiagram_high}
    \end{subfigure}
        \begin{subfigure}{0.85\textwidth}
        \includegraphics[width=\textwidth]{Figures/drawio/kepler_timingDiagram_high.png}
        \caption{Kepler Prometheus Export Timing Model}
        \label{vt1_fig:kepler_timingDiagram_high}
    \end{subfigure}
    \caption[Comparison between Tycho and Kepler export behaviour]{Comparison: Tycho and Kepler export behaviour}
\end{figure}




% ----------------------------------------------------------------------
\section{Metric Sources as Temporal Actors}
\label{sec:metric_sources}

% OVERALL LENGTH:
%   ~3–4 pages including one diagram (NVML phase-aware sketch).
%   This section is conceptual and emphasises *temporal characteristics* of
%   each metric source, not technical APIs or implementation detail.
%
% PURPOSE:
%   Present each domain not as a collector implementation but as a *temporal
%   signal* with characteristic behaviour, constraints, and uncertainties.
%   This sets up the attribution logic in later sections (especially domain
%   consistency and uncertainty handling).

% ----------------------------------------------------------------------
\subsection{eBPF and Software Counters}
\label{subsec:ebpf_temporal}

The eBPF and software counter domain represents Tycho’s event-driven view of CPU activity.
Unlike hardware domains that report values at fixed sampling times, this domain emits utilisation information at the moment execution changes occur.
These events form a temporally dense and workload dependent signal that describes how the processor is shared between user tasks, kernel work, interrupt handling, and idle execution.
All higher level aggregation occurs in userspace and is decoupled from the event timing itself.

The domain contributes three classes of metrics with distinct temporal behaviour.
\begin{itemize}
    \item Event driven metrics capture transitions in processor ownership. They reflect the precise time when a task begins or ends its use of CPU resources and therefore provide exact temporal boundaries for attribution windows.
    \item Cumulative counters accumulate durations or activity over time and expose their values whenever the collector retrieves them. The effective resolution of these counters is defined by the polling interval rather than by internal update frequency.
    \item Quasi-instantaneous counters represent hardware performance information sampled at activity boundaries. Although they are observed at discrete points, their semantics remain tied to the execution periods they describe.
\end{itemize}

Two architectural properties follow from this structure.
Event driven updates introduce no domain delay and therefore require no delay calibration.
They also permit the collector to operate with an arbitrary polling cadence because temporal alignment is already guaranteed by the event timestamps.
In Tycho the default interval matches the RAPL window for convenience rather than correctness.
In addition, each event carries the current container context, which ensures that attribution remains correct when workloads migrate across control groups.

Within Tycho’s temporal model this domain occupies a special role.
It passively accumulates fine grained ownership information and exposes it at window boundaries without influencing the timing of these windows.
Its signals also form a complete temporal partition of CPU activity within each analysis interval, which supports proportional attribution and reduces uncertainty in downstream energy modelling.
At the architectural level, this domain therefore defines the most precise and temporally coherent view of processor utilisation available to the system.

\subsection{RAPL Domains}
\label{subsec:rapl_temporal}

RAPL provides cumulative energy readings for a set of logical CPU related domains such as package, cores, uncore, and memory.  
Each domain exposes a monotonically increasing counter that reflects the total energy consumed since a hardware defined reference point.  
These counters advance independently of Tycho’s sampling schedule and represent the continuous energy behaviour of the processor.

Within Tycho these cumulative counters are observed at fixed tick boundaries.  
At each tick the system records the current value for all available domains, and the energy associated with that interval follows from the difference between consecutive readings.  
The counters therefore describe energy over time rather than instantaneous power, and the temporal resolution is defined entirely by the tick interval.  
Because the hardware updates its counters significantly more frequently than Tycho samples them, the measurements behave as effectively continuous at the chosen time scale.

RAPL sampling is synchronised with Tycho’s timing engine so that each interval has exactly one cumulative reading per domain.  
No delay calibration is required, since the counters already incorporate any internal update behaviour and can be treated as representative for the entire interval.  
At this level RAPL acts as a stable and low noise source of CPU adjacent energy.

The domain structure of RAPL aligns with Tycho’s requirement for domain level consistency.  
Per socket counters for package, core, uncore, and memory related domains form a coherent decomposition of CPU energy that remains stable across intervals.  
This decomposition is preserved throughout the attribution process and provides a reliable baseline against which software side utilisation signals can be related.


% ----------------------------------------------------------------------
\subsection{GPU/NVML Domains}
\label{subsec:nvml_temporal}

% LENGTH:
%   ~1 to 1.25 pages including one diagram.

% PURPOSE:
%   Present GPU power as a temporally rich domain with distinct properties
%   relative to CPU/RAPL, especially:
%       * instantaneous vs averaged signals,
%       * phase-aware sampling,
%       * domain-internal averaging performed by NVML.

% MUST INCLUDE:
%   - Explanation of two kinds of NVML-reported power:
%       * The commonly used *averaged* power metric (e.g. `nvmlDeviceGetPowerUsage`)
%         which is internally averaged over tens of milliseconds.
%       * The *instantaneous* or *sensor-level* NVML FIELD used by Tycho,
%         representing a more direct sample of current power draw.
%   - Rationale:
%       * The instantaneous metric provides more accurate temporal structure,
%         crucial for Tycho’s event-time model.
%       * Existing research often relies on the averaged metric, which obscures
%         fast changes; Tycho’s architecture explicitly avoids this limitation.
%   - Description of phase-aware sampling:
%       * NVML internally updates power at discrete but undocumented intervals.
%       * Tycho aligns sampling with NVML’s phase characteristics to reduce
%         aliasing and improve temporal coherence.
%   - Conceptual explanation of delay:
%       * NVML reports reflect a small delay relative to actual physical
%         events; calibration helps quantify this.
%   - Mention that GPU load, memory, and other utilisation signals may have
%     different temporal patterns, but details belong in the implementation
%     chapter.

% DIAGRAM (IMPORTANT):
%   - A schematic showing:
%       * Underlying GPU instantaneous power as a continuous curve.
%       * NVML internal update points.
%       * Tycho’s phase-aware sampling markers aligned with these points.
%     Do not include numerical values.

% MUST NOT INCLUDE:
%   - API names beyond generic references ("averaged" vs "instantaneous").
%   - Numeric defaults or specific sampling intervals.
%   - GPU architecture or kernel driver details (implementation chapter).

% MAY INCLUDE:
%   - A sentence noting that Tycho’s design intentionally treats GPU and CPU
%     domains asymmetrically due to their different temporal behaviours.


% ----------------------------------------------------------------------
\subsection{Redfish/BMC Power Source}
\label{subsec:redfish_temporal}

Redfish provides an out-of-band view of total node power through the server’s management controller.  
In contrast to the high-frequency in-band domains, Redfish publishes power updates at coarse and irregular intervals that depend on the behaviour of the underlying BMC.  
These values represent instantaneous chassis power rather than cumulative energy and therefore require temporal interpretation when used within Tycho’s event-time model.

Tycho samples Redfish strictly at tick boundaries using its monotonic timebase.  
Because BMC updates are asynchronous, many polls return repeated values, and new measurements may appear only after multiple tick intervals.  
Each observation is therefore associated with a freshness value that expresses the temporal distance between the hardware-reported update time and the sampling moment.  
At the architectural level, freshness conveys the uncertainty arising from slow or irregular publication cycles and enables the analysis component to reason about the temporal accuracy of each reading.

The coarse and irregular nature of Redfish introduces continuity requirements that differ from those of the in-band collectors.  
When no new value appears for an extended period, Tycho emits an explicit continuation of the last power value to maintain a complete and chronologically consistent power timeline.  
These continuation samples carry the same timestamping and freshness semantics as true updates but do not indicate new power information.  
This mechanism ensures that the global power series remains well defined even when the BMC publishes infrequently.

Redfish serves as Tycho’s authoritative source for total node power.  
Although its temporal resolution is limited, the measurements provide a stable reference against which CPU-related energy and software-side utilisation signals can be interpreted.  
Within Tycho’s domain model, Redfish therefore acts as a coarse but essential power source whose irregular behaviour is accommodated through timestamping, freshness annotation, and controlled sampling rather than through high-frequency polling or delay correction.





% ----------------------------------------------------------------------
\subsection{Conceptual Limitations and Uncertainty Sources}
\label{subsec:uncertainty_sources}

% LENGTH:
%   ~0.75 page.

% PURPOSE:
%   Summarise cross-domain temporal mismatch and inherent sampling
%   uncertainty. This closes the section by motivating the modelling
%   techniques introduced in the next chapter subsection.

% MUST INCLUDE:
%   - Identification of uncertainty sources:
%       * Temporal mismatch between domains (fast GPU, slow Redfish).
%       * Internal sensor averaging (NVML averaged metric).
%       * Jitter in software counters.
%       * Acquisition delays.
%       * Missing samples.
%   - Explain that these are not “errors” but natural constraints of
%     multi-source measurement systems.
%   - Clarify that Tycho’s architecture does not attempt perfect
%     synchronisation; instead it:
%       * constructs windows that respect each domain’s timing,
%       * propagates uncertainty forward to the analysis stage.

% MUST NOT INCLUDE:
%   - Numerical error bounds.
%   - Details of uncertainty quantification (belongs in analysis chapter).

% MAY INCLUDE:
%   - A forward reference: “The analysis engine (Section~\S\ref{sec:analysis_model})
%     incorporates these uncertainties by …”
%     Keep this brief.

% DIAGRAM:
%   - None required; the section is integrative and conceptual.




% ----------------------------------------------------------------------
\section{Analysis and Attribution Model}
\label{sec:analysis_model}

% OVERALL LENGTH:
%   ~3 pages for the placeholder structure in its current vague state.
%   This section MUST remain deliberately non-committal because the actual
%   analysis architecture has not been designed yet. The purpose of this
%   placeholder is to define *what kinds of content belong here*, not how
%   they will ultimately be realised.

% GUIDING NOTE:
%   Every subsection must avoid implying a specific algorithmic choice.
%   The text here should describe the *space of responsibilities* and the
%   *conceptual relationships* that the analysis model will eventually need
%   to address. No assumptions about regression models, ratio models,
%   interpolation schemes, fairness models, or uncertainty propagation may
%   be embedded in the placeholder until the real architecture is defined.


% ----------------------------------------------------------------------
\subsection{Problem Definition}
\label{subsec:analysis_problem_definition}

% LENGTH:
%   ~0.5 page.

% MUST INCLUDE (conceptually):
%   - A broad definition of the attribution task: given per-domain metric
%     samples organised into analysis windows (constructed by the timing
%     engine), the analysis phase must reconstruct estimates of:
%         * window-level domain energies,
%         * their temporal alignment,
%         * and their assignment to workloads.
%   - Clarification that this involves:
%         * combining heterogeneous signals,
%         * interpreting incomplete or uncertain data,
%         * and generating per-container or per-pod energy estimates.
%   - Emphasise that the analysis engine is a *model* that interprets
%     measurements, not a mere aggregator.

% MUST NOT INCLUDE:
%   - Any specific modelling approach (e.g. ratio models, regressions).
%   - Any concrete algorithmic steps or formulas other than purely symbolic.


% ----------------------------------------------------------------------
\subsection{Energy Reconstruction Across Domains}
\label{subsec:energy_reconstruction}

% LENGTH:
%   ~0.75 page.

% MUST INCLUDE (conceptually):
%   - Statement that the analysis model must combine CPU, GPU, uncore,
%     memory, and total-node power (e.g. Redfish) into a coherent picture
%     of energy consumption in each window.
%   - A generic decomposition identity (symbolic, not algorithmic):
%       \[
%           P_{\text{total}}(t)
%           =
%           P_{\text{cpu}}(t)
%           +
%           P_{\text{gpu}}(t)
%           +
%           P_{\text{uncore}}(t)
%           +
%           P_{\text{other}}(t)
%           + \varepsilon(t),
%       \]
%     where \(\varepsilon(t)\) symbolises modelling uncertainty.
%   - Explanation that this decomposition is conceptual only: the exact
%     interpretation, estimation steps, and domain interactions will be
%     defined later when the actual architecture is available.
%   - Mention that samples may arrive at different temporal resolutions, so
%     reconstruction must interpret them within analysis windows.

% MUST NOT INCLUDE:
%   - Any discussion of how “other” or “uncore” will be computed.
%   - Any concrete rules for combining domains (e.g. prioritisation,
%     proportionality, ratios, filtering).


% ----------------------------------------------------------------------
\subsection{Container-Level Attribution}
\label{subsec:container_attribution}

% LENGTH:
%   ~1 page.

% MUST INCLUDE (conceptually):
%   - High-level role of utilisation metrics, metadata, and domain energies:
%       * utilisation data describes workload behaviour,
%       * metadata maps processes and cgroups to containers,
%       * domain windows describe where energy originates,
%     and attribution must relate these.
%   - State that the analysis model must eventually produce per-container
%     energy estimates for each window.
%   - Clarify that:
%       * attribution may depend on utilisation patterns,
%       * attribution must support partial and uncertain data,
%       * attribution must remain stable under short-lived containers.

% DIAGRAM PLACEHOLDER:
%   - A conceptual attribution-flow diagram:
%       * Inputs: domain-window energies, utilisation metrics, metadata.
%       * Outputs: per-container energy contributions.
%       * No arrows showing mathematical rules — only conceptual flows.
%     The final diagram will be drawn once the architecture is fixed.

% MUST NOT INCLUDE:
%   - Any allocation rules (e.g. proportional, residual-split, regression).
%   - Any equations mapping utilisation to energy.


% ----------------------------------------------------------------------
\subsection{Residual Power Attribution}
\label{subsec:residual_power}

% LENGTH:
%   ~0.5 page.

% MUST INCLUDE (conceptually):
%   - Statement that some portion of node-level power may not be explained
%     directly by CPU or GPU domains.
%   - Clarification that the analysis model must provide a *conceptual*
%     mechanism to:
%         * quantify residual energy,
%         * distribute it meaningfully or mark it as uncertainty,
%     but without specifying how this will be done.
%   - Acknowledgement that residual handling is central to transparency and
%     must make implicit assumptions explicit.

% MUST NOT INCLUDE:
%   - Any specific strategy for distributing residual energy.
%   - Any mathematical formulas for residual modelling.


% ----------------------------------------------------------------------
\subsection{Requirements Satisfaction}
\label{subsec:analysis_requirements}

% LENGTH:
%   ~0.5 page.

% MUST INCLUDE:
%   - A *forward-looking* statement that the analysis engine, once designed
%     and implemented, must satisfy the requirements in Ch.~3, especially:
%         * temporal coherence,
%         * domain-level consistency,
%         * transparency of assumptions,
%         * lifecycle robustness,
%         * uncertainty awareness.
%   - Indicate that these requirements constrain the future design of:
%         * how windows are interpreted,
%         * how uncertainty is propagated,
%         * how attribution is stabilised for container churn,
%         * and how assumptions must be externally visible.
%   - Emphasise that this subsection is not a proof — it merely establishes
%     the criteria by which the final analysis design will later be judged.

% MUST NOT INCLUDE:
%   - Any premature claims about how the analysis will satisfy requirements.
%   - Any commitments to specific algorithms or models.



% ----------------------------------------------------------------------
\section{Calibration Framework (Conceptual)}
\label{sec:calibration_framework}

% OVERALL LENGTH:
%   ~1.5 to 2 pages. This section remains conceptual and intentionally
%   light on detail. Its purpose is to explain *why calibration exists* in
%   Tycho, *what kinds of quantities must be calibrated*, and *how*
%   calibration conceptually influences timing and analysis.
%
%   Absolutely no specific calibration algorithms, scripts, or procedures
%   should appear here — those belong to the implementation chapter.


% ----------------------------------------------------------------------
\subsection{Calibration Objectives}
\label{subsec:calibration_objectives}

% LENGTH:
%   ~0.5 page.

% PURPOSE:
%   Define the conceptual goals of calibration without describing how any of
%   them are achieved. This subsection motivates why calibration is a core
%   architectural component.

% MUST INCLUDE (conceptually):
%   - A statement that Tycho treats calibration as an integral architectural
%     element supporting the timing engine and analysis model.
%   - High-level enumeration of calibration objectives:
%       * Delay estimation:
%           Understanding systematic lag between event time and poll time
%           for each collector domain.
%       * Idle baseline identification:
%           Estimating the idle power or idle-domain behaviour needed to
%           interpret load-dependent measurements.
%       * Validation of collector timing characteristics:
%           Checking whether collectors behave as expected (e.g., update
%           intervals, jitter bounds).
%   - Emphasise that calibration outputs *constraints* or *metadata* that
%     inform the timing and analysis phases, not direct energy estimates.

% MAY INCLUDE:
%   - A brief remark that calibration must be repeatable and must not assume
%     stable hardware behaviour over long time periods.

% MUST NOT INCLUDE:
%   - Any actual calibration experiments, scripts, Python tools, or metrics.
%   - Specific numeric thresholds or default values.


% ----------------------------------------------------------------------
\subsection{Calibration Procedures}
\label{subsec:calibration_procedures}

% LENGTH:
%   ~0.5 to 0.75 page.

% PURPOSE:
%   Describe the *conceptual structure* of calibration routines without
%   committing to specific algorithms or processes. This establishes the
%   architectural hooks where calibration interacts with the timing engine.

% MUST INCLUDE (conceptually):
%   - A high-level description that calibration is carried out through
%     controlled measurements or observation phases, but:
%       * exact measurement methods,
%       * stress tools,
%       * sampling schedules,
%       are left unspecified.
%   - Clarification that calibration interacts with the timing engine by:
%       * informing expected update intervals,
%       * providing approximate delay distributions,
%       * identifying jitter characteristics,
%       * establishing confidence bounds used to assess sample freshness.
%   - A conceptual explanation that calibration may need to run:
%       * during system startup,
%       * periodically or conditionally,
%       * or when hardware/collector behaviour changes.
%   - Emphasise that calibration modifies *interpretation*, not *data*.

% MAY INCLUDE:
%   - Placeholder sentence indicating that the concrete structure of
%     calibration logic (e.g., separation into phases or routines) will be
%     defined once the analysis architecture is finalised.

% MUST NOT INCLUDE:
%   - Any procedural instructions (e.g., “run X for Y seconds”).
%   - Any discussion of tooling (stress-ng, gpu-burn, scripts, etc.).
%   - Any diagrams, unless extremely conceptual (e.g., “calibration outputs
%     feed into timing engine inputs”) — but omit for now.


% ----------------------------------------------------------------------
\subsection{Integration with Attribution}
\label{subsec:calibration_integration}

% LENGTH:
%   ~0.5 page.

% PURPOSE:
%   Explain, in purely conceptual terms, how calibration results constrain
%   and inform the analysis model, without specifying the model itself.

% MUST INCLUDE (conceptually):
%   - Statement that calibration provides domain-specific metadata that the
%     analysis engine must respect:
%       * estimated delay bounds,
%       * expected update frequency ranges,
%       * idle baseline interpretations,
%       * uncertainty indicators.
%   - Clarification that such calibration outputs influence:
%       * which samples are considered valid or stale,
%       * how windows are aligned,
%       * how domain energies are reconstructed,
%       * how uncertainty is propagated.
%   - Emphasise that calibration enhances transparency: assumptions about
%     timing and domain behaviour are explicitly documented, not hidden in
%     inference logic.

% MAY INCLUDE (OPTIONAL):
%   - A forward reference noting that the final analysis architecture will
%     detail how these calibration-derived constraints enter formal models.

% MUST NOT INCLUDE:
%   - Any specific way that calibrated values affect formulas.
%   - Any commitment to particular uncertainty propagation methods.
%   - Any mention of per-domain weighting schemes or decision thresholds.




% ----------------------------------------------------------------------
\section{Metadata and Lifecycle Integration}
\label{sec:metadata_integration}

% OVERALL LENGTH:
%   ~1.5 to 2 pages. This section provides the conceptual foundation for how
%   Tycho handles container identities, pod lifecycles, and the mapping
%   between processes, cgroups, and Kubernetes objects.
%
% PURPOSE:
%   - Explain *why* metadata is essential for attribution.
%   - Describe metadata as a *temporal signal* with its own lifecycle,
%     freshness requirements, and uncertainties.
%   - Show how metadata interacts with timing and analysis without touching
%     implementation specifics.


% ----------------------------------------------------------------------
\subsection{Role of Metadata Freshness}
\label{subsec:metadata_freshness}

% LENGTH:
%   ~0.5 to 0.75 page.

% PURPOSE:
%   Establish metadata as a time-sensitive component of the architecture,
%   not merely a static lookup table.

% MUST INCLUDE (conceptually):
%   - Clarify that metadata describes the relationship between:
%       * processes,
%       * cgroups,
%       * containers,
%       * pods,
%       * workloads (deployments, jobs, etc.).
%   - Emphasise that container metadata changes over time:
%       * Pods start, restart, terminate.
%       * PIDs appear and disappear.
%       * Cgroup hierarchies evolve dynamically.
%   - Explain why stale metadata is problematic:
%       * Incorrect or outdated mappings produce inaccurate attribution.
%       * Fast-changing workloads (e.g., batch jobs, ephemeral sidecars)
%         require metadata with predictable freshness.
%   - Motivation for a local metadata cache:
%       * Sampling metadata directly from Kubernetes APIs or cgroup
%         hierarchies on each analysis window would be too slow or
%         inconsistent.
%       * A local cache provides a temporally stable snapshot with known
%         age bounds.

% MAY INCLUDE:
%   - A conceptual note that metadata has its own lifecycle which must
%     integrate with the timing model (e.g., metadata update times also
%     occur in event time).

% MUST NOT INCLUDE:
%   - Any API paths, structs, or polling intervals.
%   - Details of how metadata is stored internally.


% ----------------------------------------------------------------------
\subsection{Mapping Processes to Containers}
\label{subsec:process_container_mapping}

% LENGTH:
%   ~0.5 to 0.75 page.

% PURPOSE:
%   Describe the conceptual relationship between raw OS-level processes and
%   higher-level Kubernetes workload identities. This establishes the
%   foundation for how utilisation metrics eventually contribute to
%   attribution.

% MUST INCLUDE (conceptually):
%   - A clear high-level description of the mapping ladder:
%       process → cgroup → container → pod → workload identity.
%   - Explain that utilisation metrics (CPU time, IO events, GPU context
%     activity, etc.) are recorded at process or cgroup granularity, but
%     attribution must occur at container or pod granularity.
%   - Statement that the mapping is *conceptual* and must be:
%       * correct over time,
%       * consistent with container lifecycle events,
%       * robust to short-lived processes.
%   - Mention that mapping must handle:
%       * multi-process containers,
%       * nested cgroups,
%       * reused PIDs,
%       * containers that terminate between metadata refreshes.

% MUST NOT INCLUDE:
%   - Implementation detail of how PIDs or cgroups are enumerated.
%   - Any discussion of container runtimes or kubelet internals.
%   - Specific naming conventions, file paths, or label formats.

% MAY INCLUDE:
%   - A short high-level conceptual figure (optional for now):
%       * Boxes representing processes → containers → pods.
%       * Arrows showing mapping direction.
%     Keep this diagram simple and entirely conceptual.


% ----------------------------------------------------------------------
\subsection{Handling Churn and Missing Metadata}
\label{subsec:metadata_churn}

% LENGTH:
%   ~0.5 page.

% PURPOSE:
%   Describe how Tycho conceptually maintains stable attribution semantics
%   when workloads appear, disappear, or fail unexpectedly. This subsection
%   is crucial for satisfying lifecycle-robustness and uncertainty-awareness
%   requirements from Ch.~3.

% MUST INCLUDE (conceptually):
%   - Explanation of *churn*:
%       * Short-lived containers (milliseconds to seconds).
%       * Frequent pod terminations or restarts.
%       * Workloads with unpredictable behaviour (batch jobs, CI runners).
%   - Explain the problem:
%       * Containers may terminate before utilisation data is processed.
%       * Metadata may be incomplete at the moment a window must be
%         analysed.
%       * Some metadata may never be observed (e.g., very short-lived pods).
%   - High-level strategies (without committing to specific mechanisms):
%       * Use metadata validity intervals: metadata is considered valid only
%         within a bounded time from its last refresh.
%       * If metadata is missing or stale, attribution must introduce:
%           - uncertainty markers, or
%           - fallback interpretations.
%       * Terminated containers must still be attributed for their active
%         windows, even if they no longer exist at analysis time.

% MUST NOT INCLUDE:
%   - Details of eviction strategies in the cache.
%   - Any specific fallback rule for missing metadata.
%   - Mention of implementation specifics like TTLs or update frequencies.

% MAY INCLUDE:
%   - A forward reference: this behaviour influences attribution uncertainty
%     handled in Section~\S\ref{sec:analysis_model}.


% ----------------------------------------------------------------------
\section{Architectural Trade-Offs and Alternatives Considered}
\label{sec:tradeoffs}

% OVERALL LENGTH:
%   ~1.5 to 2 pages. This section is intentionally reflective and conceptual.
%   Its purpose is not to provide implementation details, but to document
%   *design-space exploration* and *architectural rationale*.  
%
%   Each subsection describes:
%     - which broad alternatives exist,
%     - why they were considered,
%     - why Tycho does not adopt them (or adopts parts of them),
%     without committing to specific implementation mechanics.


% ----------------------------------------------------------------------
\subsection{Alternative Timing Designs}
\label{subsec:alternative_timing}

% LENGTH:
%   ~0.5 to 0.75 page.

% PURPOSE:
%   Clearly position Tycho’s independent, event-time-driven timing model
%   against simpler alternatives, especially tick-synchronised polling.

% MUST INCLUDE (conceptually):
%   - Description of the two dominant timing paradigms:
%       * Tick-synchronised polling:
%           - A single global polling interval.
%           - All domains sampled at the same moment.
%           - Simplicity and uniformity as benefits.
%       * Independent domain-aware polling:
%           - Each domain sampled at its own suitable frequency.
*           - Asynchrony is expected and preserved.
%   - High-level comparison:
%       * Tick-based model is simple but disregards domain-specific temporal
%         characteristics and introduces aliasing or under-sampling.
%       * Independent model respects domain behaviour but increases system
%         complexity.
%   - State explicitly that Tycho adopts independent polling because it
%     satisfies Ch.~3 requirements for temporal coherence and domain-level
%     consistency.

% MUST NOT INCLUDE:
%   - Numeric intervals, polling code, scheduling mechanisms.
%   - Direct references to Kepler internals (those belong elsewhere).

% MAY INCLUDE:
%   - A conceptual diagram (optional): two timelines, one aligned on ticks,
%     one irregular. Keep it very abstract.


% ----------------------------------------------------------------------
\subsection{Alternative Attribution Strategies}
\label{subsec:alternative_attribution}

% LENGTH:
%   ~0.5 to 0.75 page.

% PURPOSE:
%   Acknowledge the existence of multiple broad modelling philosophies for
%   energy attribution, and clarify why Tycho’s future analysis model must
%   adhere to the conceptual requirements instead of adopting a simplistic
%   approach.

% MUST INCLUDE (conceptually):
%   - High-level overview of possible attribution paradigms:
%       * Direct regression models:
%           - Fit resource utilisation to power.
%           - Require stable training sets and assume stationary workloads.
%       * Static analytical models:
%           - Predefined power coefficients.
%           - Simple but brittle; do not capture dynamic behaviour.
%       * Ratio-based or proportional models:
%           - Divide energy by utilisation proportions.
%           - Fast but sensitive to noise and unsuitable for multi-domain
%             temporal mismatches.
%   - State that these approaches were considered conceptually but present
%     challenges relative to Tycho’s requirements:
%       * They often hide modelling assumptions.
%       * They may require artificially synchronised metrics.
%       * They may be sensitive to incomplete windows and uncertain data.
%   - Emphasise that the final Tycho analysis design will be driven by the
%     architectural requirements (transparency, uncertainty, lifecycle
%     robustness), which limits reliance on the above simplistic methods.

% MUST NOT INCLUDE:
%   - Any specific commitment to Tycho’s own method.
%   - Any preliminary equations for Tycho’s analysis model.
%   - Criticism of existing tools beyond conceptual limitations.


% ----------------------------------------------------------------------
\subsection{Complexity vs Accuracy Considerations}
\label{subsec:complexity_accuracy}

% LENGTH:
%   ~0.5 page.

% PURPOSE:
%   Provide a conceptual justification for Tycho’s architectural decisions
%   by discussing the trade-off between system complexity and measurement
%   accuracy.

% MUST INCLUDE (conceptually):
%   - Acknowledge that:
%       * Independent collectors,
%       * Event-time reconstruction,
%       * Window-based attribution,
%       * Calibration, and
%       * Metadata lifecycle handling
%     each introduce architectural complexity.
%   - Explain why accuracy cannot be achieved with simpler designs:
%       * Fixed-frequency polling under-samples critical domains.
%       * Simplistic attribution hides uncertainty.
%       * Ignoring metadata freshness yields incorrect workload identities.
%   - Emphasise the architectural stance:
%       * Complexity is tolerated where it meaningfully improves model
%         transparency and temporal fidelity.
%       * Abstraction boundaries (collectors, timing, analysis) help confine
%         complexity so that individual components remain understandable and
%         maintainable.
%   - Reiterate linkage to Ch.~3:
%       * Accuracy and transparency are mandatory requirements, therefore
%         architectural complexity is justified and bounded.

% MUST NOT INCLUDE:
%   - Any implementation detail describing how complexity is handled (e.g.,
%     concurrency primitives, memory optimisation).
%   - Specific numeric performance comparisons (those belong in evaluation).

% MAY INCLUDE:
%   - A single brief example illustrating that small increases in
%     architectural sophistication (e.g., recognising NVML phase behaviour)
%     yield disproportionately large accuracy improvements, but keep it very
%     abstract.



% ----------------------------------------------------------------------
\section{Summary}
\label{sec:summary_ch4}

% LENGTH:
%   ~0.5 page. This should be compact and high-level.
%
% PURPOSE:
%   - Provide a concise synthesis of the architectural principles and
%     subsystem roles described in the chapter.
%   - Reinforce the formal link between the requirements in Ch.~3 and the
%     design choices presented here.
%   - Prepare the reader for the transition to the concrete implementation
%     details in Ch.~5 without repeating them.


% MUST INCLUDE (conceptually):
%   - A brief restatement that Tycho’s architecture is shaped directly by
%     the requirements established in Chapter~3:
%       * temporal coherence,
%       * domain-level consistency,
%       * transparent modelling assumptions,
%       * lifecycle robustness,
%       * uncertainty awareness.
%   - A short summary of the major architectural elements introduced:
%       * independent, domain-aware metric collectors,
%       * the event-time-based timing engine and window model,
%       * conceptual structure of the analysis and attribution model,
%       * calibration as a supporting subsystem informing timing and
%         interpretation,
%       * metadata freshness and mapping requirements for workload identity.
%   - Emphasise that this chapter defined **what** Tycho must do and **why**
%     it must do it in this way, but not **how** it is implemented.

% MAY INCLUDE:
%   - One sentence noting that several subsystems (e.g., collectors, metadata,
%     exporter) will be discussed again in Ch.~5 from an implementation
%     viewpoint.
%   - A remark that the detailed analysis model will be finalised and
%     justified in Ch.~5 once its architectural constraints are fully
%     resolved.

% MUST NOT INCLUDE:
%   - Any technical / implementation detail.
%   - Any new architectural concepts not already introduced.
%   - Any evaluative statements (evaluation belongs in a later chapter).

% POINTER TO NEXT CHAPTER:
%   - Conclude with a short forward reference along the lines of:
%       “The following chapter describes the concrete implementation of these
%        architectural components, including the collectors, timing engine,
%        metadata subsystem, calibration routines, and the initial analysis
%        mechanisms.”
%     Keep this phrasing high-level and free of specifics.

