\chapter{System Architecture}
\label{ch:architecture}

\section{Guiding Principles}
\label{subsec:guiding_principles}

Tycho’s architecture is shaped by a small set of foundational principles that govern how measurements are interpreted, combined and ultimately attributed. These principles are architectural in nature: they articulate \emph{how} the system must reason about observations, not \emph{how} it is implemented. They establish the conceptual baseline that the subsequent sections refine in detail.

\begin{itemize}[leftmargin=1.2em]
    \item \textbf{Accuracy-first temporal coherence.}
    Architectural decisions prioritise the reconstruction of temporally coherent views of system behaviour. Observations are treated as samples of an underlying physical process, and the architecture is designed to preserve their temporal meaning rather than force periodic alignment.

    \item \textbf{Domain-aware interpretation.}
    Metric sources differ in semantics and cadence. The architecture respects these differences and avoids imposing artificial synchrony or uniform sampling behaviour across heterogeneous domains.

    \item \textbf{Transparency of assumptions.}
    All modelling assumptions must be explicit, inspectable and externally visible. The architecture prohibits implicit corrections or hidden inference steps that would obscure how measurements lead to attribution results.

    \item \textbf{Uncertainty as a first-class concept.}
    Missing, stale or delayed information is treated as uncertainty rather than error. Architectural components convey and preserve uncertainty so that later stages may interpret it correctly.

    \item \textbf{Separation of observation, timing and attribution.}
    Measurement collection, temporal interpretation and energy attribution form distinct architectural layers. This separation prevents cross-coupling, clarifies responsibilities and ensures that improvements in one layer do not implicitly alter the behaviour of others.
\end{itemize}
\section{Traceability to Requirements}
\label{subsec:req_traceability}

The architectural structure introduced in this chapter provides a direct response to the requirements established in \S~\ref{sec:conceptual_requirements}. Each requirement class corresponds to specific architectural mechanisms, ensuring that the system design follows from formal constraints rather than implementation convenience.

\textbf{Requirement: Temporal Coherence.}
Satisfied through event-time reconstruction, independent collector timelines, and window-based temporal alignment.

\textbf{Requirement: Domain-Level Consistency.}
Addressed by per-domain interpretation layers, domain-aware handling of metric semantics, and explicit decomposition of node-level signals.

\textbf{Requirement: Cross-Domain Reconciliation.}
Supported by a unified temporal model, window-level aggregation boundaries, and explicit reconciliation logic across domains during analysis.

\textbf{Requirement: Consistent Metric Interpretation.}
Ensured by separating observation from interpretation, enforcing stable metric semantics within each domain, and isolating heterogeneous metrics into dedicated processing paths.

\textbf{Requirement: Transparent Modelling Assumptions.}
Realised through explicit modelling steps, external visibility of assumptions, and separation between measured and inferred quantities.

\textbf{Requirement: Lifecycle-Robust Attribution.}
Enabled by metadata freshness guarantees, stable process–container mapping, and attribution rules that remain valid under workload churn.

\textbf{Requirement: Uncertainty-Aware Attribution.}
Supported by explicit treatment of stale or missing data, uncertainty propagation in window evaluation, and preservation of unexplained residuals.

\section{High-Level Architecture}
\label{sec:high_level_architecture}

\subsection{Subsystem Overview}
\label{subsec:subsystem_overview}

Tycho is organised into a small set of subsystems, each with a distinct responsibility. The following overview introduces these subsystems without yet describing their interactions.

\textbf{Timing engine.}
Defines the temporal reference used throughout the system and provides the notion of analysis windows. It is responsible for deciding when a window is complete and ready to be evaluated.

\textbf{Metric collectors.}
Acquire observations from hardware and software sources and attach timestamps in the global temporal reference. They expose their output as streams of samples without coordinating with each other.

\textbf{Metadata subsystem.}
Maintains the mapping between operating-system level entities and workload identities. It tracks relationships between processes, cgroups, containers and pods over time.

\textbf{Buffering and storage layer.}
Stores recent observations in bounded histories so that samples relevant to a given window can be retrieved efficiently. It treats metric streams and metadata as read-mostly records.

\textbf{Analysis engine.}
Interprets temporally aligned observations and metadata to produce energy estimates for each analysis window. It forms the logical bridge between measurement and attribution.

\textbf{Calibration framework.}
Derives auxiliary information about typical delays, update patterns and idle behaviour. It produces constraints and characterisations that other subsystems rely on for interpretation.

\textbf{Exporter.}
Exposes the results of the analysis engine to external monitoring systems as metrics ready for scraping and downstream processing.

\subsection{Dataflow and Control Flow}
\label{subsec:dataflow_control}

Before Tycho enters normal operation, external calibration scripts determine approximate delay characteristics for all relevant metric sources. At startup, Tycho’s internal calibration component derives suitable polling frequencies for metric collectors and metadata acquisition, providing the initial operating parameters for the system.

During runtime, control flow originates in the timing engine. It triggers each collector according to its calibrated polling frequency, but collectors operate independently: they sample their respective domains without synchronising with each other, and each sample is appended to the appropriate buffer together with its timestamp and quality indicators. In parallel, metadata acquisition proceeds on its own schedule, refreshing the mappings between processes, cgroups and workload identities in the metadata cache.

The timing engine also governs when analysis occurs. At regular intervals—constituting fixed-length analysis windows—it initiates a new evaluation cycle irrespective of how many samples have been collected. Each cycle begins by estimating idle behaviour for the relevant hardware domains based on the buffered observations. The analysis engine then interprets the buffered metric samples, the metadata cache and the idle characterisations, taking calibrated delays into account when reconstructing the temporal structure of the window. It produces per-window energy estimates for all domains and workloads.

Once analysis completes, the exporter publishes the resulting metrics in a form suitable for ingestion by external monitoring systems. Calibration remains active in the background throughout the system’s lifetime: it observes collector behaviour and derived quantities over longer time spans and refines its characterisations when needed, informing both the timing and analysis components without altering any collected data.

% \begin{figure}[t]
%     \centering
%     % TODO: Insert dataflow and control flow diagram here.
%     \caption{Dataflow and control flow in Tycho. Metric sources feed collectors and the metadata subsystem, which populate the buffering layer and metadata cache. The timing engine inspects buffered data to decide when an analysis window is ready, after which the analysis engine performs attribution and the exporter publishes the resulting metrics. Calibration observes the overall behaviour and feeds auxiliary timing information back into the timing and analysis components.}
%     \label{fig:dataflow_control}
% \end{figure}

\begin{figure}[t]
    \centering
    \begin{tikzpicture}[
        node distance=1.8cm and 2.3cm,
        box/.style={draw, rounded corners, align=center, minimum width=2.8cm, minimum height=1cm},
        ext/.style={draw, dashed, rounded corners, align=center, minimum width=2.8cm, minimum height=1cm},
        data/.style={-Stealth},
        control/.style={-Stealth, dashed}
    ]

    % External sources
    \node[ext] (metric_sources) {Metric\\Sources};
    \node[ext, below=of metric_sources] (meta_sources) {Orchestration \&\\Process Info};

    % Internal components
    \node[box, right=of metric_sources] (collectors) {Metric\\Collectors};
    \node[box, right=of meta_sources] (metadata) {Metadata\\Subsystem};

    \node[box, right=of collectors] (buffers) {Buffering\\Layer};
    \node[box, right=of metadata] (metacache) {Metadata\\Cache};

    \node[box, above right=1.0cm and 2.2cm of buffers] (timing) {Timing\\Engine};
    \node[box, below right=1.0cm and 2.2cm of buffers] (analysis) {Analysis\\Engine};

    \node[box, right=of analysis] (exporter) {Exporter};
    \node[ext, right=of exporter] (prometheus) {Monitoring\\System};

    \node[box, above=of timing] (calibration) {Calibration};

    % Data flow
    \draw[data] (metric_sources) -- (collectors);
    \draw[data] (collectors) -- (buffers);

    \draw[data] (meta_sources) -- (metadata);
    \draw[data] (metadata) -- (metacache);

    \draw[data] (buffers) |- (analysis);
    \draw[data] (metacache) -- (analysis);

    \draw[data] (analysis) -- (exporter);
    \draw[data] (exporter) -- (prometheus);

    % Control / auxiliary flow
    \draw[control] (timing) -| (collectors);
    \draw[control] (timing) |- (analysis);

    \draw[control] (calibration) -- (timing);
    \draw[control] (calibration) -| (collectors);
    \draw[control] (calibration) |- (analysis);

    \draw[control] (buffers) -- (timing);
    % optional: timing inspects buffer contents conceptually

    \end{tikzpicture}
    \caption{Dataflow and control flow in Tycho. Metric sources feed collectors and the metadata subsystem, which populate the buffering layer and metadata cache. The timing engine inspects buffered data to define analysis windows and trigger evaluation. The analysis engine performs attribution for each window and the exporter publishes the resulting metrics. Calibration observes long-term behaviour and feeds auxiliary information back into timing and analysis.}
    \label{fig:dataflow_control}
\end{figure}


% ----------------------------------------------------------------------
\section{Temporal Model and Timing Engine}
\label{sec:timing_engine}

Tycho’s temporal architecture provides a coherent framework for relating heterogeneous metric streams to fixed-duration analysis windows. It establishes a common time base, defines how collectors operate, and specifies how windows are formed and interpreted. The model is intentionally simple: collectors run independently, timestamps reflect poll time, and all temporal reasoning occurs during analysis.

% ----------------------------------------------------------------------
\subsection{Event-Time Model and Timestamp Semantics}
\label{subsec:event_time}

Tycho adopts a single monotonic time base for all temporal coordination. Collectors timestamp each sample at the moment of observation; these timestamps reflect poll time, not the physical instant at which the underlying hardware event occurred. Event time is therefore a modelling construct used by the analysis engine when interpreting delay, freshness and update behaviour.

This separation keeps collectors lightweight and domain-agnostic. Each collector reports only what it directly observes; the analysis engine later interprets these timestamps in context, using calibration-derived delay characteristics to approximate underlying temporal structure.

% \medskip
% \noindent\textbf{Diagram placeholder:}  
% A minimal schematic showing a single timeline with ``poll time'' markers and an overlay illustrating conceptual ``event time'' offsets.

\begin{figure}[t]
    \centering
    \begin{tikzpicture}[
        >=Stealth,
        scale=1,
        every node/.style={font=\small}
    ]

    % Time axis
    \draw[->] (0,0) -- (10,0) node[anchor=west] {time};

    % Poll events
    \foreach \x/\label in {2/$\text{poll}_1$, 6/$\text{poll}_2$} {
        \draw[thick] (\x,0.15) -- (\x,-0.15);
        \node[above] at (\x,0.15) {\label};
    }

    % Underlying measurement intervals (conceptual event time)
    \draw[very thick, gray] (0.5,0.6) -- (2,0.6);
    \draw[very thick, gray] (4.2,0.6) -- (6,0.6);

    \node[above, gray] at (1.25,0.6) {physical change};
    \node[above, gray] at (5.1,0.6) {physical change};

    % Delay arrows
    \draw[->, gray] (2,0.5) -- (2,0.15);
    \draw[->, gray] (6,0.5) -- (6,0.15);

    \node[below] at (2,-0.15) {timestamp};
    \node[below] at (6,-0.15) {timestamp};

    \end{tikzpicture}
    \caption{Conceptual relation between physical behaviour (event time) and observations recorded at poll time. Tycho records poll-time timestamps and interprets them as approximations of underlying event-time behaviour in the analysis phase.}
    \label{fig:event_time_schematic}
\end{figure}


% ----------------------------------------------------------------------
\subsection{Independent Collector Schedules}
\label{subsec:independent_timelines}

Tycho employs independent, domain-aware sampling schedules. During startup the timing engine configures one schedule per collector, after which each collector operates autonomously on its own periodic trigger. No global poll loop exists and collectors do not synchronise with one another. They push samples only when a new observation is available.

This decoupling avoids artificial temporal alignment and preserves each domain’s intrinsic update behaviour. Collector timestamps are placed directly on the global monotonic time axis, allowing later reconstruction without imposing shared cadence or shared sampling semantics.

% \medskip
% \noindent\textbf{Diagram placeholder:}  
% Horizontal multi-track timeline showing heterogeneous sample arrival patterns across domains, without alignment.
\begin{figure}[t]
    \centering
    \begin{tikzpicture}[
        >=Stealth,
        scale=1,
        every node/.style={font=\small}
    ]

    % Global time axis
    \draw[->] (0,0) -- (11,0) node[anchor=west] {time};

    % Collector lines
    \node[left] at (0,1.5) {Collector A};
    \draw (0,1.5) -- (10.5,1.5);

    \node[left] at (0,2.5) {Collector B};
    \draw (0,2.5) -- (10.5,2.5);

    \node[left] at (0,3.5) {Collector C};
    \draw (0,3.5) -- (10.5,3.5);

    % Ticks for A (irregular)
    \foreach \x in {1.0, 3.2, 4.5, 7.1, 9.8} {
        \draw[thick] (\x,1.3) -- (\x,1.7);
    }

    % Ticks for B (denser)
    \foreach \x in {0.8, 1.6, 2.4, 3.3, 4.0, 5.2, 6.1, 7.0, 8.0, 9.0} {
        \draw[thick] (\x,2.3) -- (\x,2.7);
    }

    % Ticks for C (sparse)
    \foreach \x in {2.0, 5.5, 9.2} {
        \draw[thick] (\x,3.3) -- (\x,3.7);
    }

    \end{tikzpicture}
    \caption{Independent sampling schedules for different collectors on a shared time axis. Each collector operates on its own cadence without synchronisation, and samples are later aligned only at the level of analysis windows.}
    \label{fig:independent_timelines}
\end{figure}

% ----------------------------------------------------------------------
\subsection{Window Construction and Analysis Triggering}
\label{subsec:window_construction}

Analysis proceeds in fixed-duration windows defined solely by periodic triggers from the timing engine. If the triggers occur at monotonic times \(T_0, T_1, T_2, \dots\), window \(W_i\) is the half-open interval \([T_i, T_{i+1})\). Window duration is nominally constant but may drift slightly, which is acceptable for attribution.

When a window closes, the analysis engine performs two conceptual phases:

\begin{enumerate}[label=(\roman*)]
\item \emph{idle characterisation}, using long-term buffered history across all relevant domains, and  
\item \emph{window reconstruction and attribution}, using all samples whose timestamps precede \(T_{i+1}\).
\end{enumerate}

Only energy for the current window is attributed and exported, but additional historical samples inform delay interpretation, idle estimation and interpolation.

Tycho treats domains asymmetrically: CPU and software metrics are always required; GPU and Redfish domains contribute when available. Samples too old to fall within the current window do not contribute directly but may still inform background characterisation. Windows remain valid even when optional domains are absent.

A sample is considered stale relative to a window when its poll timestamp predates \(T_i\) by more than a domain-specific tolerance. Stale samples are ignored for direct reconstruction but do not invalidate the window.

% \medskip
% \noindent\textbf{Diagram placeholder:}  
% A window diagram showing:  
% \begin{itemize}[nosep]
% \item window boundaries at \(T_i\) and \(T_{i+1}\),  
% \item sample points from independent collectors,  
% \item which samples contribute to the window,  
% \item which samples are stale or outside the window.  
% \end{itemize}

\begin{figure}[t]
    \centering
    \begin{tikzpicture}[
        >=Stealth,
        scale=1,
        every node/.style={font=\small}
    ]

    % Time axis
    \draw[->] (0,0) -- (11,0) node[anchor=west] {time};

    % Window boundaries
    \draw[very thick] (3,0.2) -- (3,-0.2);
    \draw[very thick] (8,0.2) -- (8,-0.2);
    \node[below] at (3,-0.2) {$T_i$};
    \node[below] at (8,-0.2) {$T_{i+1}$};

    % Window highlight
    \draw[fill=gray!10, draw=none] (3,0.3) rectangle (8,4.1);
    \node[above] at (5.5,4.1) {Window $W_i = [T_i, T_{i+1})$};

    % Collector lines
    \node[left] at (0,1) {Collector A};
    \draw (0,1) -- (10.5,1);

    \node[left] at (0,2) {Collector B};
    \draw (0,2) -- (10.5,2);

    \node[left] at (0,3) {Collector C};
    \draw (0,3) -- (10.5,3);

    % Samples for A
    \foreach \x/\style in {1/gray, 3.5/black, 6.2/black, 9/gray} {
        \draw[thick,\style] (\x,0.8) -- (\x,1.2);
    }

    % Samples for B
    \foreach \x/\style in {2.5/gray, 3.2/black, 4.1/black, 7.9/black, 9.5/gray} {
        \draw[thick,\style] (\x,1.8) -- (\x,2.2);
    }

    % Samples for C
    \foreach \x/\style in {2/gray, 5.0/black, 8.5/gray} {
        \draw[thick,\style] (\x,2.8) -- (\x,3.2);
    }

    \node[gray] at (1.0,0.4) {outside window};
    \node[gray] at (9.3,0.4) {outside window};

    \end{tikzpicture}
    \caption{Analysis window $W_i$ defined by two successive analysis trigger times. Samples inside the window contribute directly to reconstruction, while samples outside may still inform background characterisation but are not attributed to $W_i$.}
    \label{fig:window_alignment}
\end{figure}


\begin{figure}[t]
    \centering
    \begin{tikzpicture}[
        >=Stealth,
        scale=1,
        every node/.style={font=\small}
    ]

    % Kepler (left)
    \node[font=\normalsize] at (5,4.2) {Kepler};

    % Time axis Kepler
    \draw[->] (0,3.5) -- (10,3.5) node[anchor=west] {time};

    % Kepler poll intervals
    \foreach \x in {1,3,5,7,9} {
        \draw[very thick] (\x,3.3) -- (\x,3.7);
        \draw[fill=gray!20, draw=none] (\x-1,3.0) rectangle (\x,3.1);
    }
    \node[below] at (1,3.0) {poll \& attribution};

    % Redfish track (slow)
    \node[left] at (0,2.6) {Redfish};
    \draw (0,2.6) -- (10,2.6);
    \foreach \x in {2,8} {
        \draw[thick] (\x,2.4) -- (\x,2.8);
    }

    % Export ticks (different cadence)
    \node[left] at (0,2.0) {Export};
    \draw (0,2.0) -- (10,2.0);
    \foreach \x in {2.5, 6.5} {
        \draw[thick] (\x,1.8) -- (\x,2.2);
    }

    % Tycho (right)
    \node[font=\normalsize] at (5,1.3) {Tycho};

    % Time axis Tycho
    \draw[->] (0,0.6) -- (10,0.6) node[anchor=west] {time};

    % Tycho windows
    \foreach \x in {1.5,3.5,5.5,7.5,9.5} {
        \draw[very thick] (\x,0.8) -- (\x,0.4);
    }
    \foreach \x in {1.5,3.5,5.5,7.5} {
        \draw[fill=gray!10, draw=none] (\x,0.9) rectangle (\x+2,1.0);
    }
    \node[above] at (2.5,1.0) {analysis windows};

    % Export after each window
    \node[left] at (0,-0.1) {Export};
    \draw (0,-0.1) -- (10,-0.1);
    \foreach \x in {1.5,3.5,5.5,7.5,9.5} {
        \draw[thick] (\x,-0.3) -- (\x,0.1);
    }

    \end{tikzpicture}
    \caption{Conceptual comparison between Kepler and Tycho timing. Kepler uses a synchronous polling interval for most domains and reuses slower Redfish readings across multiple intervals; export may occur on a different cadence. Tycho employs independent collectors and defines attribution strictly in terms of analysis windows, with export immediately following each window.}
    \label{fig:tycho_kepler_timing}
\end{figure}


\begin{figure}[t]
    \centering
    \begin{tikzpicture}[
        >=Stealth,
        scale=1,
        every node/.style={font=\small}
    ]

    % Time axis
    \draw[->] (0,0) -- (11,0) node[anchor=west] {time};

    % Underlying continuous power (conceptual)
    \draw[gray] plot[smooth] coordinates {
        (0.5,0.6)
        (1.5,1.2)
        (2.5,0.8)
        (3.5,1.6)
        (4.5,1.0)
        (5.5,1.8)
        (6.5,1.1)
        (7.5,1.5)
        (8.5,0.9)
        (9.5,1.3)
    };
    \node[gray] at (2.2,1.9) {instantaneous GPU power};

    % NVML internal update points
    \foreach \x in {1.0,3.0,5.0,7.0,9.0} {
        \draw[very thick] (\x,0.2) -- (\x,0.5);
    }
    \node[below] at (1.0,0.2) {NVML updates};

    % Tycho sampling aligned to NVML phase
    \foreach \x in {1.0,3.0,5.0,7.0,9.0} {
        \draw[fill=black] (\x,0.5) circle (0.06);
    }
    \node[above] at (7.0,0.7) {Tycho phase-aware samples};

    \end{tikzpicture}
    \caption{Conceptual view of GPU power as a continuous signal, periodically updated internal NVML values, and Tycho’s phase-aware sampling aligned to these updates. No specific update interval or magnitude is implied.}
    \label{fig:nvml_phase_sampling}
\end{figure}



% ----------------------------------------------------------------------
\subsection{Comparison to Kepler Timing Model}
\label{subsec:kepler_comparison}

Kepler employs a synchronous timing model in which all metric domains (except Redfish) are sampled in a single periodic poll cycle. A fixed-length polling interval defines both the sampling cadence and the logical unit of attribution. Redfish updates occur at a much slower pace and the most recent Redfish value is reused across multiple intervals. Export occurs at a separate cadence, which may not match the attribution interval.

Tycho diverges fundamentally: collectors run independently, windows are defined by analysis triggers rather than poll cycles, the model permits heterogeneous update patterns, and export occurs immediately after each attribution step. This structure enables finer temporal resolution, avoids dependence on synchronous poll-time alignment, and eliminates inconsistencies between data collection and publishing intervals.

\medskip
\noindent\textbf{Diagram placeholder: Tycho vs.\ Kepler timing}  
Side-by-side schematic:  
\begin{itemize}[nosep]
\item Kepler: uniform sample bars, single poll loop, slow Redfish track.  
\item Tycho: independent sample tracks and window-based attribution with immediate export.  
\end{itemize}




% ----------------------------------------------------------------------
\section{Metric Sources as Temporal Actors}
\label{sec:metric_sources}

% OVERALL LENGTH:
%   ~3–4 pages including one diagram (NVML phase-aware sketch).
%   This section is conceptual and emphasises *temporal characteristics* of
%   each metric source, not technical APIs or implementation detail.
%
% PURPOSE:
%   Present each domain not as a collector implementation but as a *temporal
%   signal* with characteristic behaviour, constraints, and uncertainties.
%   This sets up the attribution logic in later sections (especially domain
%   consistency and uncertainty handling).


% ----------------------------------------------------------------------
\subsection{CPU/RAPL Domains}
\label{subsec:rapl_temporal}

% LENGTH:
%   ~0.75 page.

% PURPOSE:
%   Characterise RAPL as a cumulative energy domain with effectively
%   continuous behaviour, explaining how this shapes its integration into
%   Tycho’s event-time model.

% MUST INCLUDE:
%   - Conceptual description of RAPL domains relevant to energy modelling:
%       * package, core, uncore, dram (depending on hardware availability).
%   - Explanation that RAPL exposes *cumulative energy counters* that are
%     monotonically increasing with wraparound.
%   - Emphasise temporal implications:
%       * These counters reflect energy consumed over time, not instantaneous
%         power.
%       * Event-time behaviour is reconstructed by differencing consecutive
%         samples.
%       * The temporal resolution is limited only by sampling rate and by
%         variability in hardware update intervals.
%   - State clearly:
%       * No sysfs paths.
%       * No discussion of actual polling code.
%   - Mention wraparound conceptually:
%       * Wraparound must be detectable and corrected in the analysis model
%         (details appear in the implementation chapter, not here).

% MAY INCLUDE:
%   - Short illustrative formula:
%       \[
%           \Delta E = E(t_2) - E(t_1), \qquad
%           \bar{P} \approx \Delta E / (t_2 - t_1).
%       \]
%     Keep it conceptual; detailed discrete handling belongs later.

% MUST NOT INCLUDE:
%   - Any numeric update rates.
%   - Implementation mechanics (paths, syscalls).
%   - Hardware-specific quirks except at a conceptual level.


% ----------------------------------------------------------------------
\subsection{GPU/NVML Domains}
\label{subsec:nvml_temporal}

% LENGTH:
%   ~1 to 1.25 pages including one diagram.

% PURPOSE:
%   Present GPU power as a temporally rich domain with distinct properties
%   relative to CPU/RAPL, especially:
%       * instantaneous vs averaged signals,
%       * phase-aware sampling,
%       * domain-internal averaging performed by NVML.

% MUST INCLUDE:
%   - Explanation of two kinds of NVML-reported power:
%       * The commonly used *averaged* power metric (e.g. `nvmlDeviceGetPowerUsage`)
%         which is internally averaged over tens of milliseconds.
%       * The *instantaneous* or *sensor-level* NVML FIELD used by Tycho,
%         representing a more direct sample of current power draw.
%   - Rationale:
%       * The instantaneous metric provides more accurate temporal structure,
%         crucial for Tycho’s event-time model.
%       * Existing research often relies on the averaged metric, which obscures
%         fast changes; Tycho’s architecture explicitly avoids this limitation.
%   - Description of phase-aware sampling:
%       * NVML internally updates power at discrete but undocumented intervals.
%       * Tycho aligns sampling with NVML’s phase characteristics to reduce
%         aliasing and improve temporal coherence.
%   - Conceptual explanation of delay:
%       * NVML reports reflect a small delay relative to actual physical
%         events; calibration helps quantify this.
%   - Mention that GPU load, memory, and other utilisation signals may have
%     different temporal patterns, but details belong in the implementation
%     chapter.

% DIAGRAM (IMPORTANT):
%   - A schematic showing:
%       * Underlying GPU instantaneous power as a continuous curve.
%       * NVML internal update points.
%       * Tycho’s phase-aware sampling markers aligned with these points.
%     Do not include numerical values.

% MUST NOT INCLUDE:
%   - API names beyond generic references ("averaged" vs "instantaneous").
%   - Numeric defaults or specific sampling intervals.
%   - GPU architecture or kernel driver details (implementation chapter).

% MAY INCLUDE:
%   - A sentence noting that Tycho’s design intentionally treats GPU and CPU
%     domains asymmetrically due to their different temporal behaviours.


% ----------------------------------------------------------------------
\subsection{Redfish/BMC Power Source}
\label{subsec:redfish_temporal}

% LENGTH:
%   ~0.5 page.

% PURPOSE:
%   Present Redfish power readings as coarse but authoritative signals,
%   explaining their role in Tycho’s event-time model and as potential
%   triggers for window formation.

% MUST INCLUDE:
%   - Description of Redfish as a low-frequency, aggregated node-level power
%     source.
%   - Emphasise:
%       * Long and variable sample intervals (hundreds of milliseconds to
%         seconds).
%       * Availability of *freshness indicators* (e.g. timestamps or update
%         counters), enabling Tycho to interpret event times more accurately
%         than relying on poll time alone.
%   - Explain its architectural role:
%       * Acts as the authoritative “total node power” reference.
%       * May serve as the trigger for window completion in some modes.
%   - Conceptual temporal implications:
%       * Redfish readings often span windows and therefore define natural
%         analysis boundaries.
%       * Their low frequency introduces uncertainty that must be handled
%         explicitly in attribution.

% MUST NOT INCLUDE:
%   - JSON paths, HTTP details, schema structures.
%   - Vendor-specific differences (implementation chapter).


% ----------------------------------------------------------------------
\subsection{eBPF and Software Counters}
\label{subsec:ebpf_temporal}

% LENGTH:
%   ~0.75 page.

% PURPOSE:
%   Characterise software-side utilisation metrics (CPU time, IO counts,
%   scheduler events, cgroup stats) as temporally diverse signals:
%       * some cumulative,
%       * some event-driven,
%       * some quasi-instantaneous.

% MUST INCLUDE:
%   - eBPF as event-driven:
%       * Metrics recorded exactly at the moment events occur.
%       * Intrinsic high temporal resolution.
%       * Non-uniform density, reflecting workload behaviour.
%   - Cgroup and /proc counters:
%       * Cumulative counters updated by kernel mechanisms.
%       * Polling resolution determines effective temporal resolution.
%   - Integration into Tycho’s temporal model:
%       * All samples receive global monotonic timestamps.
%       * Event-driven metrics require different aggregation logic than
%         cumulative counters or instantaneous hardware readings.
%   - Abstract temporal implications:
%       * eBPF may contribute many events within a single analysis window.
%       * Cgroup stats may contribute only a few samples.

% MUST NOT INCLUDE:
%   - Implementation specifics (maps, programs, syscalls).
%   - Kernel tick behaviour beyond a conceptual remark.

% MAY INCLUDE:
%   - One sentence linking this to the requirement for domain-level
%     consistency.


% ----------------------------------------------------------------------
\subsection{Conceptual Limitations and Uncertainty Sources}
\label{subsec:uncertainty_sources}

% LENGTH:
%   ~0.75 page.

% PURPOSE:
%   Summarise cross-domain temporal mismatch and inherent sampling
%   uncertainty. This closes the section by motivating the modelling
%   techniques introduced in the next chapter subsection.

% MUST INCLUDE:
%   - Identification of uncertainty sources:
%       * Temporal mismatch between domains (fast GPU, slow Redfish).
%       * Internal sensor averaging (NVML averaged metric).
%       * Jitter in software counters.
%       * Acquisition delays.
%       * Missing samples.
%   - Explain that these are not “errors” but natural constraints of
%     multi-source measurement systems.
%   - Clarify that Tycho’s architecture does not attempt perfect
%     synchronisation; instead it:
%       * constructs windows that respect each domain’s timing,
%       * propagates uncertainty forward to the analysis stage.

% MUST NOT INCLUDE:
%   - Numerical error bounds.
%   - Details of uncertainty quantification (belongs in analysis chapter).

% MAY INCLUDE:
%   - A forward reference: “The analysis engine (Section~\S\ref{sec:analysis_model})
%     incorporates these uncertainties by …”
%     Keep this brief.

% DIAGRAM:
%   - None required; the section is integrative and conceptual.




% ----------------------------------------------------------------------
\section{Analysis and Attribution Model}
\label{sec:analysis_model}

% OVERALL LENGTH:
%   ~3 pages for the placeholder structure in its current vague state.
%   This section MUST remain deliberately non-committal because the actual
%   analysis architecture has not been designed yet. The purpose of this
%   placeholder is to define *what kinds of content belong here*, not how
%   they will ultimately be realised.

% GUIDING NOTE:
%   Every subsection must avoid implying a specific algorithmic choice.
%   The text here should describe the *space of responsibilities* and the
%   *conceptual relationships* that the analysis model will eventually need
%   to address. No assumptions about regression models, ratio models,
%   interpolation schemes, fairness models, or uncertainty propagation may
%   be embedded in the placeholder until the real architecture is defined.


% ----------------------------------------------------------------------
\subsection{Problem Definition}
\label{subsec:analysis_problem_definition}

% LENGTH:
%   ~0.5 page.

% MUST INCLUDE (conceptually):
%   - A broad definition of the attribution task: given per-domain metric
%     samples organised into analysis windows (constructed by the timing
%     engine), the analysis phase must reconstruct estimates of:
%         * window-level domain energies,
%         * their temporal alignment,
%         * and their assignment to workloads.
%   - Clarification that this involves:
%         * combining heterogeneous signals,
%         * interpreting incomplete or uncertain data,
%         * and generating per-container or per-pod energy estimates.
%   - Emphasise that the analysis engine is a *model* that interprets
%     measurements, not a mere aggregator.

% MUST NOT INCLUDE:
%   - Any specific modelling approach (e.g. ratio models, regressions).
%   - Any concrete algorithmic steps or formulas other than purely symbolic.


% ----------------------------------------------------------------------
\subsection{Energy Reconstruction Across Domains}
\label{subsec:energy_reconstruction}

% LENGTH:
%   ~0.75 page.

% MUST INCLUDE (conceptually):
%   - Statement that the analysis model must combine CPU, GPU, uncore,
%     memory, and total-node power (e.g. Redfish) into a coherent picture
%     of energy consumption in each window.
%   - A generic decomposition identity (symbolic, not algorithmic):
%       \[
%           P_{\text{total}}(t)
%           =
%           P_{\text{cpu}}(t)
%           +
%           P_{\text{gpu}}(t)
%           +
%           P_{\text{uncore}}(t)
%           +
%           P_{\text{other}}(t)
%           + \varepsilon(t),
%       \]
%     where \(\varepsilon(t)\) symbolises modelling uncertainty.
%   - Explanation that this decomposition is conceptual only: the exact
%     interpretation, estimation steps, and domain interactions will be
%     defined later when the actual architecture is available.
%   - Mention that samples may arrive at different temporal resolutions, so
%     reconstruction must interpret them within analysis windows.

% MUST NOT INCLUDE:
%   - Any discussion of how “other” or “uncore” will be computed.
%   - Any concrete rules for combining domains (e.g. prioritisation,
%     proportionality, ratios, filtering).


% ----------------------------------------------------------------------
\subsection{Container-Level Attribution}
\label{subsec:container_attribution}

% LENGTH:
%   ~1 page.

% MUST INCLUDE (conceptually):
%   - High-level role of utilisation metrics, metadata, and domain energies:
%       * utilisation data describes workload behaviour,
%       * metadata maps processes and cgroups to containers,
%       * domain windows describe where energy originates,
%     and attribution must relate these.
%   - State that the analysis model must eventually produce per-container
%     energy estimates for each window.
%   - Clarify that:
%       * attribution may depend on utilisation patterns,
%       * attribution must support partial and uncertain data,
%       * attribution must remain stable under short-lived containers.

% DIAGRAM PLACEHOLDER:
%   - A conceptual attribution-flow diagram:
%       * Inputs: domain-window energies, utilisation metrics, metadata.
%       * Outputs: per-container energy contributions.
%       * No arrows showing mathematical rules — only conceptual flows.
%     The final diagram will be drawn once the architecture is fixed.

% MUST NOT INCLUDE:
%   - Any allocation rules (e.g. proportional, residual-split, regression).
%   - Any equations mapping utilisation to energy.


% ----------------------------------------------------------------------
\subsection{Residual Power Attribution}
\label{subsec:residual_power}

% LENGTH:
%   ~0.5 page.

% MUST INCLUDE (conceptually):
%   - Statement that some portion of node-level power may not be explained
%     directly by CPU or GPU domains.
%   - Clarification that the analysis model must provide a *conceptual*
%     mechanism to:
%         * quantify residual energy,
%         * distribute it meaningfully or mark it as uncertainty,
%     but without specifying how this will be done.
%   - Acknowledgement that residual handling is central to transparency and
%     must make implicit assumptions explicit.

% MUST NOT INCLUDE:
%   - Any specific strategy for distributing residual energy.
%   - Any mathematical formulas for residual modelling.


% ----------------------------------------------------------------------
\subsection{Requirements Satisfaction}
\label{subsec:analysis_requirements}

% LENGTH:
%   ~0.5 page.

% MUST INCLUDE:
%   - A *forward-looking* statement that the analysis engine, once designed
%     and implemented, must satisfy the requirements in Ch.~3, especially:
%         * temporal coherence,
%         * domain-level consistency,
%         * transparency of assumptions,
%         * lifecycle robustness,
%         * uncertainty awareness.
%   - Indicate that these requirements constrain the future design of:
%         * how windows are interpreted,
%         * how uncertainty is propagated,
%         * how attribution is stabilised for container churn,
%         * and how assumptions must be externally visible.
%   - Emphasise that this subsection is not a proof — it merely establishes
%     the criteria by which the final analysis design will later be judged.

% MUST NOT INCLUDE:
%   - Any premature claims about how the analysis will satisfy requirements.
%   - Any commitments to specific algorithms or models.



% ----------------------------------------------------------------------
\section{Calibration Framework (Conceptual)}
\label{sec:calibration_framework}

% OVERALL LENGTH:
%   ~1.5 to 2 pages. This section remains conceptual and intentionally
%   light on detail. Its purpose is to explain *why calibration exists* in
%   Tycho, *what kinds of quantities must be calibrated*, and *how*
%   calibration conceptually influences timing and analysis.
%
%   Absolutely no specific calibration algorithms, scripts, or procedures
%   should appear here — those belong to the implementation chapter.


% ----------------------------------------------------------------------
\subsection{Calibration Objectives}
\label{subsec:calibration_objectives}

% LENGTH:
%   ~0.5 page.

% PURPOSE:
%   Define the conceptual goals of calibration without describing how any of
%   them are achieved. This subsection motivates why calibration is a core
%   architectural component.

% MUST INCLUDE (conceptually):
%   - A statement that Tycho treats calibration as an integral architectural
%     element supporting the timing engine and analysis model.
%   - High-level enumeration of calibration objectives:
%       * Delay estimation:
%           Understanding systematic lag between event time and poll time
%           for each collector domain.
%       * Idle baseline identification:
%           Estimating the idle power or idle-domain behaviour needed to
%           interpret load-dependent measurements.
%       * Validation of collector timing characteristics:
%           Checking whether collectors behave as expected (e.g., update
%           intervals, jitter bounds).
%   - Emphasise that calibration outputs *constraints* or *metadata* that
%     inform the timing and analysis phases, not direct energy estimates.

% MAY INCLUDE:
%   - A brief remark that calibration must be repeatable and must not assume
%     stable hardware behaviour over long time periods.

% MUST NOT INCLUDE:
%   - Any actual calibration experiments, scripts, Python tools, or metrics.
%   - Specific numeric thresholds or default values.


% ----------------------------------------------------------------------
\subsection{Calibration Procedures}
\label{subsec:calibration_procedures}

% LENGTH:
%   ~0.5 to 0.75 page.

% PURPOSE:
%   Describe the *conceptual structure* of calibration routines without
%   committing to specific algorithms or processes. This establishes the
%   architectural hooks where calibration interacts with the timing engine.

% MUST INCLUDE (conceptually):
%   - A high-level description that calibration is carried out through
%     controlled measurements or observation phases, but:
%       * exact measurement methods,
%       * stress tools,
%       * sampling schedules,
%       are left unspecified.
%   - Clarification that calibration interacts with the timing engine by:
%       * informing expected update intervals,
%       * providing approximate delay distributions,
%       * identifying jitter characteristics,
%       * establishing confidence bounds used to assess sample freshness.
%   - A conceptual explanation that calibration may need to run:
%       * during system startup,
%       * periodically or conditionally,
%       * or when hardware/collector behaviour changes.
%   - Emphasise that calibration modifies *interpretation*, not *data*.

% MAY INCLUDE:
%   - Placeholder sentence indicating that the concrete structure of
%     calibration logic (e.g., separation into phases or routines) will be
%     defined once the analysis architecture is finalised.

% MUST NOT INCLUDE:
%   - Any procedural instructions (e.g., “run X for Y seconds”).
%   - Any discussion of tooling (stress-ng, gpu-burn, scripts, etc.).
%   - Any diagrams, unless extremely conceptual (e.g., “calibration outputs
%     feed into timing engine inputs”) — but omit for now.


% ----------------------------------------------------------------------
\subsection{Integration with Attribution}
\label{subsec:calibration_integration}

% LENGTH:
%   ~0.5 page.

% PURPOSE:
%   Explain, in purely conceptual terms, how calibration results constrain
%   and inform the analysis model, without specifying the model itself.

% MUST INCLUDE (conceptually):
%   - Statement that calibration provides domain-specific metadata that the
%     analysis engine must respect:
%       * estimated delay bounds,
%       * expected update frequency ranges,
%       * idle baseline interpretations,
%       * uncertainty indicators.
%   - Clarification that such calibration outputs influence:
%       * which samples are considered valid or stale,
%       * how windows are aligned,
%       * how domain energies are reconstructed,
%       * how uncertainty is propagated.
%   - Emphasise that calibration enhances transparency: assumptions about
%     timing and domain behaviour are explicitly documented, not hidden in
%     inference logic.

% MAY INCLUDE (OPTIONAL):
%   - A forward reference noting that the final analysis architecture will
%     detail how these calibration-derived constraints enter formal models.

% MUST NOT INCLUDE:
%   - Any specific way that calibrated values affect formulas.
%   - Any commitment to particular uncertainty propagation methods.
%   - Any mention of per-domain weighting schemes or decision thresholds.




% ----------------------------------------------------------------------
\section{Metadata and Lifecycle Integration}
\label{sec:metadata_integration}

% OVERALL LENGTH:
%   ~1.5 to 2 pages. This section provides the conceptual foundation for how
%   Tycho handles container identities, pod lifecycles, and the mapping
%   between processes, cgroups, and Kubernetes objects.
%
% PURPOSE:
%   - Explain *why* metadata is essential for attribution.
%   - Describe metadata as a *temporal signal* with its own lifecycle,
%     freshness requirements, and uncertainties.
%   - Show how metadata interacts with timing and analysis without touching
%     implementation specifics.


% ----------------------------------------------------------------------
\subsection{Role of Metadata Freshness}
\label{subsec:metadata_freshness}

% LENGTH:
%   ~0.5 to 0.75 page.

% PURPOSE:
%   Establish metadata as a time-sensitive component of the architecture,
%   not merely a static lookup table.

% MUST INCLUDE (conceptually):
%   - Clarify that metadata describes the relationship between:
%       * processes,
%       * cgroups,
%       * containers,
%       * pods,
%       * workloads (deployments, jobs, etc.).
%   - Emphasise that container metadata changes over time:
%       * Pods start, restart, terminate.
%       * PIDs appear and disappear.
%       * Cgroup hierarchies evolve dynamically.
%   - Explain why stale metadata is problematic:
%       * Incorrect or outdated mappings produce inaccurate attribution.
%       * Fast-changing workloads (e.g., batch jobs, ephemeral sidecars)
%         require metadata with predictable freshness.
%   - Motivation for a local metadata cache:
%       * Sampling metadata directly from Kubernetes APIs or cgroup
%         hierarchies on each analysis window would be too slow or
%         inconsistent.
%       * A local cache provides a temporally stable snapshot with known
%         age bounds.

% MAY INCLUDE:
%   - A conceptual note that metadata has its own lifecycle which must
%     integrate with the timing model (e.g., metadata update times also
%     occur in event time).

% MUST NOT INCLUDE:
%   - Any API paths, structs, or polling intervals.
%   - Details of how metadata is stored internally.


% ----------------------------------------------------------------------
\subsection{Mapping Processes to Containers}
\label{subsec:process_container_mapping}

% LENGTH:
%   ~0.5 to 0.75 page.

% PURPOSE:
%   Describe the conceptual relationship between raw OS-level processes and
%   higher-level Kubernetes workload identities. This establishes the
%   foundation for how utilisation metrics eventually contribute to
%   attribution.

% MUST INCLUDE (conceptually):
%   - A clear high-level description of the mapping ladder:
%       process → cgroup → container → pod → workload identity.
%   - Explain that utilisation metrics (CPU time, IO events, GPU context
%     activity, etc.) are recorded at process or cgroup granularity, but
%     attribution must occur at container or pod granularity.
%   - Statement that the mapping is *conceptual* and must be:
%       * correct over time,
%       * consistent with container lifecycle events,
%       * robust to short-lived processes.
%   - Mention that mapping must handle:
%       * multi-process containers,
%       * nested cgroups,
%       * reused PIDs,
%       * containers that terminate between metadata refreshes.

% MUST NOT INCLUDE:
%   - Implementation detail of how PIDs or cgroups are enumerated.
%   - Any discussion of container runtimes or kubelet internals.
%   - Specific naming conventions, file paths, or label formats.

% MAY INCLUDE:
%   - A short high-level conceptual figure (optional for now):
%       * Boxes representing processes → containers → pods.
%       * Arrows showing mapping direction.
%     Keep this diagram simple and entirely conceptual.


% ----------------------------------------------------------------------
\subsection{Handling Churn and Missing Metadata}
\label{subsec:metadata_churn}

% LENGTH:
%   ~0.5 page.

% PURPOSE:
%   Describe how Tycho conceptually maintains stable attribution semantics
%   when workloads appear, disappear, or fail unexpectedly. This subsection
%   is crucial for satisfying lifecycle-robustness and uncertainty-awareness
%   requirements from Ch.~3.

% MUST INCLUDE (conceptually):
%   - Explanation of *churn*:
%       * Short-lived containers (milliseconds to seconds).
%       * Frequent pod terminations or restarts.
%       * Workloads with unpredictable behaviour (batch jobs, CI runners).
%   - Explain the problem:
%       * Containers may terminate before utilisation data is processed.
%       * Metadata may be incomplete at the moment a window must be
%         analysed.
%       * Some metadata may never be observed (e.g., very short-lived pods).
%   - High-level strategies (without committing to specific mechanisms):
%       * Use metadata validity intervals: metadata is considered valid only
%         within a bounded time from its last refresh.
%       * If metadata is missing or stale, attribution must introduce:
%           - uncertainty markers, or
%           - fallback interpretations.
%       * Terminated containers must still be attributed for their active
%         windows, even if they no longer exist at analysis time.

% MUST NOT INCLUDE:
%   - Details of eviction strategies in the cache.
%   - Any specific fallback rule for missing metadata.
%   - Mention of implementation specifics like TTLs or update frequencies.

% MAY INCLUDE:
%   - A forward reference: this behaviour influences attribution uncertainty
%     handled in Section~\S\ref{sec:analysis_model}.


% ----------------------------------------------------------------------
\section{Architectural Trade-Offs and Alternatives Considered}
\label{sec:tradeoffs}

% OVERALL LENGTH:
%   ~1.5 to 2 pages. This section is intentionally reflective and conceptual.
%   Its purpose is not to provide implementation details, but to document
%   *design-space exploration* and *architectural rationale*.  
%
%   Each subsection describes:
%     - which broad alternatives exist,
%     - why they were considered,
%     - why Tycho does not adopt them (or adopts parts of them),
%     without committing to specific implementation mechanics.


% ----------------------------------------------------------------------
\subsection{Alternative Timing Designs}
\label{subsec:alternative_timing}

% LENGTH:
%   ~0.5 to 0.75 page.

% PURPOSE:
%   Clearly position Tycho’s independent, event-time-driven timing model
%   against simpler alternatives, especially tick-synchronised polling.

% MUST INCLUDE (conceptually):
%   - Description of the two dominant timing paradigms:
%       * Tick-synchronised polling:
%           - A single global polling interval.
%           - All domains sampled at the same moment.
%           - Simplicity and uniformity as benefits.
%       * Independent domain-aware polling:
%           - Each domain sampled at its own suitable frequency.
*           - Asynchrony is expected and preserved.
%   - High-level comparison:
%       * Tick-based model is simple but disregards domain-specific temporal
%         characteristics and introduces aliasing or under-sampling.
%       * Independent model respects domain behaviour but increases system
%         complexity.
%   - State explicitly that Tycho adopts independent polling because it
%     satisfies Ch.~3 requirements for temporal coherence and domain-level
%     consistency.

% MUST NOT INCLUDE:
%   - Numeric intervals, polling code, scheduling mechanisms.
%   - Direct references to Kepler internals (those belong elsewhere).

% MAY INCLUDE:
%   - A conceptual diagram (optional): two timelines, one aligned on ticks,
%     one irregular. Keep it very abstract.


% ----------------------------------------------------------------------
\subsection{Alternative Attribution Strategies}
\label{subsec:alternative_attribution}

% LENGTH:
%   ~0.5 to 0.75 page.

% PURPOSE:
%   Acknowledge the existence of multiple broad modelling philosophies for
%   energy attribution, and clarify why Tycho’s future analysis model must
%   adhere to the conceptual requirements instead of adopting a simplistic
%   approach.

% MUST INCLUDE (conceptually):
%   - High-level overview of possible attribution paradigms:
%       * Direct regression models:
%           - Fit resource utilisation to power.
%           - Require stable training sets and assume stationary workloads.
%       * Static analytical models:
%           - Predefined power coefficients.
%           - Simple but brittle; do not capture dynamic behaviour.
%       * Ratio-based or proportional models:
%           - Divide energy by utilisation proportions.
%           - Fast but sensitive to noise and unsuitable for multi-domain
%             temporal mismatches.
%   - State that these approaches were considered conceptually but present
%     challenges relative to Tycho’s requirements:
%       * They often hide modelling assumptions.
%       * They may require artificially synchronised metrics.
%       * They may be sensitive to incomplete windows and uncertain data.
%   - Emphasise that the final Tycho analysis design will be driven by the
%     architectural requirements (transparency, uncertainty, lifecycle
%     robustness), which limits reliance on the above simplistic methods.

% MUST NOT INCLUDE:
%   - Any specific commitment to Tycho’s own method.
%   - Any preliminary equations for Tycho’s analysis model.
%   - Criticism of existing tools beyond conceptual limitations.


% ----------------------------------------------------------------------
\subsection{Complexity vs Accuracy Considerations}
\label{subsec:complexity_accuracy}

% LENGTH:
%   ~0.5 page.

% PURPOSE:
%   Provide a conceptual justification for Tycho’s architectural decisions
%   by discussing the trade-off between system complexity and measurement
%   accuracy.

% MUST INCLUDE (conceptually):
%   - Acknowledge that:
%       * Independent collectors,
%       * Event-time reconstruction,
%       * Window-based attribution,
%       * Calibration, and
%       * Metadata lifecycle handling
%     each introduce architectural complexity.
%   - Explain why accuracy cannot be achieved with simpler designs:
%       * Fixed-frequency polling under-samples critical domains.
%       * Simplistic attribution hides uncertainty.
%       * Ignoring metadata freshness yields incorrect workload identities.
%   - Emphasise the architectural stance:
%       * Complexity is tolerated where it meaningfully improves model
%         transparency and temporal fidelity.
%       * Abstraction boundaries (collectors, timing, analysis) help confine
%         complexity so that individual components remain understandable and
%         maintainable.
%   - Reiterate linkage to Ch.~3:
%       * Accuracy and transparency are mandatory requirements, therefore
%         architectural complexity is justified and bounded.

% MUST NOT INCLUDE:
%   - Any implementation detail describing how complexity is handled (e.g.,
%     concurrency primitives, memory optimisation).
%   - Specific numeric performance comparisons (those belong in evaluation).

% MAY INCLUDE:
%   - A single brief example illustrating that small increases in
%     architectural sophistication (e.g., recognising NVML phase behaviour)
%     yield disproportionately large accuracy improvements, but keep it very
%     abstract.



% ----------------------------------------------------------------------
\section{Summary}
\label{sec:summary_ch4}

% LENGTH:
%   ~0.5 page. This should be compact and high-level.
%
% PURPOSE:
%   - Provide a concise synthesis of the architectural principles and
%     subsystem roles described in the chapter.
%   - Reinforce the formal link between the requirements in Ch.~3 and the
%     design choices presented here.
%   - Prepare the reader for the transition to the concrete implementation
%     details in Ch.~5 without repeating them.


% MUST INCLUDE (conceptually):
%   - A brief restatement that Tycho’s architecture is shaped directly by
%     the requirements established in Chapter~3:
%       * temporal coherence,
%       * domain-level consistency,
%       * transparent modelling assumptions,
%       * lifecycle robustness,
%       * uncertainty awareness.
%   - A short summary of the major architectural elements introduced:
%       * independent, domain-aware metric collectors,
%       * the event-time-based timing engine and window model,
%       * conceptual structure of the analysis and attribution model,
%       * calibration as a supporting subsystem informing timing and
%         interpretation,
%       * metadata freshness and mapping requirements for workload identity.
%   - Emphasise that this chapter defined **what** Tycho must do and **why**
%     it must do it in this way, but not **how** it is implemented.

% MAY INCLUDE:
%   - One sentence noting that several subsystems (e.g., collectors, metadata,
%     exporter) will be discussed again in Ch.~5 from an implementation
%     viewpoint.
%   - A remark that the detailed analysis model will be finalised and
%     justified in Ch.~5 once its architectural constraints are fully
%     resolved.

% MUST NOT INCLUDE:
%   - Any technical / implementation detail.
%   - Any new architectural concepts not already introduced.
%   - Any evaluative statements (evaluation belongs in a later chapter).

% POINTER TO NEXT CHAPTER:
%   - Conclude with a short forward reference along the lines of:
%       “The following chapter describes the concrete implementation of these
%        architectural components, including the collectors, timing engine,
%        metadata subsystem, calibration routines, and the initial analysis
%        mechanisms.”
%     Keep this phrasing high-level and free of specifics.

