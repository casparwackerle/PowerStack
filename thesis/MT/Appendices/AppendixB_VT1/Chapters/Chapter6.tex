% Indicate the main file. Must go at the beginning of the file.
% !TEX root = ../main.tex
\chapter{Discussion}
\label{vt1_Chapter6}

\section{Conclusion and Evaluation}

\subsection{Evaluation of Cluster Setup}

The cluster setup was successful and proved viable for further Kubernetes testing. While implementing the entire setup in an automated manner required substantial additional effort, the resulting deployment functioned reliably throughout the project. The ability to tear down and re-deploy the cluster at any desired depth (ranging from Kubernetes deployments and configurations to a complete reinstallation) was invaluable during experimentation. This ensured that any misconfigurations introduced during implementation could be fully removed, preventing residual effects from failed installations or incorrect configurations.

The automated setup was intentionally designed for portability across different hardware platforms. Although this capability was not tested within the project, it significantly increases the setup’s reusability. Future work could adapt and deploy the setup with minimal adjustments, enabling researchers and engineers to quickly establish experimental Kubernetes clusters in diverse environments.

One of the primary constraints of this project was the decision not to implement a high-availability (HA) cluster. Given the project’s focus on energy efficiency measurements rather than production-grade reliability, this was an appropriate trade-off. However, HA clusters are standard in large-scale production systems. Energy efficiency research in such environments could offer additional insights into how energy optimization strategies behave under real-world workload distributions.

Finally, graphical tools such as Rancher proved extremely useful during configuration and experimentation. Rancher’s centralized UI provided a clear overview of cluster state, simplifying Kubernetes troubleshooting and management. While the project emphasized automation, Rancher complemented the setup by offering real-time monitoring and fast identification of configuration issues.

\subsection{Evaluation of Monitoring Setup}

The monitoring setup proved effective for energy consumption testing. Prometheus, the de facto standard for Kubernetes monitoring, ensured compatibility with a wide range of tools and provided access to extensive community support, documentation, and integrations. This was particularly advantageous for Kepler, which integrates directly with Prometheus, resulting in a smooth deployment and data collection process.

A notable limitation of Prometheus is the overhead and granularity constraints introduced by periodic metric scraping. It is well suited for system monitoring at multi-second or minute-level intervals, but this limits its usefulness in high-resolution energy consumption analysis. While Kepler collects large amounts of data through eBPF and RAPL, the need to reduce data density for Prometheus-friendly exports leads to a loss of granularity. Thus, Prometheus excels at long-term trend analysis but is suboptimal for capturing rapid fluctuations in power consumption.

The use of NFS-based persistent storage on the Kubernetes control node proved reliable. Throughout the project (including multiple cluster redeployments) no monitoring data was lost. The NFS setup ensured persistent storage for Prometheus and Grafana, maintaining historical data even when the cluster was reset.

Although this monitoring setup is well suited for experimentation and research, deploying it in a production environment would require significant enhancements to ensure data integrity, resilience, and security. For instance, Prometheus data retention and storage configurations would need reinforcement, authentication and authorization mechanisms would require strengthening, and redundancy would be necessary to prevent data loss in the event of node failure.

\subsection{Evaluation of Kepler}

Kepler was integrated successfully using the provided Helm chart, although several configuration adjustments were required to ensure compatibility with the existing infrastructure. The project documentation, while helpful, has not yet reached full maturity, resulting in occasional challenges during setup and troubleshooting. Despite these hurdles, Kepler’s underlying concept is well-founded, using suitable data sources to estimate energy consumption at both the container and node levels.

\subsubsection{General Observations}

\begin{itemize}
    \item All metrics exhibited pronounced and consistent oscillations. Since the metrics are computed from simple counters, this indicates a synchronization issue, possibly between Kepler’s metric publication intervals and Prometheus’ scraping intervals. While this does not undermine the credibility of the data, resolving it would greatly improve the usability of the metrics.
    \item \textbf{CPU Energy Metrics:}  
    Kepler successfully captures workload-dependent energy variations, showing a strong correlation between CPU stress levels and estimated power consumption. Since CPU load is the dominant factor in overall server energy consumption, this is a significant strength of Kepler.
    \item \textbf{Memory Energy Metrics:}  
    Unlike CPU metrics, memory energy estimates did not show a clear correlation with applied workload. However, this is not necessarily a flaw in Kepler’s methodology. Memory typically accounts for a small proportion of overall server energy consumption and varies far less than CPU power. Thus, the lack of a pronounced correlation is not unexpected. However, the experiment did not verify Kepler’s ability to measure memory energy consumption.
    \item \textbf{Disk~I/O and Network~I/O Metrics:}  
    Kepler’s energy estimates for disk and network activity did not follow the expected trends. Although the metrics responded to workload transitions in a time-synchronized manner, the exact correlation remained unclear. In particular, disk and network energy consumption values were not proportional to the applied stress levels. This anomaly warrants further investigation, especially considering that HDD power consumption is known to depend only weakly on workload intensity.
\end{itemize}

\subsection{Credible Takeaways from the Test Results}

\textbf{Kepler’s package metrics appear reliable and provide plausible results.}  
Although the absolute values were not validated within the scope of this project, the reported metrics closely matched the CPU workload trends observed during testing.

\textbf{Energy consumption does not scale linearly with workload.}  
For package power, increasing the workload from 10\% to 90\% resulted in only an approximately 250\% increase in Kepler-estimated energy consumption. This aligns with the well-known observation that servers operate most efficiently at higher utilization levels.

\textbf{Idle energy consumption was consistently estimated to be much higher than dynamic energy consumption.}  
While older servers are known to exhibit high idle power usage, Kepler’s estimate that idle energy consumption reaches roughly 90\% on a CPU-stressed server seems unlikely and requires further investigation.

These findings suggest that Kepler’s CPU energy estimation is robust, while inconsistencies in memory, disk, and network energy metrics highlight areas requiring additional validation. This naturally motivates future research into improving Kepler’s measurement accuracy.

\section{Future Work}

\subsection{Detailed Analysis of Kepler}

While Kepler demonstrates strong capabilities in CPU power estimation, the inconsistencies in its memory, disk, and network metrics indicate areas requiring further research. A limitation of this study was its reliance on a single server platform. A meaningful next step would be to compare Kepler’s energy estimates across different hardware configurations to evaluate generalizability.

\subsection{Kepler Metrics Verification Through Elaborate Tests, Possibly Using Measuring Hardware}

Kepler’s metrics should be validated through more extensive and diverse test scenarios, using different stress tools and workloads. In some cases, integrating physical power measurement hardware could offer an additional validation layer. With deeper insight into Kepler’s internal mechanisms, it may become possible to verify the reported metrics directly. Ultimately, ensuring that Kepler metrics accurately reflect energy consumption at both the node and container levels is essential for establishing their reliability.

\subsection{Kubernetes Cluster Energy Efficiency Optimization}

If Kepler metrics prove reliable for cluster-wide energy estimation, future research could investigate energy efficiency optimizations in Kubernetes environments. Potential areas of study include evaluating existing energy-saving techniques (e.g. carbon-aware schedulers), developing new optimization strategies, and analyzing the effects of different cluster configurations. For example, experiments could explore potential energy savings achieved by disabling high-availability features or dynamically powering servers on and off based on workload demand.

\section{Final Conclusion}

This project successfully established an experimental Kubernetes cluster with integrated energy monitoring. The results demonstrate that Kepler is a promising tool for CPU energy estimation, although further refinement is needed for other resource types. Going forward, improved metric validation, hardware comparisons, and research into cluster-wide optimization strategies will be essential to fully leverage Kepler for practical energy efficiency improvements.
