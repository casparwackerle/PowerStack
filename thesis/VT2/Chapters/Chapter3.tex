\chapter{Attributing Server Power Consumption to Containerized Workloads} % Main chapter title
\label{Chapter3}

\section{Introduction and Context}

While the previous chapter focused on system-level and component-level power measurement and estimation, this chapter shifts focus to an equally complex task: attributing measured server power consumption to the individual containers or workloads responsible for it.

Attributing energy consumption in this context is inherently difficult due to  multi-tenant, multi-layered workloads across multiple CPU cores and devices, as well as temporal granularty mismatch issues. Consequently, direct one-to-one mapping of energy consumption to workload is generally not possible.

Nonetheless, various techniques have emerged to approach this problem. The goal is to create an accurate and fair approximation of how much energy a given container or process is responsible for at any point in time. This chapter provides a conceptual foundation for these techniques. The subsequent Chapter~\ref{Chapter4} will examine how selected tools implement these ideas in practice. While some implementation aspects will be referenced for illustration, this chapter is focused on general methodologies, not tool-specific behavior.

\section{Power Attribution Methodology}

\subsection{The Central Idea Behind Power Attribution}

At its core, the concept of power attribution is simple: a task should be held accountable for the energy consumed by the resources it actively uses. If a task occupies the CPU for a given period, it is attributed the energy consumed by the CPU during that time. By summing the energy usage of all tasks belonging to a container, one can estimate the total energy consumption of that container. Since energy is the integral of power over time, the average power consumption of a container can be calculated by dividing its attributed energy by the total duration of interest. Depending on the use case, either energy (in joules) or power (in watts) may provide more meaningful insight. Energy is often used to quantify cost or carbon footprint, while power helps identify peak loads and inefficiencies.

While this model appears intuitive, its implementation in real systems is far from trivial. One major complication stems from the intricacies of multitasking on modern systems, which is discussed in subsection~\ref{sec:linux-multitasking}. Subsection~\ref{sec:utilization_tracking} examines and compares different utilization tracking mechanisms, in Linux and Kubernetes. A a result of the fine-grained temporal control of multitasking, another major challenge is temporal granularity. Power consumption is typically sampled at much coarser intervals than kernel resource usage statistics. These mismatched update rates and resolutions must be reconciled to build meaningful correlations. This issue is elaborated in subsection~\ref{sec:granularity}.

Consequently, power attribution becomes a complex algorithmic process, involving summation, weighting, and interpolation across multiple metrics. It must strike a balance between data availability and estimation accuracy. A perfectly accurate system is not feasible, especially in heterogeneous or production-grade environments. Limitations and accuracy trade-offs are further discussed in subsection~\ref{ch:limitations}.

Real-world systems also introduce additional complications such as idle power, shared background processes, or missing hardware counters. These edge cases and practical constraints are addressed in section~\ref{sec:realworld-problems}. Finally, section~\ref{sec:attribution-philosophies} discusses the different philosophies of different attribution models to take account for different key demographics.

Despite these difficulties, power attribution serves a critical role in understanding container behavior. If applied consistently across all containers and system resources, it can uncover the dynamic patterns of energy usage within a server. This insight forms a foundational building block for cluster-level energy optimization. Administrators or automated systems can use this data to analyze the effect of configuration changes, improve workload scheduling, or optimize performance-per-watt, whether during runtime or post-execution.

\subsection{Multitasking, Execution Units, and related metrics in Linux}
\label{sec:linux-multitasking}
Linux is a multitasking operating system that enables multiple programs to run concurrently by managing how processor time is divided among tasks. This capability is central to container-based computing and directly impacts how workload activity is linked to energy consumption.

Multitasking in Linux operates on two levels: time-sharing on a single core and true parallel execution across multiple cores. On a single-core system, the kernel scheduler rapidly switches between tasks by allocating short time slices, creating the illusion of parallelism. On multi-core systems, tasks can run simultaneously on different cores, increasing throughput but also complicating the task of correlating resource usage with measured power consumption.

At the kernel level, the smallest unit of execution is a \emph{task}. This term covers both user-space processes and threads, which the kernel treats uniformly in terms of scheduling and resource accounting. Each task is represented by a \texttt{task\_struct}, which tracks its state, scheduling data, and resource usage.

A \emph{process} is typically a task with its own address space. Threads, by contrast, share memory with their parent process but are scheduled independently. As a result, a multi-threaded program or container may generate several concurrent tasks, potentially running across multiple cores. These tasks are indistinguishable from processes in kernel metrics, which complicates aggregation unless care is taken to associate related threads correctly.

In containerized environments, tasks belonging to the same container are grouped using Linux control groups (cgroups) and namespaces. These mechanisms allow the kernel to apply limits and collect resource usage statistics at the container level, making them central to energy attribution in Kubernetes-based systems.

\subsection{Resource Utilization Tracking in Linux and Kubernetes}
\label{sec:utilization_tracking}

In modern Linux-based systems, particularly within Kubernetes environments, multiple methods exist to track resource utilization. These methods vary significantly in terms of temporal granularity, scope, and origin. While they often expose overlapping information, their internal mechanisms differ, leading to trade-offs in precision, resolution, and suitability for certain use cases such as energy attribution.

The following list of tracking mechanisms does not address the difference between cgroups v1 and v2 and assumes that on most modern servers default to cgroups v2.

\subsubsection*{CPU Utilization Tracking}

\begin{itemize}
    \item \textbf{/proc/stat:} A global, cumulative snapshot of CPU activity since boot. It records jiffies spent in user, system, idle, and iowait modes. Temporal resolution is high, but data is coarse and not process- or cgroup-specific.
    \item \textbf{/proc/\textless pid\textgreater :} Provides per-task CPU statistics including time spent in user and kernel mode. Offers fine-grained tracking on a per-process level but must be polled manually at high frequency to detect short-lived changes. Contains information about task container and namespace.
    \item \textbf{cgroups:} Tracks cumulative CPU usage in nanoseconds per cgroup. In Kubernetes, each container runs in its own cgroup, enabling container-level usage attribution. Granularity is high, and this is a foundational metric for tools like KEPLER and cAdvisor.
    \item \textbf{eBPF:} eBPF enables near-real-time tracking of per-task CPU cycles and execution and allows correlation of resource usage to kernel events (e.g. context switches). It is especially valuable when precise attribution to short-lived tasks or containers is required.
    \item \textbf{Hybrid tools:} Many tools provide aggregated metrics and statistics based on the afforementioned methods. While user-friendly, these are usually provide lower temporal precision, but may be useful in some instances. \textbf{cAdvisor:} collects and aggregates CPU usage per container by reading from cgroups. While widely used, its default update interval is coarse. Data is sampled and averaged, which limits its use in high-resolution analysis. \textbf{metrics-server (metrics.k8s.io):} exposes aggregated CPU usage via the Kubernetes API. It pulls metrics from Kubelet (which relies on cAdvisor) and is updated every ~15 seconds. Not suitable for precise or historical analysis.
\end{itemize}

\subsubsection*{Memory Utilization Tracking}

\begin{itemize}
    \item \textbf{/proc/meminfo:} Provides a system-wide view of memory usage but lacks per-task or per-container resolution.
    \item \textbf{/proc/\textless pid\textgreater/status:} Exposes memory-related counters for each process (e.g., RSS, virtual memory size). Temporal granularity is fine but requires frequent polling.
    \item \textbf{cgroups (memory):} Records memory usage for groups of processes. `memory.usage\textunderscore in\textunderscore bytes` shows current memory usage per cgroup, allowing container-level tracking. High granularity and reliability, frequently used in both monitoring and enforcement.
    \item \textbf{cAdvisor and metrics-server:} As with CPU, memory stats are aggregated from cgroup data. These APIs offer lower resolution and no historical data.
\end{itemize}

\subsubsection*{Disk I/O Utilization Tracking}

\begin{itemize}
    \item \textbf{/proc/diskstats:} Exposes per-disk block I/O statistics (read/write ops, sectors read/written, etc.). High resolution but only at the device level.
    \item \textbf{/proc/\textless pid\textgreater/io:} Tracks per-process I/O activity (bytes read/written, syscall counts). Useful for attributing I/O behavior, but coarse in how it correlates to actual disk access timing.
    \item \textbf{cgroups (blkio):} Reports aggregated I/O stats per cgroup (bytes, ops, per-device). Allows container-level attribution. Granularity depends on polling rate and support by the underlying I/O subsystem.
    \item \textbf{eBPF (tracepoints, kprobes):} Enables real-time tracing of block I/O syscalls, bio submission, and completion.
\end{itemize}

\subsubsection*{Network I/O Utilization Tracking}

\begin{itemize}
    \item \textbf{/proc/net/dev:} Shows network statistics per interface. Updated continuously, but lacks process/container granularity.
    \item \textbf{cgroups (net\textunderscore cls, net\textunderscore prio):} Used to mark packets with cgroup IDs, enabling traffic shaping and classification. Attribution is possible if paired with packet monitoring tools, but rarely used directly.
    \item \textbf{eBPF:} Allows tracing of network activity at various points in the stack (packet ingress, egress, socket calls). Offers very high granularity and can attribute traffic to specific containers.
\end{itemize}

\subsubsection*{Comparative Summary}

\begin{table}[H]
\centering
\begin{tabular}{| m{3.2cm} | m{2cm}| m{3.6cm} | m{4cm} |}
\hline
\textbf{Source} & \textbf{Granularity} & \textbf{Scope} & \textbf{Notes} \\
\Xhline{1.5pt}
/proc/stat & Medium & Global & Jiffy-based, coarse \\
\hline
/proc/\textless pid\textgreater/stat & High & Per-process & Fine-grained, must poll manually \\
\hline
cgroups & High & Per-cgroup & Foundation for container metrics \\
\hline
cAdvisor & Medium-Low & Per-container & Aggregated from cgroups, limited rate \\
\hline
eBPF & Very High & Per-task, system-wide & Real-time, customizable, low overhead \\
\hline
\end{tabular}
\caption{Comparison of resource usage tracking mechanisms}
\end{table}

\subsubsection*{The Role of eBPF in High-Fidelity Resource Tracking}

eBPF (extended Berkeley Packet Filter) is a kernel technology that allows programs to be safely injected into the kernel to observe or manipulate system behavior. In the context of resource tracking, eBPF offers several advantages:

\begin{itemize}
    \item \textbf{High granularity:} eBPF programs can trace function calls, syscalls, and kernel events at microsecond precision.
    \item \textbf{Low overhead:} Designed to be efficient, eBPF avoids the performance penalties associated with traditional tracing.
    \item \textbf{Flexibility:} It can be used to attach to CPU, I/O, memory, and network events.
\end{itemize}

KEPLER uses eBPF to monitor CPU cycles and task scheduling events with high precision, enabling accurate attribution of resource usage to short-lived or highly dynamic workloads. It complements cgroup and perf-based metrics, allowing power attribution models to track containers that would otherwise be indistinguishable using standard polling-based methods.

\textbf{Limitations of eBPF} include:
\begin{itemize}
    \item Complexity of implementation and deployment
    \item Kernel version dependencies (older kernels have limited capabilities)
    \item Limited observability of certain high-level abstractions (e.g., full container metadata requires augmentation)
\end{itemize}

Overall, eBPF represents a powerful augmentation to traditional Linux resource tracking mechanisms, particularly in time-sensitive and high-frequency observability applications.


























\subsection{Temporal Granularity and Measurement Resolution}
\label{sec:granularity}
To correlate CPU usage with power consumption, time must be considered at an appropriate granularity. The Linux kernel tracks CPU usage at the level of scheduler ticks, which are driven by a system-wide timer interrupt configured via \texttt{CONFIG\_HZ}. Typical values range from 250 to 1000 Hz, meaning time slices of 4 to 1 milliseconds, respectively. These ticks, or \emph{jiffies}, represent the smallest scheduling time unit and are used to increment counters such as \texttt{utime} and \texttt{stime} for each task.

More modern interfaces (such as cgroup v2’s \texttt{cpu.stat}) provide higher-resolution timestamps, often in nanoseconds, depending on the kernel version and configuration.

In contrast, power measurement tools generally operate at coarser time resolutions. Intel RAPL, for example, may expose updates every few milliseconds to hundreds of milliseconds, while BMC- or IPMI-based readings typically update once per second or slower. As a result, power attribution techniques must reconcile the high-frequency task activity data with lower-frequency power measurements, often through aggregation or interpolation over common time intervals.

A clear understanding of these execution and timing units is essential for building reliable power attribution models. These concepts underpin all subsequent steps, including metric fusion, resource accounting, and workload-level aggregation.

\subsection{Limitations}
\label{ch:limitations}

\section{Real-world problems}
\label{sec:realworld-problems}

\section{Attribution Philosophies}
\label{sec:attribution-philosophies}








% \begin{table}[H]
% \centering
% \caption{Relevant Linux Concepts for Power Attribution}
% \begin{tabular}{p{3.2cm} p{10.8cm}}
% \toprule
% \textbf{Concept} & \textbf{Description} \\
% \midrule
% \texttt{task} & The fundamental unit of execution in the Linux kernel, representing either a process or a thread. Each task is associated with a \texttt{task\_struct}. \\
% \texttt{process} & A task with a unique address space. Can spawn multiple threads. Identified by a PID. \\
% \texttt{thread} & A task that shares memory and other resources with its parent process. Scheduled independently. \\
% \texttt{cgroup} & Control groups allow grouping of tasks to apply resource limits and gather aggregated usage statistics. \\
% \texttt{namespace} & Kernel feature that provides isolation of global system resources (e.g., PIDs, network) for containers. \\
% \texttt{jiffy} & The smallest time unit in the Linux kernel scheduler, defined by the timer interrupt frequency (e.g., 1 ms for \texttt{CONFIG\_HZ=1000}). \\
% \texttt{CONFIG\_HZ} & Kernel configuration parameter defining the number of timer interrupts per second, setting the jiffy granularity. \\
% \texttt{utime}/\texttt{stime} & Per-task counters for time spent in user mode and system (kernel) mode, usually in jiffies. \\
% \texttt{/proc} & Virtual filesystem exposing kernel and process information, including per-task CPU stats and system activity. \\
% \texttt{/sys/fs/cgroup} & Interface exposing cgroup metrics and resource controls. Used for container-level CPU, memory, and I/O accounting. \\
% Completely Fair Scheduler (CFS) & Default Linux CPU scheduler, allocating CPU time fairly among tasks using a virtual runtime model. \\
% Runqueue & Per-CPU queue holding runnable tasks, from which the scheduler picks the next to execute. Impacts CPU activity patterns. \\
% \texttt{task\_struct} & Core kernel structure that stores all metadata about a task, including its scheduling state and resource usage. \\
% \bottomrule
% \end{tabular}
% \end{table}



 
\section{Available Metrics for Attribution}




\begin{comment}


\section{Overview and Challenges}

3.1 Introduction and Context

    What this chapter is about: attribution of observed/measured power to containerized workloads.

    Why this is hard: modern servers run multi-tenant, multi-layered workloads on multi-core CPUs across distributed systems.

    Brief mention that Chapter 4 will discuss implementations (tools), and that some methods discussed here are implemented in those tools.

3.2 General Methodology of Power Attribution

    Recap: What is being measured? (e.g., node-level power via RAPL, BMC, IPMI, etc.)

    What needs to be attributed? (e.g., container CPU time, memory bandwidth, network I/O, etc.)

    Temporal slicing: how time is broken into intervals, and why this is necessary.

    Synchronization of metrics: fusion of different data sources (e.g., power metrics vs. cgroup stats).

    Challenges: different update rates, time granularity mismatches, delays, buffering.

    Include: short recap of Linux scheduling and how resource usage can be tracked per-process or per-cgroup.
3.3 Available Metrics for Attribution

    Kubernetes-level metrics (e.g., metrics-server, Prometheus, kubelet summaries).

    Linux cgroups (v1/v2): cpuacct.usage, memory.stat, blkio, etc.

    Container-runtime links: how to map containers to pids or cgroups.

    Which of these can be sampled frequently and reliably?

    You might need a table of metrics per subsystem: CPU, memory, I/O, network.
3.4 Dealing with Data Gaps and Imperfect Systems

    Missing RAPL: fallback strategies (e.g., model-based estimates, heuristics).

    Granularity mismatch: smoothing, interpolation, or discarding metrics.

    Unattributable power: idle power, background daemons, OS tasks.

    Could bring up Scaphandre’s fallback mode or Kepler’s power models.
3.5 Attribution Philosophies

    Should idle power be distributed? If so, how? (Evenly? Proportional to active time?)

    System processes: Should kubelet, OS daemons be excluded or charged to all users?

    Perspective matters: Developer wants per-container efficiency, Admin wants cluster-wide utilization.

    Energy proportionality: how fair is the attribution?

    This is where you can dig into conceptual frameworks and different stakeholder goals.
3.6 Distributed Cluster Considerations

    Multi-node clusters: how to gather power + workload metrics across nodes.

    Synchronization issues across nodes (e.g., clock drift, metric lag).

    Existing methods (e.g., Kepler node agents, Prometheus federation).

    Example: how Kepler does this with Prometheus and CRDs.

    Important to mention that some tools assume node-level independence.
3.7 Implementation and Technical Considerations

    Needed kernel interfaces (e.g., procfs, sysfs, eBPF)

    Prometheus scraping intervals, resolution

    Process-to-container mappings (CRI / containerd / Docker specifics)

    Accuracy limitations introduced by monitoring frequency, sampling delays.

    You can reference the Scaphandre and Kepler docs here for concrete implementation notes.


3.8 Summary and Transition

    Summarize the key conceptual challenges.

    State that Chapter 4 will now look at how different tools attempt to solve these challenges.











Attributing energy consumption to workloads is challenging due to the temporal, spatial, and semantic mismatches between power measurements and system activity data. A variety of technical and philosophical issues must be considered, particularly in multi-tenant containerized environments.

% TODO: Briefly reference Jay et al. and Raffin et al. for real-world evidence on divergence and limitations.

\section{General Attribution Methodology}

\subsection{Measurement vs. Attribution}
Measured node-level power data must be distributed over container-level workloads. This requires additional information on workload activity, typically extracted from system and Kubernetes metrics.

\subsection{Temporal Slicing and Synchronization}
To make attribution meaningful, all involved metrics must be synchronized in time. This section explains how time intervals are formed and what granularity is feasible in practice.

% TODO: Insert a brief recap of Linux scheduling behavior on multi-core systems.
% TODO: Add example of Scaphandre's approach to time alignment.

\subsection{Metric Fusion Challenges}

Different metrics (e.g., power, CPU time, I/O counters) are exposed at different intervals and precision levels. Fusion of these requires preprocessing such as interpolation or resampling.

% TODO: Discuss granularity mismatches, buffering delays, and implications for accuracy.

\section{Available Metrics and Resource Mapping}

\subsection{Linux Cgroups and Kernel Interfaces}
Linux exposes resource usage per process and control group. These metrics form the basis for workload tracking.

\subsection{Kubernetes-Specific Metrics}
The orchestration layer provides higher-level metadata and metrics, enabling container-to-node mapping and abstraction over pods.

\subsection{From Container to Resource Usage}
This section explains how container runtimes, the kubelet, and tools like Prometheus bridge the gap between containerized workloads and kernel metrics.

% TODO: Include a table summarizing relevant metrics by subsystem (CPU, memory, I/O, network).

\section{Handling Incomplete or Missing Data}

Power attribution must remain functional even when some metric sources are missing. Common issues include:
\begin{itemize}
    \item RAPL not available (AMD CPUs, virtualized hardware, etc.)
    \item No access to power states (e.g., NIC power states)
    \item Missing max/idle power for heuristic models
\end{itemize}

% TODO: Discuss fallback models used by Kepler or Scaphandre
% TODO: Introduce the concept of estimation-based attribution using known interfaces like PHY medium for NICs

\section{Attribution Philosophies}

Different users require different attribution strategies. This section explores:
\begin{itemize}
    \item Idle power attribution: should it be distributed or excluded?
    \item System service attribution: kubelet, OS daemons, monitoring agents
    \item Fairness and energy proportionality
    \item Stakeholder views: developers vs. platform operators
\end{itemize}

% TODO: Optional diagram: visualizing power attribution choices in stacked bar chart

\section{Multi-Node Considerations in Kubernetes Clusters}

In distributed clusters, each node must measure and attribute energy locally. This section covers:
\begin{itemize}
    \item Distributed metric collection (Prometheus federation, node-exporter, etc.)
    \item Time synchronization between nodes (NTP, scrape intervals)
    \item KEPLER and Scaphandre: how tools implement cross-node monitoring
\end{itemize}

% TODO: Include discussion of architectural limitations in cluster-wide correlation

\section{Implementation Considerations}

\subsection{Data Sources and Kernel Access}
Covers procfs, sysfs, powercap, perf, eBPF, and other Linux interfaces for metric collection.

\subsection{Metric Collection Strategies}
Includes Prometheus-based scraping, local daemons, and event-driven collection.

\subsection{Container Identification and Attribution}
Explains how process-to-container mappings are maintained in Docker, containerd, and CRI-based runtimes.

% TODO: Explain the challenges of PID reuse, cgroup migration, container restarts.

\section{Related Work and Comparative Studies}

Recent studies have critically analyzed the accuracy and usefulness of software-based power meters:

\begin{itemize}
    \item Jay et al. (2023): Identified systematic offsets between software and hardware meters, while highlighting correlation consistency.
    \item Raffin and Trystram (2024): Compared internal access methods to RAPL, identifying major implementation differences.
    \item Khan et al. (2018): Validated RAPL against smart plugs; demonstrated suitability for most datacenter workloads.
\end{itemize}

% TODO: Insert citation keys from BibTeX library

\section{Conclusion and Outlook}


\end {comment}