% Indicate the main file. Must go at the beginning of the file.
% !TEX root = ../main.tex

\chapter{Implementation} % Main chapter title
\label{Chapter3}

This chapter describes the implementation and configuration of the various components used in this project. All automation scripts are designed to be idempotent. All scripts can be executed with shell scripts in the \texttt{Powerstack/scripts}-directory. Generally, all configuration is to be done in the central configuration file (\texttt{/Powerstack/configs/inventory.yml}) unless otherwise stated. Sensitive information is to be defined in the ansible-vault file\\(\texttt{/Powerstack/configs/vault.yml}). To keep this chapter brief, instructions for verification are written in Appendix \ref{AppendixB}

\section{K3s Installation}

This section describes the steps involved in setting up a Kubernetes cluster using K3s on bare-metal servers. The installation was automated using an Ansible playbook forked from the official k3s-io/k3s-ansible \parencite{k3s-ansible} repository, with necessary customizations for internal IP-based communication.
\subsection{Preparing the Nodes}

Before running the Ansible playbook, the following prerequisites need to be in place on all servers:

\begin{itemize}
    \item \textbf{Operating System:} Ubuntu 22.04 (used kernel version 5.15.0)
    \item \textbf{Passwordless SSH:} Passwordless SSH access must be configured for a user with sudo privileges on all servers.
    \item \textbf{Networking:} Each server should have both an internal IP (for cluster communication) and an external IP (for access via VPN or external management).
    \item Local Ansible Control Node Setup:
    \begin{itemize}
        \item \textbf{Ansible-community} 9.2.0 (must be 8.0+).
        \item \textbf{Python} 3.12.3 and Jinja 3.1.2 installed as dependencies.
        \item \textbf{kubectl} 1.31.3
    \end{itemize}
\end{itemize}

\subsection{K3s Installation with Ansible}

The playbook supports x64, arm64, and armhf architectures. For this project, it was tested on x64 architecture only.

\subsubsection{Configuration Details}
\begin{itemize}
    \item Internal and external IP addresses of all servers must be specified.
    \item One server must be designated as the control node.
    \item Default configurations such as ansible-port, ansible-user, and k3s-version can be changed if needed.
\end{itemize}

\subsubsection{Kubectl Configuration}
\begin{itemize}
    \item The playbook automatically sets up kubectl for the user on the Ansible control node by copying the Kubernetes config file from the control node to the local machine.
    \item The user must rename the config file from 'config-new' to 'config' and set the context to powerstack using the following command:\\
    \texttt{kubectl config use-context powerstack}
\end{itemize}

\section{NFS Installation and Setup}

\subsection{NFS Installation with Ansible}

Setting up the NFS server and clients was fully automated using an Ansible playbook. Before beginning the automated setup, the following manual step must be completed:

\begin{itemize}
\item \textbf{Disk Selection:} A suitable disk must be chosen on the control node to act as persistent storage. It is important to note that this disk will be reformatted, and all existing data will be lost.
\end{itemize}

The Ansible playbook performs the following actions:

\begin{itemize}
\item \textbf{Disk Preparation:} The selected disk is partitioned (if necessary) and formatted with a single Btrfs partition. The entire disk space is allocated to this partition. The partition is then mounted to \texttt{/mnt/data}, and an entry is added to \texttt{/etc/fstab} to ensure persistence across reboots.
\item \textbf{NFS Server Setup:} The \texttt{nfs-kernel-server} package is installed and configured on the control node. The directory \texttt{/mnt/data} is exported as an NFS share, accessible to the worker nodes.
\item \textbf{NFS Client Setup:} On each worker node, the \texttt{nfs-common} package is installed. The NFS share is mounted, and an \texttt{/etc/fstab} entry is created to ensure persistence across reboots.
\end{itemize}

\subsubsection{Configuration Details}

\begin{itemize}
    \item The nfs network must be specified, and the control and worker nodes must be in that network
    \item The export path must be specified
\end{itemize}

\section{Rancher Installation and Setup}

\subsection{Rancher Installation with Ansible and Helm}

Although not strictly necessary for the project, Rancher was deployed in the\\
\texttt{cattle-system} namespace to assist with debugging and system analysis. The installation was automated using an Ansible playbook, which integrates Helm for deploying Rancher and its dependencies. The key steps are as follows:

\begin{itemize}
\item \textbf{Helm Installation:} Helm was installed on the control node to facilitate the deployment of Rancher and its dependencies.
\item \textbf{Namespace Creation:} The \texttt{cattle-system} namespace was created to host the Rancher deployment.
\item \textbf{Cert-Manager Deployment:} Cert-Manager, a prerequisite for Rancher, was installed to manage TLS certificates.
\item \textbf{Rancher Deployment:} Rancher was installed using the official Helm chart. During installation, the following parameters were configured:
  \begin{itemize}
  \item \textbf{Hostname:} A Rancher hostname was defined to enable access.
  \item The Helm chart was configured with the \texttt{--set tls=external} option to enable external access to Rancher.
  \item \textbf{Bootstrap Password:} A secure bootstrap password was set for the default Rancher administrator account.
  \end{itemize}
\item \textbf{Ingress Configuration:} An ingress resource was configured to route traffic to Rancher, allowing access through the defined hostname.
\end{itemize}



\section{Monitoring Stack Installation and Setup with Ansible}

The monitoring stack, comprising Prometheus, Grafana, and AlertManager, was deployed using the kube-prometheus-stack\parencite{prometheus_helm_charts}-Helm chart from the\\\texttt{prometheus-community/helm-charts} repository. While the repository was forked for convenience, no changes were made to the upstream chart, ensuring compatibility with future updates.

\subsection{Prometheus and Grafana Installation with Ansible and Helm}

The installation process was automated using Ansible roles, ensuring idempotency and centralization of configurations. The following key steps were executed:

\begin{itemize}  
    \item \textbf{Persistent Storage Configuration:}
    \begin{itemize}
        \item Directories for Prometheus, Grafana, and AlertManager were created on the NFS-mounted disk.
        \item A custom \texttt{StorageClass} was defined for the NFS storage. The default storage \texttt{StorageClass} local-path was overridden to be non-default.
        \item PersistentVolumes (PVs) were created for Prometheus, Grafana, and AlertManager. A PersistentVolumeClaim (PVC) was explicitly created for Grafana, while PVCs for Prometheus and AlertManager were managed by the Helm chart.
    \end{itemize}

    \item \textbf{Helm Chart Installation:}
    \begin{itemize}
        \item A Helm values file was generated dynamically using a Jinja template. This template incorporated variables from the central Ansible configuration file to ensure consistency. Sensitive information, such as the Grafana admin password, was included in the values file. To mitigate potential security risks, the values file was removed from the control node after installation.
        \item The Helm chart was installed using an Ansible playbook. The following customizations were applied via the generated values file:
        \begin{itemize}
            \item PVC sizes for Prometheus and AlertManager were set based on the central configuration.
            \item A Grafana admin password was defined.
            \item Prometheus scrape configurations were adjusted to include the KEPLER endpoints.
            \item Changes to the \texttt{securityContext} were made to allow Prometheus to scrape KEPLER metrics.
        \end{itemize}
    \end{itemize}

    \item \textbf{Service Port Forwarding:}
    \begin{itemize}
        \item Prometheus, Grafana, and AlertManager services were exposed using static \texttt{NodePort}s defined in the central configuration file, enabling external access.
    \end{itemize}

    \item \textbf{Cleanup:}
    \begin{itemize}
        \item A cleanup playbook was executed to remove sensitive configuration files from both the control node and the Ansible control node.
    \end{itemize}
\end{itemize}

\subsection{Removal Playbook}

An Ansible playbook was created to handle the complete uninstallation of the monitoring stack. This was necessary to ensure that PVs and PVCs were explicitly removed to avoid residual artifacts in the Kubernetes cluster.

\section{KEPLER Installation and Setup with Ansible and Helm}

\subsection{Preparing the Environment}

The KEPLER deployment uses the official KEPLER Helm chart repository. Before deploying KEPLER, several prerequisites must be addressed to ensure proper functionality.

\subsubsection{Redfish Interface}

The Redfish Scalable Platforms Management API is a RESTful API specification for out-of-band systems management. On the Lenovo servers used in this project, Redfish exposes IPMI power metrics, which KEPLER accesses through its Redfish interface. To verify Redfish functionality, navigate to the Lenovo XClarity Controller and ensure the following setting is enabled:
\begin{itemize}
    \item \textbf{IPMI over LAN:} This option can be found under \texttt{Network -> Service Enablement and Port Assignment}.
\end{itemize}

The Redfish API can be tested by visiting the following endpoints in a web browser:
\begin{itemize}
    \item General Redfish information: \texttt{https://<BMC-IP>/redfish/v1}
    \item Power metrics: \texttt{https://<BMC-IP>/redfish/v1/Chassis/1/Power\#\textbackslash{}PowerControl}
\end{itemize}

\subsubsection{Kernel Configuration}

KEPLER requires kernel-level access for eBPF tracing, which involves setting a tracepoint using the \texttt{syscall perf\textunderscore event\textunderscore open}. By default, this syscall is restricted. To allow KEPLER to function properly, an Ansible role is used to modify the kernel parameter \texttt{perf\textunderscore event\textunderscore paranoid} via \texttt{sysctl} without requiring a reboot.

The restriction level can be verified by checking the value of \texttt{/proc/sys/kernel/perf\textunderscore event\textunderscore paranoid}. For this project, all restrictions were removed by setting the value to \texttt{-1}.

\subsection{KEPLER Deployment with Ansible and Helm}

KEPLER was deployed using the KEPLER Helm chart\parencite{kepler_helm_chart} from the\\\texttt{sustainable-computing-io/kepler-helm-chart} repository, with Ansible automating the configuration and deployment process. The deployment configuration was centralized in a Jinja template, which was rendered locally and copied to the control node before applying it.

Key configurations in the Helm values file include:
\begin{itemize}
    \item \textbf{Enabled metrics:} Various metric sources are enabled for detailed energy monitoring.
    \item \textbf{Service port:} The KEPLER service port is defined for Prometheus to scrape metrics.
    \item \textbf{Service interval:} The KEPLER service interval is set to 10 seconds.
    \item \textbf{Redfish metrics:} Redfish/IPMI metrics are enabled, and Redfish API credentials are provided. The Redfish credentials are the same as those used for the Lenovo XClarity Controller interface. Note that the BMC IP address differs from the node IP address.
\end{itemize}

\subsection{Verifying KEPLER Metrics}

After deployment, it was essential to verify that KEPLER was correctly collecting and exposing metrics. Verification involves the following steps:

\subsubsection{Prometheus scraping}

After deploymnet, successful Prometheus scaping of the KEPLER endpoints can be verified using the Prometheus web interface. 

\subsubsection{Metric availability}

All KEPLER metrics were checked individually in the Promehteus web interace to ensure that non-zero values were being written. Each metric would disclose a single metric, which was a welcome additional confirmation that the listed data source was being monitored correctly.

\subsubsection{Kepler logs} 

The KEPLER logs were inspected for insight into used data sources:
\lstinputlisting[
    language=bash,
    caption=\texttt{kepler.log},
    basicstyle=\ttfamily\tiny
]{Code/kepler.log}

\subsubsection{Power metrics from ACPI / IMPI}

In the event that both ACPI and IPMI were configured to measure platform power, KEPLER prefered to use IPMI as its primary data source, meaning that it would use the IPMI overall energy consumption, and calculate lower-level energy consumption using ACPI. This is to be expected, since IPMI allows to measure power at a higher level than ACPI, and can get detailed power data for the entire plaform. In the absence of IPMI data, KEPLER uses ACPI as the only power data source. 

\subsubsection{Redfish issues}

KEPLER was sporadically unable to correcly handle individual redfish data values. These incedents were sparse for different data values. Unfortunately, the source of this issue could not be eliminated in the context of this thesis. The log below shows an instance of the following error:

\begin{lstlisting}[language=bash]
Failed to get power: json: cannot unmarshal number 3.07 into Go struct field Voltages.Voltages.ReadingVolts of type int
\end{lstlisting}

\subsubsection{Error Message cpu0/online}
The following error message is notable: 
\begin{lstlisting}[language=bash]
WARNING: failed to read int from file: open /sys/devices/system/cpu/cpu0/online: no such file or directory
\end{lstlisting}
The missing file warning can be attributed to the fact that the Intel Xeon used in this project does not support Core Offlining, i.e. the dynamic disableling of individual CPU Cores at runtime. While Core Offlining is an interesting feature for energy-efficiency ananlysis, this can be acccepted as a hardware limitation of this project.