% % !TEX root = ../main.tex

% %----------------------------------------------------------------------------------------
% % APPENDIX B
% %----------------------------------------------------------------------------------------

% \chapter{System Verification Instructions} % Main appendix title

% \label{AppendixB} % For referencing this appendix elsewhere, use \ref{AppendixB}

% \section{K3s Installation verification}

% \begin{itemize}
%     \item Verify Node Status: 
%     \begin{itemize}
%         \item Run the following command on the local machine to check that all nodes are correctly registered and ready:\\
%         \texttt{kubectl get nodes -o wide}
%         \item Ensure that all nodes appear as Ready and that they are using their internal IP addresses for communication.
%     \end{itemize}

%     \item Verify K3s Services:
%     \begin{itemize}
%         \item On each node, verify that the K3s service is running by executing:\\
%         \texttt{systemctl status k3s} or, for worker nodes:\\
%         \texttt{systemctl status k3s-agent}
%     \end{itemize}

%     \item Verify Pod Status:
%     \begin{itemize}
%         \item Ensure that all Kubernetes system pods are running without errors:\\
%         \texttt{kubectl get pods -A}
%         \item Confirm that critical pods in the kube-system namespace are running.
%     \end{itemize}

%     \item Verify Cluster Access:
%     \begin{itemize}
%         \item Test basic Kubernetes commands from the local machine to ensure proper access to the cluster:\\
%         \texttt{kubectl get namespaces}\\
%         \texttt{kubectl get pods --all-namespaces}
%     \end{itemize}

%     \item Network Connectivity:
%     \begin{itemize}
%         \item Verify internal IP connectivity by pinging the internal IPs of other nodes from each server.
%         \item Ensure that external IP connectivity is functional through VPN.
%     \end{itemize}

%     \item Re-run Ansible Playbook using shell script:
%     \begin{itemize}
%         \item Re-run the Ansible playbook to confirm idempotency:\\
%         \texttt{sh scripts/deploy\textunderscore k3s.sh}
%         \item Ensure that no errors occur and that all tasks complete without changes unless intentionally made.
%     \end{itemize}
% \end{itemize}

% \section{NFS server verification}

% Verifying the NFS installation involves confirming the correct functioning of both the server and client configurations. The following steps can be performed:

% \begin{itemize}
% \item \textbf{Disk Verification:} On the control node, verify that the disk is mounted correctly by checking \texttt{/etc/fstab} and using the command \texttt{df -h}. Ensure that \texttt{/mnt/data} is listed with the expected disk size and mount point.
% \item \textbf{NFS Server Export:} On the control node, run the command \texttt{exportfs -v} to confirm that the \texttt{/mnt/data} directory is exported as an NFS share.
% \item \textbf{NFS Client Mount:} On each worker node, verify that the NFS share is mounted correctly by using \texttt{df -h} or \texttt{mount | grep nfs}. Ensure that the share is listed with the expected mount point and server information.
% \item \textbf{Read/Write Test:} On a worker node, navigate to the mounted NFS directory and perform a simple file read/write test. For example:
%   \begin{itemize}
%   \item Create a file: \texttt{touch /mnt/data/testfile}.
%   \item Check the file on the control node to confirm visibility.
%   \item Delete the file to ensure write permissions are functional.
%   \end{itemize}
% \item \textbf{Service Verification:} On the control node, verify that the \texttt{nfs-kernel-server} service is running using the command \texttt{systemctl status nfs-kernel-server}.
% \item \textbf{Log Inspection:} Check the NFS logs on the control node (\texttt{/var/log/syslog}) for any errors or warnings related to the NFS server.
% \end{itemize}

% \section{Rancher verification}

% \begin{itemize}
%     \item \textbf{Namespace Verification:} Confirm that the \texttt{cattle-system} namespace exists using \texttt{kubectl get namespaces}.
%     \item \textbf{Cert-Manager Deployment:} Verify that Cert-Manager pods are running successfully using \texttt{kubectl get pods -n cert-manager}.
%     \item \textbf{Rancher Pods:} Check that Rancher pods are running and healthy using \texttt{kubectl get pods -n cattle-system}.
%     \item \textbf{Ingress Verification:} Use \texttt{kubectl get ingress -n cattle-system} to confirm that an ingress resource was created with the expected hostname.
%     \item \textbf{Web Interface Access:} Access Rancher through a web browser using the defined hostname. Log in with the bootstrap password to confirm access.
%     \item \textbf{Cluster Registration:} Register the local Kubernetes cluster in Rancher to verify that Rancher can communicate with the cluster.
%     \item \textbf{Log Inspection:} Inspect logs for the Rancher pods using \texttt{kubectl logs <pod-name> -n cattle-system} to ensure there are no errors or warnings.
% \end{itemize}


% !TEX root = ../main.tex
%----------------------------------------------------------------------------------------
% APPENDIX B
%----------------------------------------------------------------------------------------

\chapter{System Verification Instructions} % Main appendix title

\label{AppendixB} % For referencing this appendix elsewhere, use \ref{AppendixB}

\section{K3s}

\begin{itemize}
    \item \textbf{Verify Node Status:} Run \texttt{kubectl get nodes -o wide} on the local machine to check that all nodes are registered and ready. Ensure all nodes appear as \texttt{Ready} and are using their internal IP addresses for communication.
    
    \item \textbf{Verify K3s Services:} On each control node, verify that the K3s service is running using \texttt{systemctl status k3s}. For worker nodes, use \texttt{systemctl status k3s-agent}.
    
    \item \textbf{Verify Pod Status:} Use \texttt{kubectl get pods -A} to ensure all Kubernetes system pods are running without errors. Confirm that critical pods in the \texttt{kube-system} namespace are running.
    
    \item \textbf{Verify Cluster Access:} Test basic Kubernetes commands from the local machine:
    \begin{itemize}
        \item \texttt{kubectl get namespaces}
        \item \texttt{kubectl get pods --all-namespaces}
    \end{itemize}
    
    \item \textbf{Network Connectivity:} Ping the internal IPs of other nodes from each server to verify internal connectivity. Ensure external IP connectivity is functional through the VPN.
    
    \item \textbf{Re-run Ansible Playbook:} Execute \texttt{sh scripts/deploy\textunderscore k3s.sh} to confirm idempotency of the playbook. Verify that no errors occur and all tasks complete without unnecessary changes.
\end{itemize}

\section{NFS Server}

\begin{itemize}
    \item \textbf{Disk Verification:} On the control node, verify the disk is mounted correctly using \texttt{/etc/fstab} and \texttt{df -h}. Confirm that \texttt{/mnt/data} is listed with the expected disk size and mount point.
    
    \item \textbf{NFS Server Export:} Run \texttt{exportfs -v} on the control node to verify that \texttt{/mnt/data} is exported as an NFS share.
    
    \item \textbf{NFS Client Mount:} On each worker node, verify the NFS share is mounted using \texttt{df -h} or \texttt{mount | grep nfs}. Ensure the share is listed with the correct mount point and server information.
    
    \item \textbf{Read/Write Test:} On a worker node, navigate to the mounted NFS directory and perform the following:
    \begin{itemize}
        \item Create a file: \texttt{touch /mnt/data/testfile}.
        \item Verify the file is visible on the control node.
        \item Delete the file to confirm write permissions are functional.
    \end{itemize}
    
    \item \textbf{Service Verification:} On the control node, verify the \texttt{nfs-kernel-server} service is running using \texttt{systemctl status nfs-kernel-server}.
    
    \item \textbf{Log Inspection:} Check \texttt{/var/log/syslog} on the control node for any NFS-related errors or warnings.
\end{itemize}

\section{Rancher}

\begin{itemize}
    \item \textbf{Namespace Verification:} Confirm the \texttt{cattle-system} namespace exists using \texttt{kubectl get namespaces}.
    
    \item \textbf{Cert-Manager Deployment:} Verify that Cert-Manager pods are running using \texttt{kubectl get pods -n cert-manager}.
    
    \item \textbf{Rancher Pods:} Check the status of Rancher pods using \texttt{kubectl get pods -n cattle-system}.
    
    \item \textbf{Ingress Verification:} Use \texttt{kubectl get ingress -n cattle-system} to ensure an ingress resource exists with the expected hostname.
    
    \item \textbf{Web Interface Access:} Access Rancher via the hostname in a web browser. Log in using the bootstrap password to confirm access.
    
    \item \textbf{Cluster Registration:} Register the local Kubernetes cluster in Rancher and verify that communication is established.
    
    \item \textbf{Log Inspection:} Inspect Rancher pod logs using \texttt{kubectl logs <pod-name> -n cattle-system} to ensure no errors or warnings are present.
\end{itemize}

\section{Kube-monitoring-stack}

\begin{itemize}
    \item \textbf{Namespace Verification:} Run \texttt{kubectl get namespaces} to confirm that the \texttt{monitoring} namespace exists.
    
    \item \textbf{Pod Status:} Verify that all pods in the \texttt{monitoring} namespace are running using \texttt{kubectl get pods -n monitoring}.
    
    \item \textbf{Service Status:} Confirm that services for Prometheus, Grafana, and AlertManager are running and accessible using \texttt{kubectl get svc -n monitoring}.
    
    \item \textbf{Web Access:} Access Grafana through the defined NodePort and log in using the configured admin credentials.
    
    \item \textbf{Scrape Configuration:} Check Prometheus targets to ensure that KEPLER endpoints are being scraped correctly.
    
    \item \textbf{Data Persistence:} Restart the cluster and verify that monitoring data is retained by checking PVs and PVCs.
\end{itemize}
